{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "from scipy.linalg import null_space\n",
    "from scipy.linalg import sqrtm\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "from dataclasses import dataclass\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tolerance for numerical computation, set to 1e-10 by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tol = 1e-10 # The absolute tolerance\n",
    "r_tol = 1e-7  # The relative tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Word_Bis:               # The class of bisectors in the symmetric space $X_3$. A list of Word_Bis models describes the bisectors defining the Dirichlet-Selber domain.\n",
    "    word: np.ndarray          # A matrix $g$ in $SL(3,R)$, typically a word in given generators\n",
    "    bis: np.ndarray           # A normal vector (as a 3*3 matrix) of the Selberg bisector $Bis(X, g.X)$\n",
    "\n",
    "@dataclass\n",
    "class Poly_Face:              # The class of faces of polytopes in $X_3$. A list of Poly_Face models describes the polytope structure of the Dirichlet-Selber domain.\n",
    "    equs: list[int]           # A list of bisectors indices (in the list of the accompanying Word_Bis models) whose intersection is the minimal plane containing the face.\n",
    "    codim: int                # The codimension (5 - dim) of the face.\n",
    "    subfaces: list[int]       # A list of face indices that are proper subfaces of the current face.\n",
    "    sample_point: np.ndarray  # A point in $X_3$ (as a 3*3 matrix) lying in the interior of the current face.\n",
    "\n",
    "@dataclass\n",
    "class Ridge_Cycle:            # The class describing a ridge-cycle of a Dirichlet-Selberg domain.\n",
    "    ridge: list[int]          # A list of ridge indices (in the list of the accompanying Poly_Face models), for ridges $r_0, r_1, r_2,...$ in the same ridge cycle.\n",
    "    pairing: list[int]        # A list of word indices (in the list of the accompanying Word_Bis models), each word $g_i$ sends $r_i$ to $r_{i+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_span(vectors, vec):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    vectors: list of np.ndarray\n",
    "        a list of arrays describing a linearly independent collection of vectors.\n",
    "    vec: np.ndarray\n",
    "        an array describing a vector of the same dimension.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    is_in_span: bool\n",
    "        True if `vec` lies in the span of `vectors`, up to tolerance.\n",
    "    \"\"\"\n",
    "    if len(vectors) == 0:\n",
    "        return np.linalg.norm(vec) < a_tol             # The first vector (if nonzero) is independent on its own\n",
    "    matrix = np.array(vectors).T                       # Stack the current independent vectors into a matrix, so each column is a vector    \n",
    "    projection = matrix @ np.linalg.pinv(matrix) @ vec # Compute the projection of the new vector onto the space spanned by the existing vectors\n",
    "    residual = vec - projection                        # Compute the difference (residual) between the new vector and its projection\n",
    "    return np.linalg.norm(residual) < a_tol            # The new vector is dependent to the existing ones if the residual is smaller than the threshold\n",
    "\n",
    "def extract_basis(vectors):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    vectors: list of np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    indep_vectors: list of np.ndarray\n",
    "        a linearly independent sub-list of `vectors` (same span), up to tolerance.\n",
    "    \"\"\"\n",
    "    indep_vectors = []\n",
    "    for vector in vectors:\n",
    "        if not in_span(indep_vectors, vector):\n",
    "            indep_vectors.append(vector)\n",
    "    return indep_vectors\n",
    "\n",
    "def same_span(vectors_A, vectors_B):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    vectors_A: list of np.ndarray\n",
    "    vectors_B: list of np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    is_same_span: bool\n",
    "        True if span(vectors_A) == span(vectors_B), up to tolerance.\n",
    "    \"\"\"\n",
    "    rank_A = len(extract_basis(vectors_A))                   # Check if they define the same plane by a rank argument\n",
    "    rank_B = len(extract_basis(vectors_B))\n",
    "    rank_AplusB = len(extract_basis(vectors_A + vectors_B))\n",
    "    return (rank_A == rank_AplusB) and (rank_B == rank_AplusB)\n",
    "\n",
    "def symm_to_vec(mat, scale = 1):\n",
    "    \"\"\"\n",
    "    Flatten a symmetric 3×3 `mat` into a 6-vector `vec`\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat: np.ndarray\n",
    "    scale: np.float64\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    vec: np.ndarray\n",
    "    \"\"\"\n",
    "    vec = [mat[0][0], mat[1][1], mat[2][2], scale * mat[0][1], scale * mat[0][2], scale * mat[1][2]]\n",
    "    return vec\n",
    "\n",
    "def vec_to_symm(vec, scale = 1):\n",
    "    \"\"\"\n",
    "    Reassemble a 6-vector `vec` into 3×3 symmetric matrix `mat`\n",
    "    Parameters\n",
    "    ----------\n",
    "    vec: np.ndarray\n",
    "    scale: np.float64\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mat: np.ndarray\n",
    "    \"\"\"\n",
    "    mat = np.array([[vec[0], scale * vec[3], scale * vec[4]],\n",
    "                     [scale * vec[3], vec[1], scale * vec[5]],\n",
    "                     [scale * vec[4], scale * vec[5], vec[2]]])\n",
    "    return mat\n",
    "\n",
    "def is_positive_definite(mat):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat: np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    is_positive_definite: bool\n",
    "        Return True if symmetric matrix `mat` is strictly positive‐definite (all eigenvalues exceed `a_tol`).\n",
    "    \"\"\"\n",
    "    if not isinstance(mat, np.ndarray):\n",
    "        raise ValueError(\"Input must be a numpy array.\")\n",
    "    if mat.shape[0] != mat.shape[1]:\n",
    "        return False                                  # The matrix is not square\n",
    "    try:\n",
    "        min_diag = np.min(np.linalg.eigvalsh(mat))    # Find the smallest eigenvalue\n",
    "        return min_diag > a_tol                       # Positive definite if it is positive (concerning the tolerance).\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False                                  # Not positive definite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question-specific Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orth_complement(matrices):\n",
    "    \"\"\"\n",
    "    Given a list of symmetric 3×3 `mats`, return a basis for their trace-orthogonal complement\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrices: list of np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    orth_matrices: list of np.ndarray\n",
    "    \"\"\"\n",
    "    vectors = [symm_to_vec(matrix) for matrix in matrices]\n",
    "    vectors = extract_basis(vectors)\n",
    "    orth_vectors = null_space(np.array(vectors)).T.tolist()\n",
    "    orth_matrices = [np.array(vec_to_symm(orth_vector, 1/2)) for orth_vector in orth_vectors]\n",
    "    return orth_matrices\n",
    "\n",
    "def sympy_to_cvxpy(mat_sym, free_syms):\n",
    "    \"\"\"\n",
    "    Convert a SymPy matrix `mat_sym` with variables in free_syms into a CVXPY expression\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat_sym: sp.Matrix\n",
    "    free_syms: tuple of sp.symbols\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mat_cvx: cp.Expression\n",
    "    \"\"\"\n",
    "    n_vars = len(free_syms)\n",
    "    rows, cols = mat_sym.shape                                                                # Get the matrix shape\n",
    "    coeff_matrices = [np.zeros((rows, cols), dtype=np.float64) for _ in range(n_vars + 1)]  # Initialize the coefficient matrices\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):                 \n",
    "            expr = sp.expand(mat_sym[i, j])                                                   # Decompose the matrix into entries\n",
    "            if expr.is_Add:                 \n",
    "                terms = expr.as_ordered_terms()                                             # Convert the entry into a list of summands\n",
    "            else:\n",
    "                terms = [expr]                                                              # Simply wrap the entry if it is a single term\n",
    "            for term in terms:\n",
    "                found = False\n",
    "                for idx, sym in enumerate(free_syms):\n",
    "                    if term.has(sym):\n",
    "                        coeff = term.coeff(sym)\n",
    "                        coeff_matrices[idx + 1][i, j] = float(coeff)                        # Add the coefficient of a certain variable to the corresponding matrix\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    coeff_matrices[0][i, j] = float(term)                                   # Add the constant term to the zeroth matrix\n",
    "    x_cvx = cp.Variable(n_vars)                                                             # Define the cvxpy variables\n",
    "    mat_cvx = coeff_matrices[0] + sum(x_cvx[i]*coeff_matrices[i+1] for i in range(n_vars))    # Combine the coefficient matrices into a cvxpy matrix with variables\n",
    "    return mat_cvx\n",
    "\n",
    "def perp_vectors(vec):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    vec: list of np.float64\n",
    "        A 3-vector with at least one positive & one negative component\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    u_vec: list of np.float64\n",
    "        A positive-definite perpendicular vector\n",
    "    w_vec: list of np.float64\n",
    "        An indefinite perpendicular vector\n",
    "    \"\"\"\n",
    "    positive_indices = [i for i, x in enumerate(vec) if x > a_tol]\n",
    "    negative_indices = [i for i, x in enumerate(vec) if x < -a_tol]\n",
    "    if not positive_indices or not negative_indices:\n",
    "        return None, None                 # Our program does not focus on definite input vectors\n",
    "    positive_index = positive_indices[0]  # Find the first positive component index of the vector\n",
    "    negative_index = negative_indices[0]  # Find the first negative component index of the vector\n",
    "    v0 = vec[positive_index]       # The positive one becomes v0\n",
    "    v1 = vec[negative_index]       # The negative one becomes v1\n",
    "    v2 = vec[3 - positive_index - negative_index] # The remaining becomes v2\n",
    "    if v2<0:                              # Compute the perpendicular vectors in the new order\n",
    "        u_sorted = [-v1/(np.sqrt(v0**2 + v1**2)) - v2/(np.sqrt(v0**2 + v2**2)), v0/(np.sqrt(v0**2 + v1**2)), v0/(np.sqrt(v0**2 + v2**2))]\n",
    "        w_sorted = [-v1/(np.sqrt(v0**2 + v1**2)) + v2/(np.sqrt(v0**2 + v2**2)), v0/(np.sqrt(v0**2 + v1**2)), -v0/(np.sqrt(v0**2 + v2**2))]\n",
    "    else:\n",
    "        u_sorted = [-v1/(np.sqrt(v0**2 + v1**2)), v0/(np.sqrt(v0**2 + v1**2)) + v2/(np.sqrt(v1**2 + v2**2)), -v1/(np.sqrt(v1**2 + v2**2))]\n",
    "        w_sorted = [-v1/(np.sqrt(v0**2 + v1**2)), v0/(np.sqrt(v0**2 + v1**2)) - v2/(np.sqrt(v1**2 + v2**2)), v1/(np.sqrt(v1**2 + v2**2))]\n",
    "    u_vec = [u_sorted[[positive_index, negative_index, 3 - positive_index - negative_index].index(i)] for i in range(3)] # Permute the vector back to the original order\n",
    "    w_vec = [w_sorted[[positive_index, negative_index, 3 - positive_index - negative_index].index(i)] for i in range(3)]\n",
    "    return u_vec, w_vec\n",
    "\n",
    "def find_psd_combination(mat_expr, free_syms):\n",
    "    \"\"\"\n",
    "    Solve a small CVXPY problem to find a positive-definite linear combination of `mat_expr` in sp.Matrix with variables in free_syms\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat_expr: sp.Matrix\n",
    "    free_syms: tuple of sp.symbols\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    psd_combination: Optional[np.ndarray]\n",
    "    \"\"\"\n",
    "    t = cp.Variable()\n",
    "    x = cp.Variable(len(free_syms))\n",
    "    mat_cvx = sympy_to_cvxpy(mat_expr, free_syms)                     # The combination of certain matrices\n",
    "    constraints = [mat_cvx - t*np.eye(3) >> 0, x >= -1, x <= 1] # Our question only concerns coefficients lying between -1 and 1\n",
    "    prob = cp.Problem(cp.Maximize(t), constraints)        # Find maximal t such that M-tI is positive definite\n",
    "    prob.solve(solver=cp.SCS,eps=a_tol,max_iters=50000)     # Add verbose=True if needed\n",
    "    if prob.value > 100*a_tol:\n",
    "        return mat_cvx.value                                    # The positive definite linear combination with maximized least eigenvalue\n",
    "    else:\n",
    "        return None                                       # No positive definite linear combinations\n",
    "\n",
    "def riemannian_angle(equ_1, equ_2, base):\n",
    "    \"\"\"\n",
    "    Compute the Riemannian angle between two hyperplanes (normals `equ_1`, `equ_2`) at point `base` in X₃.\n",
    "    Parameters\n",
    "    ----------\n",
    "    equ_1: np.ndarray\n",
    "    equ_2: np.ndarray\n",
    "    base: np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    angle: np.float64\n",
    "    \"\"\"\n",
    "    comp_1 = base @ equ_1\n",
    "    comp_2 = base @ equ_2\n",
    "    angle_cos = - (np.trace(comp_1 @ comp_2))/(np.sqrt((np.trace(comp_1 @ comp_1)) * (np.trace(comp_2 @ comp_2))))\n",
    "    angle = np.arccos(angle_cos)   # Formula is discussed in my paper\n",
    "    return angle\n",
    "\n",
    "def perturb_within_plane(mat, plane_eqs, new_eq):\n",
    "    \"\"\"\n",
    "    Given PD `mat` on the intersection of `plane_eqs`, perturb it slightly across `new_eq` while preserving PD and original constraints.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat: np.ndarray\n",
    "    plane_eqs: list of np.ndarray\n",
    "    new_eq: np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    proj_mat: np.ndarray\n",
    "    \"\"\"\n",
    "    mat = np.array(mat)                                                           # make the matrices numpy for safety reason\n",
    "    plane_eqs = [np.array(equ) for equ in plane_eqs]\n",
    "    new_eq = np.array(new_eq)\n",
    "    if not is_positive_definite(mat):\n",
    "        raise ValueError(\"perturb_within_plane: Input must be positive definite.\")\n",
    "    else:\n",
    "        mat_sqrt = sqrtm(mat)                                                     # Congruence so the input matrix is taken to the origin\n",
    "        plane_eqs_trans = [mat_sqrt @ equ @ mat_sqrt for equ in plane_eqs]\n",
    "        new_eq_trans = mat_sqrt @ new_eq @ mat_sqrt\n",
    "        orth_equs = orth_complement(plane_eqs_trans)\n",
    "        orth_vectors = [symm_to_vec(equ, np.sqrt(2)) for equ in orth_equs]    # Convert from matrices to vectors\n",
    "        new_vector = symm_to_vec(new_eq_trans, np.sqrt(2))\n",
    "        orth_vectors_mat = np.array(orth_vectors).T                                  # Stack the current independent vectors into a matrix, each column is a vector\n",
    "        coeffs = list(np.linalg.pinv(orth_vectors_mat) @ new_vector)                 # Project the new vector to the existing ones\n",
    "        proj_trans = sum(coeff*equ for coeff, equ in zip(coeffs, orth_equs)) # This linear combination lies on the desired plane while keeps away from the new hyperplane\n",
    "        proj_mat = mat_sqrt @ proj_trans @ mat_sqrt                          # Take the matrix back\n",
    "        while not is_positive_definite(proj_mat):\n",
    "            proj_mat = 0.5*proj_mat + 0.5*mat                                    # Go back toward the original matrix if the new one is indefinite\n",
    "        proj_mat = proj_mat/((det(proj_mat)) ** (1/3))                            # Unitize the matrix with respect to the determinant\n",
    "        return proj_mat\n",
    "\n",
    "def maps_plane_equal(old_eqs, new_eqs, isom):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    old_eqs: list of np.ndarray\n",
    "    new_eqs: list of np.ndarray\n",
    "    isom: np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    is_mapped: bool\n",
    "        True if applying `isom` in sends the hyperplane system `old_eqs` to `new_eqs` (i.e. spaces coincide).\n",
    "    \"\"\"\n",
    "    mapped_eqs = [inv(isom) @ mat @ inv(isom.T) for mat in old_eqs] # The normal matrices for the mapped plane\n",
    "    mapped_vecs = [symm_to_vec(mat) for mat in mapped_eqs]          # Convert from matrices to vectors\n",
    "    new_vecs = [symm_to_vec(mat) for mat in new_eqs]\n",
    "    return same_span(mapped_vecs, new_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_matrix_products(gens, max_length):\n",
    "    \"\"\"\n",
    "    Enumerate all distinct products in {gens} U {gens⁻¹} up to length `max_length` and avoiding back‐tracking\n",
    "    Parameters\n",
    "    ----------\n",
    "    gens: list of np.ndarray\n",
    "    max_length: int\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mat_products: list of np.ndarray\n",
    "    \"\"\"\n",
    "    gens = [np.array(mat) for mat in gens] # Make sure they are numpy arrays\n",
    "    k = len(gens)\n",
    "    G = gens + [inv(mat) for mat in gens]\n",
    "    inv_idx = lambda j: (j + k) % (2*k)\n",
    "    mat_products = [np.eye(gens[0].shape[0])]  # The list of matrices and last-index-list, List[np.ndarray]\n",
    "    frontier = {0: set()} # Dict[int, Set[int]]\n",
    "    for _ in range(max_length):\n",
    "        next_frontier = {}  # Dict[int, Set[int]] \n",
    "        for ind in frontier:            # A tuple of word and a possible last-index\n",
    "            for j, mat in enumerate(G):        # A tuple of generator and its index to be added\n",
    "                if inv_idx(j) in frontier[ind]:\n",
    "                    continue                   # Avoid backtracking\n",
    "                N = mat_products[ind] @ mat                    # If not, add the generator to the end of the word\n",
    "                matched = False\n",
    "                for S_ind in range(len(mat_products)):\n",
    "                    if np.allclose(N, mat_products[S_ind], atol = a_tol, rtol = r_tol): # The word is already there; if it is in next_frontier, add a last-index\n",
    "                        matched = True\n",
    "                        if S_ind in next_frontier:\n",
    "                            next_frontier[S_ind].add(j)\n",
    "                        break\n",
    "                if not matched:\n",
    "                    mat_products.append(N)\n",
    "                    N_ind = len(mat_products) - 1\n",
    "                    next_frontier[N_ind] = set()\n",
    "                    next_frontier[N_ind].add(j)\n",
    "        frontier = next_frontier\n",
    "        if not frontier:\n",
    "            break\n",
    "    mat_products.sort(key=lambda M: np.trace(M.T @ M)) # sort by Frobenius norm\n",
    "    return mat_products\n",
    "\n",
    "def find_feasible_point(plane_eqs):\n",
    "    \"\"\"\n",
    "    Check if the intersection of the given hyperplane constraints is non-empty. Return a feasible point or None.\n",
    "    Parameters\n",
    "    ----------\n",
    "    plane_eqs: list of np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    feasible_point: Optional[np.ndarray]\n",
    "    \"\"\"\n",
    "    vectors = [symm_to_vec(equ) for equ in plane_eqs]\n",
    "    independent_vectors = extract_basis(vectors)\n",
    "    indep_matrix = [vec_to_symm(vec) for vec in independent_vectors] # Extract a linearly independent sublist\n",
    "    indep_matrix_sp = [sp.Matrix(mat) for mat in indep_matrix]\n",
    "    A = indep_matrix[0]\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(A)\n",
    "    ev_orth, ev_orth_neg = perp_vectors(eigenvalues)\n",
    "    if ev_orth is None:\n",
    "        feasible_point = None                           # No feasible points if A is semi-definite\n",
    "    else:\n",
    "        n = len(indep_matrix)\n",
    "        Q = eigenvectors\n",
    "        D_orth = np.diag(ev_orth)\n",
    "        if n == 1:\n",
    "            feasible_point = Q @ D_orth @ Q.T           # If n = 1, Find the feasible point from the perpendicular vector of the eigenvalue\n",
    "        else:\n",
    "            linearized_matrix = [Q.T @ mat @ Q for mat in indep_matrix]\n",
    "            linearized_matrix_sp = [sp.Matrix(mat) for mat in linearized_matrix]\n",
    "            x_v = sp.symbols('x1:5')\n",
    "            x_v_new = x_v                                # The necessary variables\n",
    "            diag_max = [a + abs(b) for a, b in zip(ev_orth, ev_orth_neg)]\n",
    "            D_orth_neg = [np.diag(ev_orth_neg),\\\n",
    "                        vec_to_symm(np.sqrt(diag_max[0]*diag_max[1]) * np.eye(6)[:, 3]),\\\n",
    "                        vec_to_symm(np.sqrt(diag_max[0]*diag_max[2]) * np.eye(6)[:, 4]),\\\n",
    "                        vec_to_symm(np.sqrt(diag_max[1]*diag_max[2]) * np.eye(6)[:, 5])]\n",
    "            D_orth_sp = sp.Matrix(D_orth)\n",
    "            D_orth_neg_sp = [sp.Matrix(mat) for mat in D_orth_neg]\n",
    "            matrix_comb = sum((var * mat for mat, var in zip(D_orth_neg_sp, x_v)), start=D_orth_sp)\n",
    "            for i in range(1,n):                        # Remove extra variables\n",
    "                trace_matrix_prod = (matrix_comb * linearized_matrix_sp[i]).trace().expand()\n",
    "                trace_coeffs = {var: trace_matrix_prod.coeff(var) for var in x_v}\n",
    "                if all(abs(coeff) < a_tol for coeff in trace_coeffs.values()): # If a nonzero constant appears, return to false since it is surely empty.\n",
    "                    return None                                                # To avoid dead loop, this case has to return on its own\n",
    "                max_var = max(trace_coeffs, key=lambda v: abs(trace_coeffs[v]))\n",
    "                x_sol = sp.solve(trace_matrix_prod, max_var)[0]                # Solve f = 0 for max_var\n",
    "                x_v_new = tuple(var for var in x_v_new if var != max_var)      # Drop max_var from x_v_new\n",
    "                matrix_comb = matrix_comb.subs(max_var,x_sol)\n",
    "            if n == 5:                                   # If all variables are removed, the feasible point is derived from matrix_comb\n",
    "                D = np.array(matrix_comb).astype(np.float64)\n",
    "                if is_positive_definite(D):\n",
    "                    feasible_point = Q @ D @ Q.T\n",
    "                else:\n",
    "                    feasible_point = None\n",
    "            else:                                        # Otherwise, use cvxpy to find the positive-definite linear combination\n",
    "                poly_comb = matrix_comb.det()\n",
    "                poly_comb_coeff = poly_comb.as_coefficients_dict()\n",
    "                all_zero = all(abs(coef) < a_tol for coef in poly_comb_coeff.values())\n",
    "                if all_zero:\n",
    "                    feasible_point = None\n",
    "                else:\n",
    "                    D = find_psd_combination(matrix_comb, x_v_new)\n",
    "                    if D is None:\n",
    "                        feasible_point = None\n",
    "                    else:\n",
    "                        feasible_point = Q @ D @ Q.T\n",
    "    if feasible_point is not None:\n",
    "        if not is_positive_definite(feasible_point):     # In corner cases, the matrix cvxpy produced may not be positive definite\n",
    "            feasible_point = None\n",
    "        else:\n",
    "            feasible_point = np.array(feasible_point)\n",
    "            feasible_point = feasible_point/((det(feasible_point)) ** (1/3))\n",
    "    return feasible_point\n",
    "\n",
    "def add_facet_to_domain(wbs, faces, new_wb):\n",
    "    \"\"\"\n",
    "    Insert `new_wb` into the Dirichlet-Selberg domain structure (`wbs`, `faces`), updating the face lists in place.\n",
    "    Parameters\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    faces: list of Poly_Face\n",
    "    new_wb: Word_Bis\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    faces: list of Poly_Face\n",
    "    \"\"\"\n",
    "    new_vec = symm_to_vec(new_wb.bis)\n",
    "    face_conds = [0]*len(faces)                            # Assign a condition number (1 to 6, initialized with 0) to each face\n",
    "    for j in range(len(face_conds)):\n",
    "        face_equs = [wbs[ind].bis for ind in faces[j].equs]\n",
    "        face_vecs = [symm_to_vec(equ) for equ in face_equs]\n",
    "        if in_span(extract_basis(face_vecs), new_vec):     # It is type 1 if the equations defining F_j span the new equation\n",
    "            face_conds[j] = 1\n",
    "        elif faces[j].subfaces == []:                      # The case if face is minimal\n",
    "            if find_feasible_point(face_equs + [new_wb.bis]) is not None: # It is type 6 if the new hyperplane intersects with the minimal face\n",
    "                face_conds[j] = 6\n",
    "            else:                                                         # It is type 2 or 4 if the new hyperplane does not intersect with the minimal face\n",
    "                face_sample_point = faces[j].sample_point\n",
    "                if np.trace(face_sample_point @ new_wb.bis) > 0:\n",
    "                    face_conds[j] = 2\n",
    "                else:\n",
    "                    face_conds[j] = 4\n",
    "        else:                                              # The case if face is not minimal (has subfaces)\n",
    "            face_subfaces = faces[j].subfaces\n",
    "            face_subfaces_temp = [face_conds[ind] for ind in face_subfaces]\n",
    "            if 6 in face_subfaces_temp:                    # Any subface is of type 6 -> type 6\n",
    "                face_conds[j] = 6\n",
    "            elif {2, 3} & set(face_subfaces_temp) and {4, 5} & set(face_subfaces_temp): # One subface is of type 2 or 3, another subface is of type 4 or 5 -> type 6\n",
    "                face_conds[j] = 6\n",
    "            elif {1, 3, 5} & set(face_subfaces_temp):      # One subface is of type 1, 3 or 5 -> type 3 or 5\n",
    "                face_sample_point = faces[j].sample_point\n",
    "                if np.trace(face_sample_point @ new_wb.bis) > 0:\n",
    "                    face_conds[j] = 3\n",
    "                else:\n",
    "                    face_conds[j] = 5\n",
    "            else:                                                     # All subfaces are of type 2 or 4\n",
    "                if find_feasible_point(face_equs + [new_wb.bis]) is not None: # If the new hyperplane intersects the span of the face\n",
    "                    face_inters_sample_point = find_feasible_point(face_equs + [new_wb.bis])\n",
    "                    face_subfaces_equs = []\n",
    "                    for ind in face_subfaces:\n",
    "                        if faces[ind].codim == faces[j].codim + 1:\n",
    "                            face_subfaces_equs_temp = [elem for elem in faces[ind].equs if elem not in faces[j].equs]\n",
    "                            face_subfaces_equs[:] = list(set(face_subfaces_equs) | set(face_subfaces_equs_temp))\n",
    "                    face_conds[j] = 6                                  # The case below does not happen -> 6\n",
    "                    for ind in face_subfaces_equs:\n",
    "                        if np.trace(face_inters_sample_point @ wbs[ind].bis) < 0:\n",
    "                            face_conds[j] = face_subfaces_temp[0]      # If any side separates the sample point from the face -> 2 or 4\n",
    "                            break\n",
    "                else:                                                  # If the new hyperplane does not intersect the span of the face -> 2 or 4\n",
    "                    face_conds[j] = face_subfaces_temp[0]\n",
    "\n",
    "    ind_remove_list = [j for j in range(len(face_conds)) if face_conds[j] in [4, 5]]\n",
    "    for j in sorted(ind_remove_list, reverse=True):     # Faces of type 4 or 5: will be deleted\n",
    "        del faces[j]\n",
    "        del face_conds[j]\n",
    "    for j in range(len(face_conds)):                    # The presence of these faces as subfaces of the other is also erased.\n",
    "        faces[j].subfaces = [ind for ind in faces[j].subfaces if ind not in ind_remove_list]\n",
    "        List_subfaces_temp = []\n",
    "        for ind in faces[j].subfaces:\n",
    "            decrease = sum(1 for val in ind_remove_list if val < ind)\n",
    "            List_subfaces_temp.append(ind - decrease)\n",
    "        faces[j].subfaces = List_subfaces_temp.copy()\n",
    "    for j in range(len(face_conds)):                    # Faces of type 1: the new equation will be added\n",
    "        if face_conds[j] == 1:\n",
    "            faces[j].equs.append(len(wbs))\n",
    "        elif face_conds[j] == 6:                        # Faces of type 6\n",
    "            new_face_equs = faces[j].equs + [len(wbs)]  # a new face will born\n",
    "            new_face_codim = faces[j].codim + 1         # Codimension of the new face\n",
    "            new_face_subfaces = [ind for ind in faces[j].subfaces if face_conds[ind] == 1]\n",
    "            for ind in faces[j].subfaces:\n",
    "                if ind < len(face_conds):\n",
    "                    if face_conds[ind] == 6:\n",
    "                        faces[j].subfaces.append(faces[ind].subfaces[-1])\n",
    "                        new_face_subfaces.append(faces[ind].subfaces[-1])\n",
    "            faces[j].subfaces.append(len(faces))        # Subfaces for both old and new faces\n",
    "            if len(new_face_subfaces) == 0:             # Sample point for the new face\n",
    "                face_equs = [wbs[ind].bis for ind in faces[j].equs]\n",
    "                new_face_sample_point = find_feasible_point(face_equs + [new_wb.bis])\n",
    "            elif len(new_face_subfaces) >= 2:           # >=2 subfaces: barycenter\n",
    "                new_face_sample_point = sum((faces[ind].sample_point for ind in new_face_subfaces), np.zeros((3, 3)))\n",
    "                new_face_sample_point = new_face_sample_point/((det(new_face_sample_point)) ** (1/3))\n",
    "            else:                                       # Exactly 1 subface: pertube the sample point of the subface\n",
    "                face_equs = [wbs[ind].bis for ind in faces[j].equs]\n",
    "                subface_equ_ind = next((ind for ind in faces[new_face_subfaces[0]].equs if ind not in set(new_face_equs)), None)\n",
    "                subface_equ = wbs[subface_equ_ind].bis\n",
    "                subface_sample_point = faces[new_face_subfaces[0]].sample_point\n",
    "                new_face_sample_point = perturb_within_plane(subface_sample_point, face_equs + [new_wb.bis], subface_equ)\n",
    "            if np.trace(faces[j].sample_point @ new_wb.bis) < np.sqrt(a_tol):   # Sample point for the old face: pertube the sample point of the new face\n",
    "                face_equs = [wbs[ind].bis for ind in faces[j].equs]\n",
    "                old_face_sample_point = perturb_within_plane(new_face_sample_point, face_equs, new_wb.bis)\n",
    "                while any(ind not in faces[j].equs and np.trace(wb.bis @ faces[j].sample_point) > a_tol\\\n",
    "                          and np.trace(wb.bis @ old_face_sample_point) < a_tol for ind, wb in enumerate(wbs)): # Check if this point is inside the polytope\n",
    "                    old_face_sample_point = 0.5*(old_face_sample_point + new_face_sample_point)\n",
    "                temporary_sample_point = 0.5*(old_face_sample_point + new_face_sample_point)\n",
    "                temporary_sample_point = temporary_sample_point/((det(temporary_sample_point)) ** (1/3))\n",
    "                faces[j].sample_point = temporary_sample_point\n",
    "            faces.append(Poly_Face(new_face_equs, new_face_codim, new_face_subfaces, np.array(new_face_sample_point)))  # Save the new face to faces\n",
    "    wbs.append(new_wb)                                                           # Save the new equation to bises_active\n",
    "\n",
    "    equ_remove_list = list(range(len(wbs)))                                      # Remove the unnecessary equations\n",
    "    for j in range(len(faces)):\n",
    "        if faces[j].codim == 1:\n",
    "            equ_remove_list = [ind for ind in equ_remove_list if ind != faces[j].equs[0]]\n",
    "    for j in sorted(equ_remove_list, reverse=True):\n",
    "        del wbs[j]\n",
    "    for j in range(len(faces)):\n",
    "        faces[j].equs = [ind for ind in faces[j].equs if ind not in equ_remove_list]\n",
    "        List_equs_temp = []\n",
    "        for ind in faces[j].equs:\n",
    "            decrease = sum(1 for val in equ_remove_list if val < ind)\n",
    "            List_equs_temp.append(ind - decrease)\n",
    "        faces[j].equs = List_equs_temp.copy()\n",
    "    faces_indexed = [(i, face) for i, face in enumerate(faces)]\n",
    "    faces_indexed.sort(key=lambda obj: obj[1].codim, reverse=True)                # Sort the faces by their dimension (small to large)\n",
    "    index_mapping = {old_index: new_index for new_index, (old_index, _) in enumerate(faces_indexed)}\n",
    "    for _, face in faces_indexed:\n",
    "        face.subfaces = [index_mapping[ind] for ind in face.subfaces]\n",
    "    faces = [face for _, face in faces_indexed]\n",
    "    return wbs, faces\n",
    "\n",
    "def are_faces_paired(wbs, faces, i_old, i_new, isom):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    faces: list of Poly_Face\n",
    "    i_old: int\n",
    "    i_new: int\n",
    "    isom: np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    are_paired: bool\n",
    "        True if the facet indexed `i_old` and `i_new` are paired by word `isom`.\n",
    "    \"\"\"\n",
    "    if faces[i_old].codim != faces[i_new].codim:\n",
    "        return False\n",
    "    if len(faces[i_old].subfaces) != len(faces[i_new].subfaces):\n",
    "        return False\n",
    "    old_face_equations = [wbs[ind].bis for ind in faces[i_old].equs]\n",
    "    new_face_equations = [wbs[ind].bis for ind in faces[i_new].equs]\n",
    "    if not maps_plane_equal(old_face_equations, new_face_equations, isom):\n",
    "        return False\n",
    "    if len(faces[i_old].subfaces) == 0:\n",
    "        return True\n",
    "    cod = faces[i_old].codim\n",
    "    old_facets = [j for j in faces[i_old].subfaces if faces[j].codim == cod + 1]\n",
    "    new_facets = [k for k in faces[i_new].subfaces if faces[k].codim == cod + 1]\n",
    "    if len(old_facets) != len(new_facets):\n",
    "        return False\n",
    "    for j in old_facets:\n",
    "        if not any(are_faces_paired(wbs, faces, j, k, isom) for k in new_facets):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_unpaired_ridges(wbs, faces):\n",
    "    \"\"\"\n",
    "    Return the list of ridge indices with associated facet indices that remain unpaired in the current (pre-exact) Dirichlet-Selberg domain.\n",
    "    Parameters\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    faces: list of Poly_Face\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    unpaired_ridges: list of [int, int]\n",
    "    \"\"\"\n",
    "    facet_indices = [i for i in range(len(faces)) if faces[i].codim == 1]\n",
    "    unpaired_ridges = []\n",
    "    for i in facet_indices:\n",
    "        i_ridges = [j for j in faces[i].subfaces if faces[j].codim == 2]\n",
    "        i_pair = next((i_0 for i_0 in facet_indices if np.all(np.abs(wbs[faces[i].equs[0]].word @ wbs[faces[i_0].equs[0]].word\\\n",
    "                                                                     - np.eye(3))<a_tol)), None)\n",
    "        if i_pair != None:\n",
    "            i_pair_ridges = [j_0 for j_0 in faces[i_pair].subfaces if faces[j_0].codim == 2]\n",
    "            for j in i_ridges:\n",
    "                j_equations = [wbs[ind].bis for ind in faces[j].equs]\n",
    "                j_pair = next((j_0 for j_0 in i_pair_ridges if maps_plane_equal(j_equations,\\\n",
    "                                        [wbs[ind].bis for ind in faces[j_0].equs],wbs[faces[i].equs[0]].word)), None)\n",
    "                if j_pair is None:\n",
    "                    mat = (wbs[faces[i].equs[0]].word).T @ faces[j].sample_point @ wbs[faces[i].equs[0]].word\n",
    "                    if all(np.trace(mat @ wbs[ind].bis)> a_tol for ind in range(len(wbs)) if ind not in faces[i_pair].equs):\n",
    "                        unpaired_ridges.append([i, j])\n",
    "    return unpaired_ridges\n",
    "\n",
    "def find_path_word(wbs, faces, dest):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    faces: list of Poly_Face\n",
    "    dest: np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    path_word: list of int\n",
    "        The product of facet pairings of indices in `path_word` takes `dest` into the Dirichlet‐Selberg domain.\n",
    "    \"\"\"\n",
    "    if not is_positive_definite(dest):\n",
    "        raise ValueError(\"find_path_word: destination point must be positive definite.\")\n",
    "    dest = dest/(det(dest) ** (1/3))                            # Normalize the destination point\n",
    "    center = next(face.sample_point for face in faces if face.codim == 0)  # The center is the sample point of the polytope itself\n",
    "    if all(np.trace(dest @ wb.bis)>-a_tol for wb in wbs):                  # If the destination is already in the Dirichlet-Selberg domain\n",
    "        return []\n",
    "    meet_ind = max(range(len(wbs)), key = lambda i: -(np.trace(dest @ wbs[i].bis))/(np.trace(center @ wbs[i].bis)))\n",
    "    meet_word = wbs[meet_ind].word                                             # The word corresponding to the first bisector meeting the ray from the center towards the destination\n",
    "    new_dest = meet_word.T @ dest @ meet_word                               # Take the destination closer to the center\n",
    "    new_path = find_path_word(wbs, faces, new_dest)\n",
    "    new_path.insert(0, meet_ind)\n",
    "    return new_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core Solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_bisectors(gens, max_length, center):\n",
    "    \"\"\"\n",
    "    For each non‐trivial word w (|w|≤max_length) in the group generated by `gens` that moves `center`, compute the bisector Bis(center, w.center).\n",
    "    Parameters\n",
    "    ----------\n",
    "    gens: list of np.ndarray\n",
    "    max_length: int\n",
    "    center: np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    \"\"\"\n",
    "    words = distinct_matrix_products(gens, max_length)\n",
    "    wbs = [Word_Bis(word, np.array(word) @ inv(np.array(center)) @ np.array(word).T - inv(np.array(center)))\\\n",
    "           for word in words]                                                # Definition of Selberg bisectors\n",
    "    wbs_filtered = [wb for wb in wbs if not np.all(np.abs(wb.bis)<a_tol)]      # Exclude bisectors with zero normal matrices\n",
    "    return wbs_filtered\n",
    "\n",
    "def compute_selberg_domain(gens, center, length_1, length_2 = None, max_loops = 0):\n",
    "    \"\"\"\n",
    "    Build the Dirichlet‐Selberg domain: first extend all words up to `length_1`, then iteratively pair ridges using words up to `length_2`, for at most `max_loops`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    gens: list of np.ndarray\n",
    "    center: np.ndarray\n",
    "    length_1: int\n",
    "    length_2: int\n",
    "    max_loops: int\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    faces: list of Poly_Face\n",
    "    \"\"\"\n",
    "    if length_2 is None:\n",
    "        length_2 = length_1\n",
    "    wbs_1 = compute_word_bisectors(gens, length_1, center)\n",
    "    wbs_2 = compute_word_bisectors(gens, length_2, center)\n",
    "    wbs = []                                           # Initialize the word-bisectors used in the polytope\n",
    "    faces = [Poly_Face([], 0, [], np.array(center))]     # Initialize the polytope, which is just the entire space X_3\n",
    "    for i in tqdm(range(len(wbs_1)), desc =\"Adding words to the Dirichlet-Selberg domain\"):\n",
    "        wbs, faces = add_facet_to_domain(wbs, faces, wbs_1[i]) # Add the i-th word-bisector to the polytope\n",
    "    for _ in tqdm(range(max_loops), desc =\"Adding more words to eliminate unpaired ridges\"):\n",
    "        unpaired_ridges = find_unpaired_ridges(wbs, faces)\n",
    "        if not unpaired_ridges:                           # Stop searching if all ridges are paired\n",
    "            break\n",
    "        else:\n",
    "            facet_indices = [i for i in range(len(faces)) if faces[i].codim == 1]\n",
    "            min_dist = np.inf\n",
    "            new_wb = None                                     # Searching for the candidate bisector closest to the origin\n",
    "            for i, j in unpaired_ridges:\n",
    "                i_pair = next((i_0 for i_0 in facet_indices if np.all(np.abs(wbs[faces[i].equs[0]].word @ wbs[faces[i_0].equs[0]].word\\\n",
    "                                                                     - np.eye(3))<a_tol)), None)\n",
    "                j_equations = [wbs[ind].bis for ind in faces[j].equs]\n",
    "                i_pair_equation = wbs[faces[i_pair].equs[0]].bis\n",
    "                for k in range(len(wbs_2)):\n",
    "                    if np.trace(wbs_2[k].bis @ np.array(center)) < min_dist:\n",
    "                        candidate_equations = [i_pair_equation, wbs_2[k].bis]\n",
    "                        if maps_plane_equal(j_equations, candidate_equations, wbs[faces[i].equs[0]].word):\n",
    "                            min_dist = np.trace(wbs_2[k].bis @ np.array(center))\n",
    "                            new_wb = wbs_2[k]              # Update the desired bisector if a smaller distance is detected\n",
    "            if new_wb is not None:\n",
    "                wbs, faces = add_facet_to_domain(wbs, faces, new_wb)\n",
    "    return wbs, faces\n",
    "\n",
    "def polytope_exactness(wbs, faces):\n",
    "    \"\"\"\n",
    "    If the domain is exact, return a dict: {\"facet indices\": [], \"paired_indices\": []}, else return None.\n",
    "    Parameters\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    faces: list of Poly_Face\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    pairing_dict: dict of int\n",
    "    \"\"\"\n",
    "    facet_indices = [i for i in range(len(faces)) if faces[i].codim == 1] # Get a list of facets\n",
    "    pairing_dict = {}\n",
    "    for i in facet_indices:\n",
    "        i_pair = next((j for j in facet_indices if are_faces_paired(wbs, faces,\\\n",
    "                                                                  i, j, wbs[faces[i].equs[0]].word)), None)\n",
    "        if i_pair is None:\n",
    "            return None                                           # False if facets are not paired\n",
    "        else:\n",
    "            pairing_dict[i] = i_pair\n",
    "    return pairing_dict                                          # Corresponding facets are canonically paired\n",
    "\n",
    "def compute_ridge_cycles(wbs, faces):\n",
    "    \"\"\"\n",
    "    For an exact polytope, return a list of ridge cycles.\n",
    "    Parameters\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    faces: list of Poly_Face\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    ridge_cycles: list of Ridge_Cycle\n",
    "    \"\"\"\n",
    "    pairing_dict = polytope_exactness(wbs, faces)\n",
    "    if pairing_dict is None:                  # Ridges cycles are defined only for exact polytopes \n",
    "        return None\n",
    "    facet_indices = list(pairing_dict)\n",
    "    all_ridge_indices = [i for i in range(len(faces)) if faces[i].codim == 2]\n",
    "    ridge_cycles = []                                        # Initialize the list of ridge cycles\n",
    "    for i in facet_indices:\n",
    "        ridge_indices = [j for j in faces[i].subfaces if j in all_ridge_indices]\n",
    "        for j in ridge_indices:                                  # Consider the index pair for a facet and a ridge of it\n",
    "            if any(j in ridge_cycle.ridge for ridge_cycle in ridge_cycles):\n",
    "                continue                                         # Case if it is already in a ridge cycle\n",
    "            current_ridge = j\n",
    "            current_facet = i                                # Chasing the ridges along the cycle\n",
    "            current_pairing = faces[current_facet].equs[0]\n",
    "            ridge_cycle = Ridge_Cycle([current_ridge], [current_pairing])\n",
    "            for _ in range(2*len(all_ridge_indices)):        # Ridge cycles will not be too long\n",
    "                mapped_facet = pairing_dict[current_facet]\n",
    "                new_ridge_indices = [new_j for new_j in faces[mapped_facet].subfaces if new_j in all_ridge_indices]\n",
    "                new_ridge = next((new_j for new_j in new_ridge_indices if \\\n",
    "                                    are_faces_paired(wbs, faces, current_ridge, new_j, wbs[current_pairing].word)), None)\n",
    "                new_facet = next(new_i for new_i in facet_indices if new_ridge in faces[new_i].subfaces and new_i != mapped_facet)\n",
    "                new_pairing = faces[new_facet].equs[0]\n",
    "                if new_ridge == ridge_cycle.ridge[0] and new_pairing == ridge_cycle.pairing[0]:\n",
    "                    ridge_cycles.append(ridge_cycle)      # Add the ridge cycle to ridge_cycles if a full cycle is obtained\n",
    "                    break\n",
    "                ridge_cycle.ridge.append(new_ridge)       # Shift to the next ridge and facet if the cycle is not completed\n",
    "                ridge_cycle.pairing.append(new_pairing)\n",
    "                current_ridge = new_ridge\n",
    "                current_facet = new_facet\n",
    "                current_pairing = new_pairing\n",
    "    return ridge_cycles\n",
    "\n",
    "def compute_angle_sum(wbs, faces, ridge_cycle):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    faces: list of Poly_Face\n",
    "    ridge_cycle: Ridge_Cycle\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    angle_sum_quotient: Optional[int]\n",
    "        Return k if the angle sum around `ridge_cycle` is 2π/k; else None.\n",
    "    \"\"\"\n",
    "    angle_sum = 0                                           # Initialize the angle sum\n",
    "    point = faces[ridge_cycle.ridge[0]].sample_point # The base point of the first ridge is selected to be the given sample point\n",
    "    for i in range(len(ridge_cycle.ridge)):\n",
    "        first_bis = faces[ridge_cycle.ridge[i]].equs[0]\n",
    "        second_bis = faces[ridge_cycle.ridge[i]].equs[1]\n",
    "        angle = riemannian_angle(wbs[first_bis].bis, wbs[second_bis].bis, point) # Compute the Riemannian angle between the bisectors\n",
    "        angle_sum = angle_sum + angle                       # Add this to the angle sum\n",
    "        word = wbs[ridge_cycle.pairing[i]].word          \n",
    "        point = word.T @ point @ word                       # Shift to the paired base point of the next ridge\n",
    "    quotient = 2*np.pi/angle_sum                            # Check if the quotient of the angle sum with 2pi is a natural number\n",
    "    angle_sum_quotient = round(quotient)\n",
    "    if abs(quotient - angle_sum_quotient)> 100*a_tol:\n",
    "        return None\n",
    "    else:\n",
    "        return angle_sum_quotient\n",
    "\n",
    "def is_word_recovered(wbs, faces, isom):\n",
    "    \"\"\"\n",
    "    Check if the group element `isom` is realized by a facet pairing in the domain.\n",
    "    Parameters\n",
    "    ----------\n",
    "    wbs: list of Word_Bis\n",
    "    faces: list of Poly_Face\n",
    "    isom: np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    is_recovered: bool\n",
    "    \"\"\"\n",
    "    isom = isom/(det(isom)**(1/3))\n",
    "    center = next(face.sample_point for face in faces if face.codim == 0)  # The center is the sample point of the polytope itself\n",
    "    dest_point = isom.T @ center @ isom\n",
    "    word = find_path_word(wbs, faces, dest_point)\n",
    "    for ind in word:\n",
    "        isom = isom @ wbs[ind].word\n",
    "    if np.all(np.abs(isom - np.eye(3))<a_tol):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo Program: A congruence subgroup of level-two in SL(3,Z) (may take several minutes to finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bc29f581ca444b89947c7e8c25a392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding words to the Dirichlet-Selberg domain:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/cvxpy/problems/problem.py:1510: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25833bb09192445297b57c0274469504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding more words to eliminate unpaired ridges:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generators = []\n",
    "for i, j in itertools.permutations(range(3), 2):\n",
    "    generator = np.eye(3)\n",
    "    generator[i, j] = 2\n",
    "    generators.append(generator)\n",
    "center = np.eye(3)\n",
    "wbs, faces = compute_selberg_domain(generators, center, 1, 2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo Program: A lattice group in SL(3,Z[1/2]) with 5-simplex fundamental domain (quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8160d164d24d44c4bca93feffc3fd25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding words to the Dirichlet-Selberg domain:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c5c0a511f147c185b1c17ffbf1a87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding more words to eliminate unpaired ridges:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = np.array([[1/2, 1/2, 0],\n",
    "        [1/2, -1/2, 1],\n",
    "        [1/2, -1/2, -1]])\n",
    "generators = [generator, generator[[1, 2, 0]][:, [1, 2, 0]]]\n",
    "center = np.eye(3)\n",
    "wbs, faces = compute_selberg_domain(generators, center, 1, 2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of facets: 6\n",
      "Number of ridges: 15\n",
      "Number of peaks: 16\n",
      "Number of edges: 0\n",
      "Number of vertices: 0\n",
      "Cycle 0: ridge indices=[16, 17, 21], angle‑sum divisor=2\n",
      "Cycle 1: ridge indices=[19, 24, 27], angle‑sum divisor=2\n",
      "Cycle 2: ridge indices=[22, 28, 30], angle‑sum divisor=2\n",
      "Cycle 3: ridge indices=[26, 18, 25], angle‑sum divisor=1\n",
      "Cycle 4: ridge indices=[20, 29, 23], angle‑sum divisor=2\n",
      "Generator #0 is recovered via pairings [2]\n",
      "Generator #1 is recovered via pairings [3]\n"
     ]
    }
   ],
   "source": [
    "# 1) Count faces by codimension\n",
    "for codim, name in [(1,\"facets\"), (2,\"ridges\"), (3,\"peaks\"), (4,\"edges\"), (5,\"vertices\")]:\n",
    "    count = sum(1 for f in faces if f.codim == codim)\n",
    "    print(f\"Number of {name}: {count}\")\n",
    "\n",
    "# 2) Exactness & ridge‑cycles\n",
    "pairing_dict = polytope_exactness(wbs, faces)\n",
    "if pairing_dict is None:\n",
    "    print(\"Domain is NOT exact; increase word lengths.\")\n",
    "else:\n",
    "    cycles = compute_ridge_cycles(wbs, faces)\n",
    "    for i, cycle in enumerate(cycles):\n",
    "        k = compute_angle_sum(wbs, faces, cycle)\n",
    "        print(f\"Cycle {i}: ridge indices={cycle.ridge}, angle‑sum divisor={k}\")\n",
    "\n",
    "# 3) Generator recovery\n",
    "for i, gen in enumerate(generators):\n",
    "    if is_word_recovered(wbs, faces, gen):\n",
    "        path = find_path_word(wbs, faces, gen.T @ center @ gen)\n",
    "        print(f\"Generator #{i} is recovered via pairings {path}\")\n",
    "    else:\n",
    "        print(f\"Generator #{i} is NOT recovered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the sample points are taken correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max |tr(A·X)| on each face’s plane: 2.7755575615628914e-15\n",
      "Min  tr(A·X) off each face’s plane: 0.0875728471814019\n"
     ]
    }
   ],
   "source": [
    "# 1) Maximum absolute trace over each face's own bisectors\n",
    "max_on_plane = max(\n",
    "    abs(np.trace(wbs[i].bis @ face.sample_point))\n",
    "    for face in faces\n",
    "    for i    in face.equs\n",
    ")\n",
    "print(\n",
    "    \"Max |tr(A·X)| on each face’s plane:\", \n",
    "    max_on_plane\n",
    ")\n",
    "\n",
    "# 2) Minimum trace over all bisectors *not* defining that face\n",
    "all_indices = set(range(len(wbs)))\n",
    "min_off_plane = min(\n",
    "    np.trace(wbs[j].bis @ face.sample_point)\n",
    "    for face in faces\n",
    "    for j    in (all_indices - set(face.equs))\n",
    ")\n",
    "print(\n",
    "    \"Min  tr(A·X) off each face’s plane:\", \n",
    "    min_off_plane\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
