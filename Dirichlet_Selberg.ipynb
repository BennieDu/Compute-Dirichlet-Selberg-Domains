{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "from scipy.linalg import null_space\n",
    "from scipy.linalg import sqrtm\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tolerance for numerical computation\n",
    "# Set to 1e-10 by default\n",
    "tol = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data models\n",
    "@dataclass\n",
    "class Word_Bis:               # The class of bisectors in the symmetric space $X_3$. A list of Word_Bis models describes the bisectors defining the Dirichlet-Selber domain.\n",
    "    word: np.ndarray          # A matrix $g$ in $SL(3,R)$, typically a word in given generators\n",
    "    bis: np.ndarray           # A normal vector (as a 3*3 matrix) of the Selberg bisector $Bis(X, g.X)$\n",
    "\n",
    "@dataclass\n",
    "class Poly_Face:              # The class of faces of polytopes in $X_3$. A list of Poly_Face models describes the polytope structure of the Dirichlet-Selber domain.\n",
    "    equs: list[int]           # A list of bisectors indices (in the list of the accompanying Word_Bis models) whose intersection is the minimal plane containing the face.\n",
    "    codim: int                # The codimension (5 - dim) of the face.\n",
    "    subfaces: list[int]       # A list of face indices that are proper subfaces of the current face.\n",
    "    sample_point: np.ndarray  # A point in $X_3$ (as a 3*3 matrix) lying in the interior of the current face.\n",
    "\n",
    "@dataclass\n",
    "class Find_Intersection:      # The class describing if the union of certain $X_3$ hyperplanes is empty.\n",
    "    sample_point: np.ndarray  # A sample point of the intersection if non-empty, or the zero matrix if empty.\n",
    "    is_intersection: bool     # Boolean variable describing if the intersection is empty.\n",
    "\n",
    "@dataclass\n",
    "class Ridge_Cycles:           # The class describing a ridge-cycle of a Dirichlet-Selberg domain.\n",
    "    ridge: list[int]          # A list of ridge indices (in the list of the accompanying Poly_Face models), for ridges $r_0, r_1, r_2,...$ in the same ridge cycle.\n",
    "    pairing: list[int]        # A list of word indices (in the list of the accompanying Word_Bis models), each word $g_i$ sends $r_i$ to $r_{i+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Helper functions\n",
    "##################\n",
    "# Find the first element in the first list that is not in the second one\n",
    "def first_unique_element(list1, list2):\n",
    "    set2 = set(list2)  # Convert list2 to a set for fast lookup\n",
    "    for item in list1:\n",
    "        if item not in set2:\n",
    "            return item\n",
    "    return None        # Return None if no unique element is found\n",
    "\n",
    "# Remove elements from the current list if it exists in the preceding lists\n",
    "def remove_preceding_elements(current_list, preceding_lists):\n",
    "    preceding_set = {tuple(map(tuple, matrix)) for lst in preceding_lists for matrix in lst}\n",
    "    return [matrix for matrix in current_list if tuple(map(tuple, matrix)) not in preceding_set]\n",
    "\n",
    "# Remove duplicate matrices from the list. This may need to be rewritten for a tolerance argument.\n",
    "def remove_duplicates(matrices):\n",
    "    unique_matrices = []\n",
    "    for matrix in matrices:\n",
    "        if not any(np.array_equal(matrix, unique_matrix) for unique_matrix in unique_matrices):\n",
    "            unique_matrices.append(matrix)\n",
    "    return unique_matrices\n",
    "    \n",
    "# Check if the new vector is linearly independent to a independent set of vectors (with tolerance)\n",
    "def is_linearly_independent(vectors, new_vector):\n",
    "    if len(vectors) == 0:\n",
    "        return np.linalg.norm(new_vector) > tol               # The first vector (if nonzero) is independent on its own\n",
    "    matrix = np.array(vectors).T                              # Stack the current independent vectors into a matrix, so each column is a vector    \n",
    "    projection = matrix @ np.linalg.pinv(matrix) @ new_vector # Compute the projection of the new vector onto the space spanned by the existing vectors\n",
    "    residual = new_vector - projection                        # Compute the difference (residual) between the new vector and its projection\n",
    "    return np.linalg.norm(residual) > tol                     # The new vector is dependent to the existing ones if the residual is smaller than the threshold\n",
    "\n",
    "# Return a linearly independent subset of vectors (with tolerance)\n",
    "def linearly_independent_subset(vectors):\n",
    "    indep_vectors = []\n",
    "    for vector in vectors:\n",
    "        if is_linearly_independent(indep_vectors, vector):\n",
    "            indep_vectors.append(vector)\n",
    "    return indep_vectors\n",
    "    \n",
    "# Check if a symmetric matrix (in np.array) is positive definite. Return true if it is, false if it may not be (concerning the tolerance).\n",
    "def is_positive_definite(matrix):\n",
    "    if not isinstance(matrix, np.ndarray):\n",
    "        raise ValueError(\"Input must be a numpy array.\")\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        return False                                  # The matrix is not square\n",
    "    try:\n",
    "        min_diag = np.min(np.linalg.eigvalsh(matrix)) # Find the smallest eigenvalue\n",
    "        return min_diag > tol                         # Positive definite if it is positive (concerning the tolerance).\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False                                  # Not positive definite\n",
    "\n",
    "# Converting between symmetric 3*3 matrices and 6-dimensional vectors\n",
    "def word_to_vector(word):\n",
    "    vector = [word[0][0],word[1][1],word[2][2],word[0][1],word[0][2],word[1][2]]\n",
    "    return vector\n",
    "def word_to_vector_new(word):\n",
    "    vector = [word[0][0],word[1][1],word[2][2],np.sqrt(2) * word[0][1],np.sqrt(2) * word[0][2],np.sqrt(2) * word[1][2]]\n",
    "    return vector\n",
    "def vector_to_word(vector):\n",
    "    word = np.array([[vector[0], vector[3]/2, vector[4]/2],\n",
    "                     [vector[3]/2, vector[1], vector[5]/2],\n",
    "                     [vector[4]/2, vector[5]/2, vector[2]]])\n",
    "    return word\n",
    "\n",
    "# Find the orthogonal complement of 3*3 symmetric matrices, with respect to the product trace.\n",
    "def orth_matrix(matrices):\n",
    "    vectors = [word_to_vector(matrix) for matrix in matrices]\n",
    "    vectors = linearly_independent_subset(vectors)\n",
    "    orth_vectors = null_space(np.array(vectors)).T.tolist()\n",
    "    orth_matrices = [np.array(vector_to_word(orth_vector)) for orth_vector in orth_vectors]\n",
    "    return orth_matrices\n",
    "\n",
    "# Convert a matrix of linear expressions in sympy to cvxpy for convex optimization purposes.\n",
    "def sp_to_cp(M_sym, variables):\n",
    "    free_syms = variables\n",
    "    n_vars = len(free_syms)\n",
    "    rows, cols = M_sym.shape                                                                # Get the matrix shape\n",
    "    coeff_matrices = [np.zeros((rows, cols), dtype=np.float64) for _ in range(n_vars + 1)]  # Initialize the coefficient matrices\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):                 \n",
    "            expr = sp.expand(M_sym[i, j])                                                   # Decompose the matrix into entries\n",
    "            if expr.is_Add:                 \n",
    "                terms = expr.as_ordered_terms()                                             # Convert the entry into a list of summands\n",
    "            else:\n",
    "                terms = [expr]                                                              # Simply wrap the entry if it is a single term\n",
    "            for term in terms:\n",
    "                found = False\n",
    "                for idx, sym in enumerate(free_syms):\n",
    "                    if term.has(sym):\n",
    "                        coeff = term.coeff(sym)\n",
    "                        coeff_matrices[idx + 1][i, j] = float(coeff)                        # Add the coefficient of a certain variable to the corresponding matrix\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    coeff_matrices[0][i, j] = float(term)                                   # Add the constant term to the zeroth matrix\n",
    "    x_cvx = cp.Variable(n_vars)                                                             # Define the cvxpy variables\n",
    "    M_cvx = coeff_matrices[0] + sum(x_cvx[i]*coeff_matrices[i+1] for i in range(n_vars))    # Combine the coefficient matrices into a cvxpy matrix with variables\n",
    "    return M_cvx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question-specific helper functions\n",
    "\n",
    "# Compute a basis of vectors perpendicular to a given 3-dimensional vector.\n",
    "# Specifically, given an indefinite vector, the first output vector is positive definite, while the second output vector is indefinite.\n",
    "def compute_vector(d):\n",
    "    positive_indices = [i for i, x in enumerate(d) if x > tol]\n",
    "    negative_indices = [i for i, x in enumerate(d) if x < -tol]\n",
    "    if not positive_indices or not negative_indices:\n",
    "        return None, None                 # Our program does not focus on definite input vectors\n",
    "    positive_index = positive_indices[0]  # Find the first positive component index of the vector\n",
    "    negative_index = negative_indices[0]  # Find the first negative component index of the vector\n",
    "    d_sorted = [0, 0, 0]                  # Rearrange the components of the vector into (pos, neg, rest)\n",
    "    d_sorted[0] = d[positive_index]       # The positive one becomes d0\n",
    "    d_sorted[1] = d[negative_index]       # The negative one becomes d1\n",
    "    d_sorted[2] = d[3 - positive_index - negative_index] # The remaining becomes d2\n",
    "    d0, d1, d2 = d_sorted\n",
    "    if d2<0:                              # Compute the perpendicular vectors in the new order\n",
    "        v = [-d1/(np.sqrt(d0**2 + d1**2)) - d2/(np.sqrt(d0**2 + d2**2)), d0/(np.sqrt(d0**2 + d1**2)), d0/(np.sqrt(d0**2 + d2**2))]\n",
    "        w = [-d1/(np.sqrt(d0**2 + d1**2)) + d2/(np.sqrt(d0**2 + d2**2)), d0/(np.sqrt(d0**2 + d1**2)), -d0/(np.sqrt(d0**2 + d2**2))]\n",
    "    else:\n",
    "        v = [-d1/(np.sqrt(d0**2 + d1**2)), d0/(np.sqrt(d0**2 + d1**2)) + d2/(np.sqrt(d1**2 + d2**2)), -d1/(np.sqrt(d1**2 + d2**2))]\n",
    "        w = [-d1/(np.sqrt(d0**2 + d1**2)), d0/(np.sqrt(d0**2 + d1**2)) - d2/(np.sqrt(d1**2 + d2**2)), d1/(np.sqrt(d1**2 + d2**2))]\n",
    "    v_original_order = [0, 0, 0]          # Permute the vector back to the original order\n",
    "    v_original_order[positive_index] = v[0]\n",
    "    v_original_order[negative_index] = v[1]\n",
    "    v_original_order[3 - positive_index - negative_index] = v[2]\n",
    "    w_original_order = [0, 0, 0]\n",
    "    w_original_order[positive_index] = w[0]\n",
    "    w_original_order[negative_index] = w[1]\n",
    "    w_original_order[3 - positive_index - negative_index] = w[2]\n",
    "    return v_original_order, w_original_order\n",
    "\n",
    "# Use convex optimization to find positive definite combination of certain 3*3 symmetric matrices\n",
    "def find_pos_def(mat_expr, variables):\n",
    "    t = cp.Variable()\n",
    "    l = len(variables)\n",
    "    x = cp.Variable(l)\n",
    "    M = sp_to_cp(mat_expr, variables)                     # The combination of certain matrices\n",
    "    constraints = [M - t*np.eye(3) >> 0, x >= -1, x <= 1] # Our question only concerns coefficients lying between -1 and 1\n",
    "    prob = cp.Problem(cp.Maximize(t), constraints)        # Find maximal t such that M-tI is positive definite\n",
    "    prob.solve(solver=cp.SCS,eps=tol,max_iters=50000)     # Add verbose=True if needed\n",
    "    if prob.value > 100*tol:\n",
    "        return M.value                                    # The positive definite linear combination with maximized least eigenvalue\n",
    "    else:\n",
    "        return None                                       # No positive definite linear combinations\n",
    "\n",
    "# Compute the Riemannian angle between two hyperplanes (represented by normal vectors) in X_3 at a certain base point\n",
    "# The formula is given in my paper\n",
    "def Riemannian_angle(equ_1, equ_2, mat):\n",
    "    comp_1 = mat @ equ_1\n",
    "    comp_2 = mat @ equ_2\n",
    "    angle_cos = - (np.trace(comp_1 @ comp_2))/(np.sqrt((np.trace(comp_1 @ comp_1)) * (np.trace(comp_2 @ comp_2))))\n",
    "    angle = np.arccos(angle_cos)\n",
    "    return angle\n",
    "\n",
    "# Find a positive definite matrix on the elongation of the line from the first matrix to the second one\n",
    "def elongate(matrix_1, matrix_2):\n",
    "    matrix_1 = np.array(matrix_1)\n",
    "    matrix_2 = np.array(matrix_2)\n",
    "    if not is_positive_definite(matrix_2):\n",
    "        raise ValueError(\"elongate: Input must be positive definite.\")\n",
    "    else:\n",
    "        matrix = 2*matrix_2 - matrix_1            # The elongation\n",
    "        while not is_positive_definite(matrix):   # Go back toward matrix_2 if matrix is indefinite\n",
    "            matrix = 0.5*matrix + 0.5*matrix_2\n",
    "        matrix = matrix/((det(matrix)) ** (1/3))  # Unitize the matrix with respect to the determinant\n",
    "        return np.array(matrix)\n",
    "\n",
    "# The input positive definite matrix lies on the plane defined by some equations as well as a new equation\n",
    "# Perturb it to the positive side of the hyperplane defined by the new equation while remaining positive definite and lying on the plane defined by the old equations\n",
    "def perturb_within_plane(matrix, equations, new_equation):\n",
    "    matrix = np.array(matrix)                                                           # make the matrices numpy for safety reason\n",
    "    equations = [np.array(equation) for equation in equations]\n",
    "    new_equation = np.array(new_equation)\n",
    "    if not is_positive_definite(matrix):\n",
    "        raise ValueError(\"perturb_within_plane: Input must be positive definite.\")\n",
    "    else:\n",
    "        matrix_sqrt = sqrtm(matrix)                                                     # Congruence so the input matrix is taken to the origin\n",
    "        equations_trans = [matrix_sqrt @ equ @ matrix_sqrt for equ in equations]\n",
    "        new_equation_trans = matrix_sqrt @ new_equation @ matrix_sqrt\n",
    "        orth_equations = orth_matrix(equations_trans)\n",
    "        orth_vectors = [word_to_vector_new(equation) for equation in orth_equations]    # Convert from matrices to vectors\n",
    "        new_vector = word_to_vector_new(new_equation_trans)\n",
    "        orth_vectors_matrix = np.array(orth_vectors).T                                  # Stack the current independent vectors into a matrix, each column is a vector\n",
    "        coeffs = list(np.linalg.pinv(orth_vectors_matrix) @ new_vector)                 # Project the new vector to the existing ones\n",
    "        projection_trans = sum(coeff*equ for coeff, equ in zip(coeffs, orth_equations)) # This linear combination lies on the desired plane while keeps away from the new hyperplane\n",
    "        projection = matrix_sqrt @ projection_trans @ matrix_sqrt                       # Take the matrix back\n",
    "        while not is_positive_definite(projection):\n",
    "            projection = 0.5*projection + 0.5*matrix                                    # Go back toward the original matrix if the new one is indefinite\n",
    "        projection = projection/((det(projection)) ** (1/3))                            # Unitize the matrix with respect to the determinant\n",
    "        return projection\n",
    "\n",
    "# Check if the word in SL(3,R) takes the old plane (defined by a set of normal matrices) to the new plane\n",
    "def equal_spaces(old_equations, new_equations, word):\n",
    "    mapped_equations = [inv(word) @ mat @ inv(word.T) for mat in old_equations] # The normal matrices for the mapped plane\n",
    "    mapped_vectors = [word_to_vector(mat) for mat in mapped_equations]          # Convert from matrices to vectors\n",
    "    new_vectors = [word_to_vector(mat) for mat in new_equations]\n",
    "    rank_A = len(linearly_independent_subset(mapped_vectors))                   # Check if they define the same plane by a rank argument\n",
    "    rank_B = len(linearly_independent_subset(new_vectors))\n",
    "    rank_AplusB = len(linearly_independent_subset(mapped_vectors + new_vectors))\n",
    "    spans_equal = (rank_A == rank_AplusB) and (rank_B == rank_AplusB)\n",
    "    return spans_equal\n",
    "\n",
    "# Randomly generate a SL(3,R) matrix. Not actually occurs in the main function but may be useful.\n",
    "def random_SL3_qr():\n",
    "    A = np.random.randn(3,3) # Random matrix\n",
    "    Q, R = np.linalg.qr(A)   # Random orthogonal matrix by taking QR decomposition\n",
    "    if np.linalg.det(Q) < 0: # ensure Q has det +1 (not a reflection)\n",
    "        Q[:,0] *= -1\n",
    "    x = np.random.randn(3)    # Random diagonal matrix\n",
    "    x -= np.mean(x)           # Zero trace\n",
    "    D = np.diag(np.exp(x))    # Exponential so the diagonal matrix has unit determinant\n",
    "    return Q @ D              # Assemble the orthogonal matrix with the diagonal one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:17:40.137642Z",
     "iopub.status.busy": "2025-07-06T13:17:40.137335Z",
     "iopub.status.idle": "2025-07-06T13:17:45.105174Z",
     "shell.execute_reply": "2025-07-06T13:17:45.104228Z",
     "shell.execute_reply.started": "2025-07-06T13:17:40.137620Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.99 s, sys: 817 ms, total: 4.81 s\n",
      "Wall time: 4.89 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##########################\n",
    "# Second algorithm: the positive perpendicular vector\n",
    "\n",
    "##########################\n",
    "# Function to apply abs to coefficients but not the variables\n",
    "def apply_abs_to_coeffs(expr):\n",
    "    # Extract coefficients of x, y, z\n",
    "    coeff_dict = expr.as_coefficients_dict()\n",
    "    \n",
    "    # Create the new expression by applying abs to the coefficients\n",
    "    return sum(sp.Abs(coef) * var for var, coef in coeff_dict.items())\n",
    "##########################\n",
    "\n",
    "\n",
    "##########################\n",
    "\n",
    "##########################\n",
    "# Third algorithm: check linearly independence\n",
    "# Here we assume \"vectors\" is a linearly independent set\n",
    "\n",
    "##########################\n",
    "\n",
    "##########################\n",
    "\n",
    "######################\n",
    "# Third algorithm: find the positive definite one by dichotomy method\n",
    "# matrix is 3*3, linear, in term of the variables\n",
    "\n",
    "\n",
    "##########################\n",
    "# Finally: check if a set of hyperplanes in X_3 intersect\n",
    "def find_positive_definite_intersection(words):\n",
    "    ################## Part 1: Consider a linearly independent sublist\n",
    "    word_to_vector = [[word[0][0],word[1][1],word[2][2],word[0][1],word[0][2],word[1][2]] for word in words]\n",
    "    independent_vectors = []\n",
    "    for vec in word_to_vector:\n",
    "        if is_linearly_independent(independent_vectors, vec):# Check if the current vector is linearly independent based on previous ones\n",
    "            independent_vectors.append(vec)\n",
    "    indep_matrix = [[[vec[0],vec[3],vec[4]],\n",
    "                    [vec[3],vec[1],vec[5]],\n",
    "                    [vec[4],vec[5],vec[2]]] for vec in independent_vectors]\n",
    "    indep_matrix_np = [np.array(mat) for mat in indep_matrix]\n",
    "    indep_matrix_sp = [sp.Matrix(mat) for mat in indep_matrix]\n",
    "    ################### Part 2: The non-case\n",
    "    A = indep_matrix_np[0]\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(A)\n",
    "    ev_orth, ev_orth_neg = compute_vector(eigenvalues)\n",
    "    if ev_orth is None:\n",
    "        sample_point = np.zeros((3, 3)) \n",
    "        is_intersection = False\n",
    "    else:\n",
    "        n = len(indep_matrix)\n",
    "        Q = eigenvectors\n",
    "        D_orth = np.diag(ev_orth)\n",
    "    ################### Part 3: The case if n = 1\n",
    "        if n == 1:\n",
    "            sample_point = Q @ D_orth @ Q.T\n",
    "            is_intersection = True\n",
    "    ################### Part 4: The case if n > 1, we will begin canceling the variables\n",
    "        else:\n",
    "            linearized_matrix = [Q.T @ mat @ Q for mat in indep_matrix_np]\n",
    "            linearized_matrix_sp = [sp.Matrix(mat) for mat in linearized_matrix]\n",
    "            x_v = sp.symbols('x1:5')\n",
    "            x_v_new = x_v #The necessary variables\n",
    "            diag_max = [a + abs(b) for a, b in zip(ev_orth, ev_orth_neg)]\n",
    "            D_orth_neg = [np.diag(ev_orth_neg),\\\n",
    "                          np.array([[0, np.sqrt(diag_max[0]*diag_max[1]), 0],\n",
    "                                    [np.sqrt(diag_max[0]*diag_max[1]), 0, 0],\n",
    "                                    [0, 0, 0]]),\\\n",
    "                          np.array([[0, 0, np.sqrt(diag_max[0]*diag_max[2])],\n",
    "                                    [0, 0, 0],\n",
    "                                    [np.sqrt(diag_max[0]*diag_max[2]), 0, 0]]),\\\n",
    "                          np.array([[0, 0, 0],\n",
    "                                    [0, 0, np.sqrt(diag_max[1]*diag_max[2])],\n",
    "                                    [0, np.sqrt(diag_max[1]*diag_max[2]), 0]])]\n",
    "            D_orth_sp = sp.Matrix(D_orth)\n",
    "            D_orth_neg_sp = [sp.Matrix(mat) for mat in D_orth_neg]\n",
    "            matrix_comb = sum((var * mat for mat, var in zip(D_orth_neg_sp, x_v)), start=D_orth_sp)\n",
    "            # Remove extra variables\n",
    "            for i in range(1,n):\n",
    "                trace_matrix_prod = (matrix_comb * linearized_matrix_sp[i]).trace().expand()\n",
    "                trace_coeffs = {var: trace_matrix_prod.coeff(var) for var in x_v}\n",
    "                #If a nonzero constant appears, return to false since it is surely empty.\n",
    "                if all(abs(coeff) < tol for coeff in trace_coeffs.values()):\n",
    "                    sample_point = np.zeros((3, 3)) \n",
    "                    is_intersection = False\n",
    "                    return Find_Intersection(np.array(sample_point), is_intersection) \n",
    "                max_var = max(trace_coeffs, key=lambda v: abs(trace_coeffs[v]))\n",
    "                x_sol = sp.solve(trace_matrix_prod, max_var)[0]  # Solve f = 0 for max_var\n",
    "                x_v_new = tuple(var for var in x_v_new if var != max_var) # Drop max_var from x_v_new\n",
    "                matrix_comb = matrix_comb.subs(max_var,x_sol)\n",
    "            # If all variables are removed\n",
    "            if n == 5:\n",
    "                D = np.array(matrix_comb).astype(np.float64)\n",
    "                if is_positive_definite(D):\n",
    "                    sample_point = Q @ D @ Q.T\n",
    "                    is_intersection = True\n",
    "                else:\n",
    "                    sample_point = np.zeros((3, 3)) \n",
    "                    is_intersection = False\n",
    "            # Set the equations\n",
    "            else:\n",
    "                poly_comb = matrix_comb.det()\n",
    "                poly_comb_coeff = poly_comb.as_coefficients_dict()\n",
    "                all_zero = all(abs(coef) < tol for coef in poly_comb_coeff.values())\n",
    "                if all_zero:\n",
    "                    sample_point = np.zeros((3, 3)) \n",
    "                    is_intersection = False\n",
    "                else:\n",
    "                    D = find_pos_def(matrix_comb, x_v_new)\n",
    "                    if D is None:\n",
    "                        sample_point = np.zeros((3, 3)) \n",
    "                        is_intersection = False\n",
    "                    else:\n",
    "                        sample_point = Q @ D @ Q.T\n",
    "                        is_intersection = True\n",
    "    if is_intersection:\n",
    "        if not is_positive_definite(sample_point):\n",
    "            is_intersection = False\n",
    "            sample_point = np.zeros((3, 3))\n",
    "        else:\n",
    "            sample_point = sample_point/((det(sample_point)) ** (1/3))\n",
    "    return Find_Intersection(np.array(sample_point), is_intersection)\n",
    "################################################################\n",
    "\n",
    "# Function to remove elements appearing in preceding lists\n",
    "#################################################################\n",
    "# Compute all words from input\n",
    "def generator_to_words(generators, length):\n",
    "    A = [np.array(generator) for generator in generators]\n",
    "    n = length\n",
    "    k = len(A)\n",
    "    A_inv = [inv(matrix) for matrix in A]\n",
    "    A = A + A_inv\n",
    "    # List of words ending with each generator\n",
    "    word_A = [[matrix] for matrix in A]\n",
    "    # List of \"old\" words\n",
    "    old_A = [[] for matrix in A]\n",
    "    # List of \"all\" words\n",
    "    all_A = [[] for matrix in A]\n",
    "    # Beginning of the loop\n",
    "    for _ in range(n-1):\n",
    "        new_A = [[] for matrix in A]\n",
    "        for i in range(2*k):\n",
    "            for j in range(2*k):\n",
    "                if (j-i) % (2*k) != k:\n",
    "                    new_A[i] = new_A[i] + [matrix @ A[i] for matrix in word_A[j]]\n",
    "        for i in range(2*k):\n",
    "            old_A[i] = remove_duplicates(old_A[i] + word_A[i])\n",
    "            word_A[i] = remove_duplicates(new_A[i])\n",
    "        for i in range(2*k):\n",
    "            word_A[i] = remove_preceding_elements(word_A[i], old_A + word_A[:i])\n",
    "    for i in range(2*k):\n",
    "        all_A[i] = old_A[i] + word_A[i]\n",
    "    together_A = [matrix for matrix_list in all_A for matrix in matrix_list]\n",
    "    together_A.sort(key=lambda M: np.trace(M.T @ M))\n",
    "    return together_A\n",
    "#################################\n",
    "# Compute the equations for the bisector\n",
    "def word_bisectors(generators, length, center):\n",
    "    words = generator_to_words(generators, length)\n",
    "    wbs = [Word_Bis(word, np.array(word) @ inv(np.array(center)) @ np.array(word).T - inv(np.array(center)))\\\n",
    "           for word in words]\n",
    "    wbs_filtered = [wb for wb in wbs if not np.all(np.abs(wb.bis)<tol)]\n",
    "    return wbs_filtered\n",
    "################################\n",
    "# Both are positive definite\n",
    "\n",
    "####################################\n",
    "####################################\n",
    "# Find the perturbation of the matrix.\n",
    "# Presumably, the matrix is positive definite, and is normal to all old equations and the new equation.\n",
    "# Find a positive definite matrix, still normal to all old equations, but has a positive product with the new equation.\n",
    "\n",
    "####################################\n",
    "def selberg_domain_add_facet(wbs_active, List_faces, new_wb):\n",
    "    new_vec = word_to_vector(new_wb.bis)\n",
    "    # Assign to each face a case number\n",
    "    List_temp = [0]*len(List_faces)\n",
    "    # After each round, I will always sort the elements so their codimensions are small to large.\n",
    "    for j in range(len(List_temp)):\n",
    "        # If the equations defining F_j span the new equation\n",
    "        face_equs = [wbs_active[ind].bis for ind in List_faces[j].equs]\n",
    "        face_vecs = [word_to_vector(equ) for equ in face_equs]\n",
    "        if not is_linearly_independent(linearly_independent_subset(face_vecs), new_vec):\n",
    "            List_temp[j] = 1\n",
    "        # If the face is a minimal face. Since excellent me always sorts the faces, I can always check j from small to large.\n",
    "        elif List_faces[j].subfaces == []:\n",
    "            # if the new hyperplane intersects with the minimal face, it's type 6\n",
    "            if find_positive_definite_intersection(face_equs + [new_wb.bis]).is_intersection:\n",
    "                List_temp[j] = 6\n",
    "            # if the new hyperplane does not intersect with the minimal face, it's type 2 or 4\n",
    "            else:\n",
    "                face_sample_point = List_faces[j].sample_point\n",
    "                if np.trace(face_sample_point @ new_wb.bis) > 0:\n",
    "                    List_temp[j] = 2\n",
    "                else:\n",
    "                    List_temp[j] = 4\n",
    "        # If the face has subfaces.\n",
    "        else:\n",
    "            face_subfaces = List_faces[j].subfaces\n",
    "            face_subfaces_temp = [List_temp[ind] for ind in face_subfaces]\n",
    "            # If the type of either subface is 6.\n",
    "            if 6 in face_subfaces_temp:\n",
    "                List_temp[j] = 6\n",
    "            # If the type of a subface is 2 or 3, while which of the other subface is 4 or 5.\n",
    "            elif {2, 3} & set(face_subfaces_temp) and {4, 5} & set(face_subfaces_temp):\n",
    "                List_temp[j] = 6\n",
    "            # If the type of a subface is 1, 3, or 5.\n",
    "            elif {1, 3, 5} & set(face_subfaces_temp):\n",
    "                face_sample_point = List_faces[j].sample_point\n",
    "                if np.trace(face_sample_point @ new_wb.bis) > 0:\n",
    "                    List_temp[j] = 3\n",
    "                else:\n",
    "                    List_temp[j] = 5\n",
    "            # Types of all subfaces are 2, or are 4.\n",
    "            else:\n",
    "                # If the new hyperplane intersects the span of the face\n",
    "                if find_positive_definite_intersection(face_equs + [new_wb.bis]).is_intersection:\n",
    "                    # Sample point of this intersection\n",
    "                    face_inters_sample_point = find_positive_definite_intersection(face_equs + [new_wb.bis]).sample_point\n",
    "                    # Find out the equations shape the sides of the face \n",
    "                    face_subfaces_equs = []\n",
    "                    for ind in face_subfaces:\n",
    "                        if List_faces[ind].codim == List_faces[j].codim + 1:\n",
    "                            face_subfaces_equs_temp = [elem for elem in List_faces[ind].equs if elem not in List_faces[j].equs]\n",
    "                            face_subfaces_equs[:] = list(set(face_subfaces_equs) | set(face_subfaces_equs_temp))\n",
    "                    # Assume the type is 6\n",
    "                    List_temp[j] = 6\n",
    "                    for ind in face_subfaces_equs:\n",
    "                        # However, if any side separates the sample point from the face, the type is either 2 or 4\n",
    "                        if np.trace(face_inters_sample_point @ wbs_active[ind].bis) < 0:\n",
    "                            List_temp[j] = face_subfaces_temp[0]\n",
    "                            break\n",
    "                # If the new hyperplane does not intersect the span of the face, the type is either 2 or 4\n",
    "                else:\n",
    "                    List_temp[j] = face_subfaces_temp[0]\n",
    "    # If the face is of type 4 or 5, it will be deleted.\n",
    "    ind_remove_list = [j for j in range(len(List_temp)) if List_temp[j] in [4, 5]]\n",
    "    for j in sorted(ind_remove_list, reverse=True):\n",
    "        del List_faces[j]\n",
    "        del List_temp[j]\n",
    "    # The presence of these faces in subfaces is also erased.\n",
    "    for j in range(len(List_temp)):\n",
    "        List_faces[j].subfaces = [ind for ind in List_faces[j].subfaces if ind not in ind_remove_list]\n",
    "        List_subfaces_temp = []\n",
    "        for ind in List_faces[j].subfaces:\n",
    "            decrease = sum(1 for val in ind_remove_list if val < ind)\n",
    "            List_subfaces_temp.append(ind - decrease)\n",
    "        List_faces[j].subfaces = List_subfaces_temp.copy()\n",
    "    # Update the remaining elements\n",
    "    for j in range(len(List_temp)):\n",
    "        # If the face is of type 1, the new equation will be added.\n",
    "        if List_temp[j] == 1:\n",
    "            List_faces[j].equs.append(len(wbs_active))\n",
    "        # If the face is of type 6:\n",
    "        elif List_temp[j] == 6:\n",
    "            # Equations for new face\n",
    "            new_face_equs = List_faces[j].equs + [len(wbs_active)]\n",
    "            # Codimension of new face\n",
    "            new_face_codim = List_faces[j].codim + 1\n",
    "            # Subfaces for both old and new faces\n",
    "            new_face_subfaces = [ind for ind in List_faces[j].subfaces if List_temp[ind] == 1]\n",
    "            for ind in List_faces[j].subfaces:\n",
    "                if ind < len(List_temp):\n",
    "                    if List_temp[ind] == 6:\n",
    "                        List_faces[j].subfaces.append(List_faces[ind].subfaces[-1])\n",
    "                        new_face_subfaces.append(List_faces[ind].subfaces[-1])\n",
    "            List_faces[j].subfaces.append(len(List_faces))\n",
    "            # Sample point for the new face\n",
    "            if len(new_face_subfaces) == 0:\n",
    "                face_equs = [wbs_active[ind].bis for ind in List_faces[j].equs]\n",
    "                new_face_sample_point = find_positive_definite_intersection(face_equs + [new_wb.bis]).sample_point\n",
    "            elif len(new_face_subfaces) >= 2:\n",
    "                new_face_sample_point = sum((List_faces[ind].sample_point for ind in new_face_subfaces), np.zeros((3, 3)))\n",
    "                if not is_positive_definite(new_face_sample_point):\n",
    "                    print(\"new_face_sample_point: unexpected non-positive definite matrix.\")\n",
    "                new_face_sample_point = new_face_sample_point/((det(new_face_sample_point)) ** (1/3))\n",
    "            # If only one subface\n",
    "            else:\n",
    "                face_equs = [wbs_active[ind].bis for ind in List_faces[j].equs]\n",
    "                subface_equ_ind = first_unique_element(List_faces[new_face_subfaces[0]].equs, new_face_equs)\n",
    "                subface_equ = wbs_active[subface_equ_ind].bis\n",
    "                subface_sample_point = List_faces[new_face_subfaces[0]].sample_point\n",
    "                new_face_sample_point = perturb_within_plane(subface_sample_point, face_equs + [new_wb.bis], subface_equ)\n",
    "            # Sample point for the old face\n",
    "            if np.trace(List_faces[j].sample_point @ new_wb.bis) < np.sqrt(tol):\n",
    "                face_equs = [wbs_active[ind].bis for ind in List_faces[j].equs]\n",
    "                old_face_sample_point = perturb_within_plane(new_face_sample_point, face_equs, new_wb.bis)\n",
    "                # Check if this point is inside the polytope. \n",
    "                # The new face will be good. Moreover, if the old sample point is on the face, it will be fine.\n",
    "                # To make it safe, add that ind is not in List_faces[j].equs\n",
    "                while any(ind not in List_faces[j].equs and np.trace(wb.bis @ List_faces[j].sample_point) > tol\\\n",
    "                          and np.trace(wb.bis @ old_face_sample_point) < tol for ind, wb in enumerate(wbs_active)):\n",
    "                    old_face_sample_point = 0.5*(old_face_sample_point + new_face_sample_point)\n",
    "                temporary_sample_point = 0.5*(old_face_sample_point + new_face_sample_point)\n",
    "                if not is_positive_definite(temporary_sample_point):\n",
    "                    print(\"temporary_sample_point: unexpected non-positive definite matrix.\")\n",
    "                temporary_sample_point = temporary_sample_point/((det(temporary_sample_point)) ** (1/3))\n",
    "                List_faces[j].sample_point = temporary_sample_point\n",
    "            # Save the new face to List_faces\n",
    "            List_faces.append(Poly_Face(new_face_equs, new_face_codim, new_face_subfaces, np.array(new_face_sample_point)))\n",
    "    # Save the new equation to bises_active\n",
    "    wbs_active.append(new_wb)\n",
    "    # Remove the unnecessary equations\n",
    "    equ_remove_list = list(range(len(wbs_active)))\n",
    "    for j in range(len(List_faces)):\n",
    "        if List_faces[j].codim == 1:\n",
    "            equ_remove_list = [ind for ind in equ_remove_list if ind != List_faces[j].equs[0]]\n",
    "    for j in sorted(equ_remove_list, reverse=True):\n",
    "        del wbs_active[j]\n",
    "    for j in range(len(List_faces)):\n",
    "        List_faces[j].equs = [ind for ind in List_faces[j].equs if ind not in equ_remove_list]\n",
    "        List_equs_temp = []\n",
    "        for ind in List_faces[j].equs:\n",
    "            decrease = sum(1 for val in equ_remove_list if val < ind)\n",
    "            List_equs_temp.append(ind - decrease)\n",
    "        List_faces[j].equs = List_equs_temp.copy()\n",
    "    # Sort the faces again, including the subfaces\n",
    "    List_faces_indexed = [(i, face) for i, face in enumerate(List_faces)]\n",
    "    List_faces_indexed.sort(key=lambda obj: obj[1].codim, reverse=True)\n",
    "    index_mapping = {old_index: new_index for new_index, (old_index, _) in enumerate(List_faces_indexed)}\n",
    "    for _, face in List_faces_indexed:\n",
    "        face.subfaces = [index_mapping[ind] for ind in face.subfaces]\n",
    "    List_faces = [face for _, face in List_faces_indexed]\n",
    "    return wbs_active, List_faces\n",
    "\n",
    "# Check if the word takes the old face to the new one\n",
    "\n",
    "def face_is_paired(my_wbs, my_face_list, old_face_ind, new_face_ind, word):\n",
    "    if my_face_list[old_face_ind].codim == my_face_list[new_face_ind].codim:\n",
    "        cod = my_face_list[old_face_ind].codim\n",
    "        if len(my_face_list[old_face_ind].subfaces) == len(my_face_list[new_face_ind].subfaces):\n",
    "            old_face_equations = [my_wbs[ind].bis for ind in my_face_list[old_face_ind].equs]\n",
    "            new_face_equations = [my_wbs[ind].bis for ind in my_face_list[new_face_ind].equs]\n",
    "            if equal_spaces(old_face_equations, new_face_equations, word):\n",
    "                if len(my_face_list[old_face_ind].subfaces) == 0:\n",
    "                    return True\n",
    "                else:\n",
    "                    old_facets = [j for j in my_face_list[old_face_ind].subfaces if my_face_list[j].codim == cod + 1]\n",
    "                    new_facets = [k for k in my_face_list[new_face_ind].subfaces if my_face_list[k].codim == cod + 1]\n",
    "                    # all old facets find a new partner\n",
    "                    if len(old_facets) != len(new_facets):\n",
    "                        return False\n",
    "                    for j in old_facets:\n",
    "                        if not any(face_is_paired(my_wbs, my_face_list, j, k, word) for k in new_facets):\n",
    "                            return False\n",
    "                    return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "def polytope_is_exact(my_wbs, my_face_list):\n",
    "    # Get a list of facets\n",
    "    facet_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 1]\n",
    "    paired_indices = []\n",
    "    for i in facet_indices:\n",
    "        i_pair = next((j for j in facet_indices if face_is_paired(my_wbs, my_face_list,\\\n",
    "                                                                  i, j, my_wbs[my_face_list[i].equs[0]].word)), None)\n",
    "        if i_pair == None:\n",
    "            return False, facet_indices, None\n",
    "        else:\n",
    "            paired_indices.append(i_pair)\n",
    "    return True, facet_indices, paired_indices\n",
    "def quick_exact(my_wbs, my_face_list):\n",
    "    facet_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 1]\n",
    "    unpaired_ridges = []\n",
    "    for i in facet_indices:\n",
    "        i_ridges = [j for j in my_face_list[i].subfaces if my_face_list[j].codim == 2]\n",
    "        i_pair = next((i_0 for i_0 in facet_indices if np.all(np.abs(my_wbs[my_face_list[i].equs[0]].word @ my_wbs[my_face_list[i_0].equs[0]].word\\\n",
    "                                                                     - np.eye(3))<tol)), None)\n",
    "        if i_pair != None:\n",
    "            i_pair_ridges = [j_0 for j_0 in my_face_list[i_pair].subfaces if my_face_list[j_0].codim == 2]\n",
    "            for j in i_ridges:\n",
    "                j_equations = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                j_pair = next((j_0 for j_0 in i_pair_ridges if equal_spaces(j_equations,\\\n",
    "                                                                            [my_wbs[ind].bis for ind in my_face_list[j_0].equs],\\\n",
    "                                                                            my_wbs[my_face_list[i].equs[0]].word)), None)\n",
    "                if j_pair == None:\n",
    "                    mat = (my_wbs[my_face_list[i].equs[0]].word).T @ my_face_list[j].sample_point @ my_wbs[my_face_list[i].equs[0]].word\n",
    "                    if all(np.trace(mat @ my_wbs[ind].bis)> tol for ind in range(len(my_wbs)) if ind not in my_face_list[i_pair].equs):\n",
    "                        unpaired_ridges.append([i, j])\n",
    "    if len(unpaired_ridges) == 0:\n",
    "        return True, None\n",
    "    else:\n",
    "        return False, unpaired_ridges\n",
    "def compute_ridge_cycle(my_wbs, my_face_list):\n",
    "    if not polytope_is_exact(my_wbs, my_face_list):\n",
    "        return None\n",
    "    else:\n",
    "        facet_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 1]\n",
    "        all_ridge_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 2]\n",
    "        ridge_cycle_list = []\n",
    "        for i in facet_indices:\n",
    "            ridge_indices = [j for j in my_face_list[i].subfaces if j in all_ridge_indices]\n",
    "            for j in ridge_indices:\n",
    "                if any(j in ridge_cycle.ridge for ridge_cycle in ridge_cycle_list):\n",
    "                    continue\n",
    "                else:\n",
    "                    current_ridge = j\n",
    "                    current_facet = i\n",
    "                    current_pairing = my_face_list[current_facet].equs[0]\n",
    "                    ridge_cycle = Ridge_Cycles([current_ridge], [current_pairing])\n",
    "                    # Ridge cycles will not be too long\n",
    "                    for _ in range(2*len(all_ridge_indices)):\n",
    "                        mapped_facet = next((mapped_i for mapped_i in facet_indices if \\\n",
    "                                          face_is_paired(my_wbs, my_face_list, current_facet, mapped_i, my_wbs[current_pairing].word)), None)\n",
    "                        new_ridge_indices = [new_j for new_j in my_face_list[mapped_facet].subfaces if new_j in all_ridge_indices]\n",
    "                        new_ridge = next((new_j for new_j in new_ridge_indices if \\\n",
    "                                          face_is_paired(my_wbs, my_face_list, current_ridge, new_j, my_wbs[current_pairing].word)), None)\n",
    "                        new_facet = next(new_i for new_i in facet_indices if new_ridge in my_face_list[new_i].subfaces and new_i != mapped_facet)\n",
    "                        new_pairing = my_face_list[new_facet].equs[0]\n",
    "                        if new_ridge == ridge_cycle.ridge[0] and new_pairing == ridge_cycle.pairing[0]:\n",
    "                            ridge_cycle_list.append(ridge_cycle)\n",
    "                            break\n",
    "                        else:\n",
    "                            ridge_cycle.ridge.append(new_ridge)\n",
    "                            ridge_cycle.pairing.append(new_pairing)\n",
    "                            current_ridge = new_ridge\n",
    "                            current_facet = new_facet\n",
    "                            current_pairing = new_pairing\n",
    "        return ridge_cycle_list\n",
    "\n",
    "def angle_sum(my_wbs, my_face_list, ridge_cycle):\n",
    "    angle_sum = 0\n",
    "    point = my_face_list[ridge_cycle.ridge[0]].sample_point\n",
    "    for i in range(len(ridge_cycle.ridge)):\n",
    "        first_bis = my_face_list[ridge_cycle.ridge[i]].equs[0]\n",
    "        second_bis = my_face_list[ridge_cycle.ridge[i]].equs[1]\n",
    "        angle = Riemannian_angle(my_wbs[first_bis].bis, my_wbs[second_bis].bis, point)\n",
    "        angle_sum = angle_sum + angle\n",
    "        word = my_wbs[ridge_cycle.pairing[i]].word\n",
    "        point = word.T @ point @ word\n",
    "    quotient = 2*np.pi/angle_sum\n",
    "    quotient_round = round(quotient)\n",
    "    if abs(quotient - quotient_round)> 100*tol:\n",
    "        return None\n",
    "    else:\n",
    "        return quotient_round\n",
    "######################################\n",
    "def compute_selberg_domain(generators, length, center):\n",
    "    wbs = word_bisectors(generators, length, center)\n",
    "    # Faces that are utilized in forming the polytope\n",
    "    wbs_active = []\n",
    "    # Data for the faces. Initially, we have the entire space as a face.\n",
    "    List_faces = [Poly_Face([], 0, [], np.array(center))]\n",
    "    print(\"number of words:\", len(wbs))\n",
    "    for i in range(len(wbs)):\n",
    "        new_wb = wbs[i]\n",
    "        wbs_active, List_faces = selberg_domain_add_facet(wbs_active, List_faces, new_wb)\n",
    "        print(i, \"-th loop completed\")\n",
    "    return wbs_active, List_faces\n",
    "def compute_selberg_domain_new(generators, length_1, length_2, loop_times, center):\n",
    "    # Likely need most of these\n",
    "    wbs = word_bisectors(generators, length_1, center)\n",
    "    # Only need a few of them. Use refined algorithm to catch these\n",
    "    more_wbs = word_bisectors(generators, length_2, center)\n",
    "    # Faces that are utilized in forming the polytope\n",
    "    wbs_active = []\n",
    "    # Data for the faces. Initially, we have the entire space as a face.\n",
    "    List_faces = [Poly_Face([], 0, [], np.array(center))]\n",
    "    print(\"number of words:\", len(wbs))\n",
    "    for i in range(len(wbs)):\n",
    "        new_wb = wbs[i]\n",
    "        wbs_active, List_faces = selberg_domain_add_facet(wbs_active, List_faces, new_wb)\n",
    "        print(i, \"-th loop completed\")\n",
    "    for _ in range(loop_times):\n",
    "        is_exact, unpaired_ridges = quick_exact(wbs_active, List_faces)\n",
    "        if is_exact:\n",
    "            break\n",
    "        else:\n",
    "            facet_indices = [i for i in range(len(List_faces)) if List_faces[i].codim == 1]\n",
    "            print(\"current number of facets:\", len(facet_indices))\n",
    "            print(\"current number of unpaired ridges\", len(unpaired_ridges))\n",
    "            # find my facet with least trace\n",
    "            min_trace = np.inf\n",
    "            new_wb = None\n",
    "            for i, j in unpaired_ridges:\n",
    "                i_pair = next((i_0 for i_0 in facet_indices if np.all(np.abs(wbs_active[List_faces[i].equs[0]].word @ wbs_active[List_faces[i_0].equs[0]].word\\\n",
    "                                                                     - np.eye(3))<tol)), None)\n",
    "                j_equations = [wbs_active[ind].bis for ind in List_faces[j].equs]\n",
    "                i_pair_equation = wbs_active[List_faces[i_pair].equs[0]].bis\n",
    "                for k in range(len(more_wbs)):\n",
    "                    if np.trace(more_wbs[k].bis @ np.array(center)) < min_trace:\n",
    "                        candidate_equations = [i_pair_equation, more_wbs[k].bis]\n",
    "                        if equal_spaces(j_equations, candidate_equations, wbs_active[List_faces[i].equs[0]].word):\n",
    "                            min_trace = np.trace(more_wbs[k].bis @ np.array(center))\n",
    "                            new_wb = more_wbs[k]\n",
    "            if new_wb is not None:\n",
    "                wbs_active, List_faces = selberg_domain_add_facet(wbs_active, List_faces, new_wb)\n",
    "            print(\"ridge fixed\")\n",
    "    return wbs_active, List_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:17:45.110280Z",
     "iopub.status.busy": "2025-07-06T13:17:45.109357Z",
     "iopub.status.idle": "2025-07-06T13:18:28.214076Z",
     "shell.execute_reply": "2025-07-06T13:18:28.213058Z",
     "shell.execute_reply.started": "2025-07-06T13:17:45.110253Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words: 16\n",
      "0 -th loop completed\n",
      "1 -th loop completed\n",
      "2 -th loop completed\n",
      "3 -th loop completed\n",
      "4 -th loop completed\n",
      "5 -th loop completed\n",
      "6 -th loop completed\n",
      "7 -th loop completed\n",
      "8 -th loop completed\n",
      "9 -th loop completed\n",
      "10 -th loop completed\n",
      "11 -th loop completed\n",
      "12 -th loop completed\n",
      "13 -th loop completed\n",
      "14 -th loop completed\n",
      "15 -th loop completed\n",
      "Number of facets: 6\n",
      "Number of ridges: 15\n",
      "Number of faces of codimension 3: 16\n",
      "The largest trace for sample points multiplying with corresponding facets: 2.886579864025407e-15\n",
      "The smallest trace of sample points multiplying with non-corresponding facets: 0.08695819189645349\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# generators = [[[0.5, 0.5, 0],\n",
    "#          [0.5, -0.5, 1],\n",
    "#          [0.5, -0.5, -1]],\n",
    "#               [[-0.5, 1, 0.5],\n",
    "#          [-0.5, -1, 0.5],\n",
    "#          [0.5, 0, 0.5]],\n",
    "#              [[-1, 0.5, -0.5],\n",
    "#          [0, 0.5, 0.5],\n",
    "#          [1, 0.5, -0.5]]]\n",
    "# # Test: Compute the polytope structure\n",
    "generators = [[[0.5, 0.5, 0],\n",
    "         [0.5, -0.5, 1],\n",
    "         [0.5, -0.5, -1]],\n",
    "              [[-0.5, 1, 0.5],\n",
    "         [-0.5, -1, 0.5],\n",
    "         [0.5, 0, 0.5]]]\n",
    "#################################\n",
    "# Test: Compute the polytope structure\n",
    "# generators = [[[1, 2, 0],\n",
    "#                [0, 1, 0],\n",
    "#                [0, 0, 1]],\n",
    "#               [[1, 0, 2],\n",
    "#                [0, 1, 0],\n",
    "#                [0, 0, 1]],\n",
    "#               [[1, 0, 0],\n",
    "#                [0, 1, 2],\n",
    "#                [0, 0, 1]],\n",
    "#               [[1, 0, 0],\n",
    "#                [2, 1, 0],\n",
    "#                [0, 0, 1]],\n",
    "#               [[1, 0, 0],\n",
    "#                [0, 1, 0],\n",
    "#                [2, 0, 1]],\n",
    "#               [[1, 0, 0],\n",
    "#                [0, 1, 0],\n",
    "#                [0, 2, 1]]]\n",
    "center = [[1, 0, 0],\n",
    "         [0, 1, 0],\n",
    "         [0, 0, 1]]\n",
    "my_wbs, my_face_list = compute_selberg_domain(generators, 2, center)\n",
    "# my_wbs, my_face_list = compute_selberg_domain_new(generators, 1, 4, 20, center)\n",
    "# ############################# \n",
    "# Count the number of faces\n",
    "# All edges and four faces of codimension 3 are on the Satake boundary, not computed here\n",
    "print(\"Number of facets:\", sum(1 for face in my_face_list if face.codim == 1))\n",
    "print(\"Number of ridges:\", sum(1 for face in my_face_list if face.codim == 2))\n",
    "print(\"Number of faces of codimension 3:\", sum(1 for face in my_face_list if face.codim == 3))\n",
    "############################# \n",
    "# Make sure every sample point lies on the corresponding plane. Expected to be something close to zero.\n",
    "max_trace = 0\n",
    "for face in my_face_list:\n",
    "    for ind in face.equs:\n",
    "        my_trace = np.trace(my_wbs[ind].bis @ face.sample_point)\n",
    "        max_trace = max(max_trace, abs(my_trace))\n",
    "print(\"The largest trace for sample points multiplying with corresponding facets:\", max_trace)\n",
    "############################# \n",
    "# Make sure every sample point is in the interior. Expected to be a positive number.\n",
    "min_trace = np.inf\n",
    "for face in my_face_list:\n",
    "    for ind in range(len(my_wbs)):\n",
    "        if ind not in face.equs:\n",
    "            my_trace = np.trace(my_wbs[ind].bis @ face.sample_point)\n",
    "            min_trace = min(min_trace, my_trace)\n",
    "print(\"The smallest trace of sample points multiplying with non-corresponding facets:\", min_trace)\n",
    "# print(my_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:20:10.386035Z",
     "iopub.status.busy": "2025-07-06T13:20:10.385642Z",
     "iopub.status.idle": "2025-07-06T13:20:11.427430Z",
     "shell.execute_reply": "2025-07-06T13:20:11.426359Z",
     "shell.execute_reply.started": "2025-07-06T13:20:10.385989Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[Ridge_Cycles(ridge=[16, 19, 29], pairing=[0, 0, 5]), Ridge_Cycles(ridge=[17, 20, 30], pairing=[0, 1, 4]), Ridge_Cycles(ridge=[22, 21, 24], pairing=[0, 2, 2]), Ridge_Cycles(ridge=[26, 25, 18], pairing=[0, 4, 1]), Ridge_Cycles(ridge=[23, 27, 28], pairing=[1, 1, 2])]\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "is_exact, original_facets, paired_facets = polytope_is_exact(my_wbs, my_face_list)\n",
    "print(is_exact)\n",
    "if is_exact:\n",
    "    ridge_cycles = compute_ridge_cycle(my_wbs, my_face_list)\n",
    "    print(ridge_cycles)\n",
    "    for ridge_cycle in ridge_cycles:\n",
    "        print(angle_sum(my_wbs, my_face_list, ridge_cycle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:20:17.470963Z",
     "iopub.status.busy": "2025-07-06T13:20:17.470644Z",
     "iopub.status.idle": "2025-07-06T13:20:17.476056Z",
     "shell.execute_reply": "2025-07-06T13:20:17.474871Z",
     "shell.execute_reply.started": "2025-07-06T13:20:17.470940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "codim_3_list = [my_face for my_face in my_face_list if my_face.codim == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:20:19.535273Z",
     "iopub.status.busy": "2025-07-06T13:20:19.534893Z",
     "iopub.status.idle": "2025-07-06T13:20:19.541142Z",
     "shell.execute_reply": "2025-07-06T13:20:19.540072Z",
     "shell.execute_reply.started": "2025-07-06T13:20:19.535248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5  0.   0. ]\n",
      " [ 0.   0.5 -0.5]\n",
      " [ 0.  -0.5  0.5]]\n",
      "[[ 0.5 -0.5  0. ]\n",
      " [-0.5  0.5  0. ]\n",
      " [ 0.   0.  -0.5]]\n",
      "[[-0.5  0.   0. ]\n",
      " [ 0.   0.5  0.5]\n",
      " [ 0.   0.5  0.5]]\n"
     ]
    }
   ],
   "source": [
    "codim_3 = codim_3_list[0]\n",
    "for equ in codim_3.equs:\n",
    "    print(my_wbs[equ].bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:20:46.025438Z",
     "iopub.status.busy": "2025-07-06T13:20:46.025121Z",
     "iopub.status.idle": "2025-07-06T13:20:46.031683Z",
     "shell.execute_reply": "2025-07-06T13:20:46.030511Z",
     "shell.execute_reply.started": "2025-07-06T13:20:46.025415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5  0. ]\n",
      " [ 0.5 -0.5  1. ]\n",
      " [ 0.5 -0.5 -1. ]]\n",
      "[[-0.5  1.   0.5]\n",
      " [-0.5 -1.   0.5]\n",
      " [ 0.5  0.   0.5]]\n",
      "[[-1.   0.5 -0.5]\n",
      " [ 0.   0.5  0.5]\n",
      " [ 1.   0.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "ridge_cycle = ridge_cycles[1]\n",
    "for wb in ridge_cycle.pairing:\n",
    "    print(my_wbs[wb].word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:48:33.636422Z",
     "iopub.status.busy": "2025-07-06T13:48:33.636058Z",
     "iopub.status.idle": "2025-07-06T13:48:33.668398Z",
     "shell.execute_reply": "2025-07-06T13:48:33.667532Z",
     "shell.execute_reply.started": "2025-07-06T13:48:33.636395Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 3, 4)\n",
      "[[ 0.          0.35355339 -0.35355339]\n",
      " [ 0.35355339  0.          0.        ]\n",
      " [-0.35355339  0.          0.        ]]\n",
      "0.0\n",
      "(0, 1, 2, 3, 5)\n",
      "[[ 0.         -0.35355339  0.        ]\n",
      " [-0.35355339  0.          0.35355339]\n",
      " [ 0.          0.35355339  0.        ]]\n",
      "0.0\n",
      "(0, 1, 2, 3, 6)\n",
      "[[ 0.          0.         -0.35355339]\n",
      " [ 0.          0.          0.35355339]\n",
      " [-0.35355339  0.35355339  0.        ]]\n",
      "0.0\n",
      "(0, 1, 2, 4, 5)\n",
      "[[0.         0.         0.35355339]\n",
      " [0.         0.         0.35355339]\n",
      " [0.35355339 0.35355339 0.        ]]\n",
      "0.0\n",
      "(0, 1, 2, 4, 6)\n",
      "[[0.         0.35355339 0.        ]\n",
      " [0.35355339 0.         0.35355339]\n",
      " [0.         0.35355339 0.        ]]\n",
      "0.0\n",
      "(0, 1, 2, 5, 6)\n",
      "[[ 0.         -0.35355339 -0.35355339]\n",
      " [-0.35355339  0.          0.        ]\n",
      " [-0.35355339  0.          0.        ]]\n",
      "0.0\n",
      "(0, 1, 3, 4, 5)\n",
      "[[ 0.00000000e+00 -2.50000000e-01  2.50000000e-01]\n",
      " [-2.50000000e-01 -2.98518123e-16  2.50000000e-01]\n",
      " [ 2.50000000e-01  2.50000000e-01 -5.00000000e-01]]\n",
      "-1.908195823574485e-17\n",
      "(0, 1, 3, 4, 6)\n",
      "[[ 0.00000000e+00  2.50000000e-01 -2.50000000e-01]\n",
      " [ 2.50000000e-01 -2.29629325e-16  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01 -5.00000000e-01]]\n",
      "1.7347234759768093e-17\n",
      "(0, 1, 3, 5, 6)\n",
      "[[ 0.00000000e+00 -2.50000000e-01 -2.50000000e-01]\n",
      " [-2.50000000e-01 -4.59258651e-17  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01  5.00000000e-01]]\n",
      "1.3877787807814488e-17\n",
      "(0, 1, 4, 5, 6)\n",
      "[[ 0.00000000e+00  2.50000000e-01  2.50000000e-01]\n",
      " [ 2.50000000e-01 -6.88887976e-17  2.50000000e-01]\n",
      " [ 2.50000000e-01  2.50000000e-01  5.00000000e-01]]\n",
      "-1.7347234759768093e-17\n",
      "(0, 2, 3, 4, 5)\n",
      "[[ 0.00000000e+00 -2.50000000e-01  2.50000000e-01]\n",
      " [-2.50000000e-01 -5.00000000e-01  2.50000000e-01]\n",
      " [ 2.50000000e-01  2.50000000e-01 -1.11022302e-16]]\n",
      "-1.3877787807814488e-17\n",
      "(0, 2, 3, 4, 6)\n",
      "[[ 0.00000000e+00  2.50000000e-01 -2.50000000e-01]\n",
      " [ 2.50000000e-01 -5.00000000e-01  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01 -8.32667268e-17]]\n",
      "-1.7347234759768136e-18\n",
      "(0, 2, 3, 5, 6)\n",
      "[[ 0.00000000e+00 -2.50000000e-01 -2.50000000e-01]\n",
      " [-2.50000000e-01  5.00000000e-01  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01  1.11022302e-16]]\n",
      "1.0408340855860803e-17\n",
      "(0, 2, 4, 5, 6)\n",
      "[[0.00000000e+00 2.50000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 5.00000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 2.50000000e-01 2.22044605e-16]]\n",
      "1.3877787807814488e-17\n",
      "(0, 3, 4, 5, 6)\n",
      "[[ 0.00000000e+00 -5.55111512e-17 -5.55111512e-17]\n",
      " [-5.55111512e-17  7.07106781e-01 -5.55111512e-17]\n",
      " [-5.55111512e-17 -5.55111512e-17 -7.07106781e-01]]\n",
      "-4.421740811494559e-50\n",
      "(1, 2, 3, 4, 5)\n",
      "[[-5.00000000e-01 -2.50000000e-01  2.50000000e-01]\n",
      " [-2.50000000e-01  0.00000000e+00  2.50000000e-01]\n",
      " [ 2.50000000e-01  2.50000000e-01  2.49800181e-16]]\n",
      "-1.0408340855860803e-17\n",
      "(1, 2, 3, 4, 6)\n",
      "[[-5.00000000e-01  2.50000000e-01 -2.50000000e-01]\n",
      " [ 2.50000000e-01  0.00000000e+00  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01  2.22044605e-16]]\n",
      "-1.3877787807814389e-17\n",
      "(1, 2, 3, 5, 6)\n",
      "[[ 5.00000000e-01 -2.50000000e-01 -2.50000000e-01]\n",
      " [-2.50000000e-01  0.00000000e+00  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01 -2.22044605e-16]]\n",
      "-1.3877787807814488e-17\n",
      "(1, 2, 4, 5, 6)\n",
      "[[ 5.00000000e-01  2.50000000e-01  2.50000000e-01]\n",
      " [ 2.50000000e-01  0.00000000e+00  2.50000000e-01]\n",
      " [ 2.50000000e-01  2.50000000e-01 -2.22044605e-16]]\n",
      "-2.0816681711721642e-17\n",
      "(1, 3, 4, 5, 6)\n",
      "[[ 7.07106781e-01 -5.55111512e-17 -5.55111512e-17]\n",
      " [-5.55111512e-17  0.00000000e+00 -5.55111512e-17]\n",
      " [-5.55111512e-17 -5.55111512e-17 -7.07106781e-01]]\n",
      "-4.421740811494559e-50\n",
      "(2, 3, 4, 5, 6)\n",
      "[[ 7.07106781e-01 -5.55111512e-17 -5.55111512e-17]\n",
      " [-5.55111512e-17 -7.07106781e-01 -5.55111512e-17]\n",
      " [-5.55111512e-17 -5.55111512e-17  0.00000000e+00]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "vertices = [[[1, 0, 0],\n",
    "                    [0, 0, 0],\n",
    "                    [0, 0, 0]],\n",
    "                   [[0, 0, 0],\n",
    "                    [0, 1, 0],\n",
    "                    [0, 0, 0]],\n",
    "                   [[0, 0, 0],\n",
    "                    [0, 0, 0],\n",
    "                    [0, 0, 1]],\n",
    "                   [[1, 1, 1],\n",
    "                    [1, 1, 1],\n",
    "                    [1, 1, 1]],\n",
    "                   [[1, -1, -1],\n",
    "                    [-1, 1, 1],\n",
    "                    [-1, 1, 1]],\n",
    "                   [[1, -1, 1],\n",
    "                    [-1, 1, -1],\n",
    "                    [1, -1, 1]],\n",
    "                   [[1, 1, -1],\n",
    "                    [1, 1, -1],\n",
    "                    [-1, -1, 1]]]\n",
    "for inds in itertools.combinations(range(7),5):\n",
    "    points = [vertices[i] for i in inds]\n",
    "    plane_equations = orth_matrix(points)\n",
    "    if len(plane_equations) == 1:\n",
    "        plane_equation = plane_equations[0]\n",
    "        if all(np.trace(plane_equation)*np.trace(plane_equation @ mat) > -1e-10 for mat in vertices):\n",
    "            print(inds)\n",
    "            print(plane_equation)\n",
    "            print(det(plane_equation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# Test: Find the sample point in bad case\n",
    "# Mat_A = [[1, 0, 0],\n",
    "#          [0, -1, 0],\n",
    "#          [0, 0, 0]]\n",
    "# Mat_B = [[[0, 0, 0],\n",
    "#           [0, -1, 0],\n",
    "#           [0, 0, 1]],\n",
    "#          [[0, 1, 0],\n",
    "#           [1, -1, 0],\n",
    "#           [0, 0, 1]],\n",
    "#          [[0, 0, 0],\n",
    "#           [0, 0, 1],\n",
    "#           [0, 1, 0]],\n",
    "#          [[0, 1, 1],\n",
    "#           [1, 0, 1],\n",
    "#           [1, 1, 0]],\n",
    "#          [[0, 0, 1],\n",
    "#           [0, 0, 1],\n",
    "#           [1, 1, 0]],\n",
    "#          [[0, 1, 0],\n",
    "#           [1, 0, 0],\n",
    "#           [0, 0, 0]]]\n",
    "# Q = np.array(random_SL3_qr())\n",
    "# M_1 = Q.T @ Mat_A @ Q\n",
    "# M_2 = Q.T @ Mat_B[0] @ Q\n",
    "M_1 = [[ 1., -1., -1.],\n",
    "       [-1.,  0.,  1.],\n",
    "       [-1.,  1.,  1.]]\n",
    "M_2 = [[0., -1., -1.],\n",
    "       [-1.,  1.,  1.],\n",
    "       [-1.,  1.,  1.]]\n",
    "M_3 = [[0.,  1., -1.],\n",
    "       [ 1.,  1., -1.],\n",
    "       [-1., -1.,  1.]]\n",
    "words = [M_1, M_2, M_3]\n",
    "%time X = find_positive_definite_intersection(words).sample_point\n",
    "print(X)\n",
    "# Y = Q @ X @ Q.T\n",
    "# print(Y)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
