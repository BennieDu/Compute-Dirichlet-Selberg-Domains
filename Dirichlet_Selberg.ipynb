{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "from scipy.linalg import null_space\n",
    "from scipy.linalg import sqrtm\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "from dataclasses import dataclass\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tolerance for numerical computation, set to 1e-10 by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Word_Bis:               # The class of bisectors in the symmetric space $X_3$. A list of Word_Bis models describes the bisectors defining the Dirichlet-Selber domain.\n",
    "    word: np.ndarray          # A matrix $g$ in $SL(3,R)$, typically a word in given generators\n",
    "    bis: np.ndarray           # A normal vector (as a 3*3 matrix) of the Selberg bisector $Bis(X, g.X)$\n",
    "\n",
    "@dataclass\n",
    "class Poly_Face:              # The class of faces of polytopes in $X_3$. A list of Poly_Face models describes the polytope structure of the Dirichlet-Selber domain.\n",
    "    equs: list[int]           # A list of bisectors indices (in the list of the accompanying Word_Bis models) whose intersection is the minimal plane containing the face.\n",
    "    codim: int                # The codimension (5 - dim) of the face.\n",
    "    subfaces: list[int]       # A list of face indices that are proper subfaces of the current face.\n",
    "    sample_point: np.ndarray  # A point in $X_3$ (as a 3*3 matrix) lying in the interior of the current face.\n",
    "\n",
    "@dataclass\n",
    "class Find_Intersection:      # The class describing if the union of certain $X_3$ hyperplanes is empty.\n",
    "    sample_point: np.ndarray  # A sample point of the intersection if non-empty, or the zero matrix if empty.\n",
    "    is_intersection: bool     # Boolean variable describing if the intersection is empty.\n",
    "\n",
    "@dataclass\n",
    "class Ridge_Cycles:           # The class describing a ridge-cycle of a Dirichlet-Selberg domain.\n",
    "    ridge: list[int]          # A list of ridge indices (in the list of the accompanying Poly_Face models), for ridges $r_0, r_1, r_2,...$ in the same ridge cycle.\n",
    "    pairing: list[int]        # A list of word indices (in the list of the accompanying Word_Bis models), each word $g_i$ sends $r_i$ to $r_{i+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first element in the first list that is not in the second one\n",
    "def first_unique_element(list1, list2):\n",
    "    set2 = set(list2)  # Convert list2 to a set for fast lookup\n",
    "    for item in list1:\n",
    "        if item not in set2:\n",
    "            return item\n",
    "    return None        # Return None if no unique element is found\n",
    "\n",
    "# Remove elements from the current list if it exists in the preceding lists\n",
    "def remove_preceding_elements(current_list, preceding_lists):\n",
    "    preceding_set = {tuple(map(tuple, matrix)) for lst in preceding_lists for matrix in lst}\n",
    "    return [matrix for matrix in current_list if tuple(map(tuple, matrix)) not in preceding_set]\n",
    "\n",
    "# Remove duplicate matrices from the list. This may need to be rewritten for a tolerance argument.\n",
    "def remove_duplicates(matrices):\n",
    "    unique_matrices = []\n",
    "    for matrix in matrices:\n",
    "        if not any(np.array_equal(matrix, unique_matrix) for unique_matrix in unique_matrices):\n",
    "            unique_matrices.append(matrix)\n",
    "    return unique_matrices\n",
    "    \n",
    "# Check if the new vector is linearly independent to a independent set of vectors (with tolerance)\n",
    "def is_linearly_independent(vectors, new_vector):\n",
    "    if len(vectors) == 0:\n",
    "        return np.linalg.norm(new_vector) > tol               # The first vector (if nonzero) is independent on its own\n",
    "    matrix = np.array(vectors).T                              # Stack the current independent vectors into a matrix, so each column is a vector    \n",
    "    projection = matrix @ np.linalg.pinv(matrix) @ new_vector # Compute the projection of the new vector onto the space spanned by the existing vectors\n",
    "    residual = new_vector - projection                        # Compute the difference (residual) between the new vector and its projection\n",
    "    return np.linalg.norm(residual) > tol                     # The new vector is dependent to the existing ones if the residual is smaller than the threshold\n",
    "\n",
    "# Return a linearly independent subset of vectors (with tolerance)\n",
    "def linearly_independent_subset(vectors):\n",
    "    indep_vectors = []\n",
    "    for vector in vectors:\n",
    "        if is_linearly_independent(indep_vectors, vector):\n",
    "            indep_vectors.append(vector)\n",
    "    return indep_vectors\n",
    "    \n",
    "# Check if a symmetric matrix (in np.array) is positive definite. Return true if it is, false if it may not be (concerning the tolerance).\n",
    "def is_positive_definite(matrix):\n",
    "    if not isinstance(matrix, np.ndarray):\n",
    "        raise ValueError(\"Input must be a numpy array.\")\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        return False                                  # The matrix is not square\n",
    "    try:\n",
    "        min_diag = np.min(np.linalg.eigvalsh(matrix)) # Find the smallest eigenvalue\n",
    "        return min_diag > tol                         # Positive definite if it is positive (concerning the tolerance).\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False                                  # Not positive definite\n",
    "\n",
    "# Converting between symmetric 3*3 matrices and 6-dimensional vectors\n",
    "def word_to_vector(word):\n",
    "    vector = [word[0][0],word[1][1],word[2][2],word[0][1],word[0][2],word[1][2]]\n",
    "    return vector\n",
    "def word_to_vector_new(word):\n",
    "    vector = [word[0][0],word[1][1],word[2][2],np.sqrt(2) * word[0][1],np.sqrt(2) * word[0][2],np.sqrt(2) * word[1][2]]\n",
    "    return vector\n",
    "def vector_to_word(vector):\n",
    "    word = np.array([[vector[0], vector[3]/2, vector[4]/2],\n",
    "                     [vector[3]/2, vector[1], vector[5]/2],\n",
    "                     [vector[4]/2, vector[5]/2, vector[2]]])\n",
    "    return word\n",
    "\n",
    "# Find the orthogonal complement of 3*3 symmetric matrices, with respect to the product trace.\n",
    "def orth_matrix(matrices):\n",
    "    vectors = [word_to_vector(matrix) for matrix in matrices]\n",
    "    vectors = linearly_independent_subset(vectors)\n",
    "    orth_vectors = null_space(np.array(vectors)).T.tolist()\n",
    "    orth_matrices = [np.array(vector_to_word(orth_vector)) for orth_vector in orth_vectors]\n",
    "    return orth_matrices\n",
    "\n",
    "# Convert a matrix of linear expressions in sympy to cvxpy for convex optimization purposes.\n",
    "def sp_to_cp(M_sym, variables):\n",
    "    free_syms = variables\n",
    "    n_vars = len(free_syms)\n",
    "    rows, cols = M_sym.shape                                                                # Get the matrix shape\n",
    "    coeff_matrices = [np.zeros((rows, cols), dtype=np.float64) for _ in range(n_vars + 1)]  # Initialize the coefficient matrices\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):                 \n",
    "            expr = sp.expand(M_sym[i, j])                                                   # Decompose the matrix into entries\n",
    "            if expr.is_Add:                 \n",
    "                terms = expr.as_ordered_terms()                                             # Convert the entry into a list of summands\n",
    "            else:\n",
    "                terms = [expr]                                                              # Simply wrap the entry if it is a single term\n",
    "            for term in terms:\n",
    "                found = False\n",
    "                for idx, sym in enumerate(free_syms):\n",
    "                    if term.has(sym):\n",
    "                        coeff = term.coeff(sym)\n",
    "                        coeff_matrices[idx + 1][i, j] = float(coeff)                        # Add the coefficient of a certain variable to the corresponding matrix\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    coeff_matrices[0][i, j] = float(term)                                   # Add the constant term to the zeroth matrix\n",
    "    x_cvx = cp.Variable(n_vars)                                                             # Define the cvxpy variables\n",
    "    M_cvx = coeff_matrices[0] + sum(x_cvx[i]*coeff_matrices[i+1] for i in range(n_vars))    # Combine the coefficient matrices into a cvxpy matrix with variables\n",
    "    return M_cvx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question-specific helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a basis of vectors perpendicular to a given 3-dimensional vector.\n",
    "# Specifically, given an indefinite vector, the first output vector is positive definite, while the second output vector is indefinite.\n",
    "def compute_vector(d):\n",
    "    positive_indices = [i for i, x in enumerate(d) if x > tol]\n",
    "    negative_indices = [i for i, x in enumerate(d) if x < -tol]\n",
    "    if not positive_indices or not negative_indices:\n",
    "        return None, None                 # Our program does not focus on definite input vectors\n",
    "    positive_index = positive_indices[0]  # Find the first positive component index of the vector\n",
    "    negative_index = negative_indices[0]  # Find the first negative component index of the vector\n",
    "    d_sorted = [0, 0, 0]                  # Rearrange the components of the vector into (pos, neg, rest)\n",
    "    d_sorted[0] = d[positive_index]       # The positive one becomes d0\n",
    "    d_sorted[1] = d[negative_index]       # The negative one becomes d1\n",
    "    d_sorted[2] = d[3 - positive_index - negative_index] # The remaining becomes d2\n",
    "    d0, d1, d2 = d_sorted\n",
    "    if d2<0:                              # Compute the perpendicular vectors in the new order\n",
    "        v = [-d1/(np.sqrt(d0**2 + d1**2)) - d2/(np.sqrt(d0**2 + d2**2)), d0/(np.sqrt(d0**2 + d1**2)), d0/(np.sqrt(d0**2 + d2**2))]\n",
    "        w = [-d1/(np.sqrt(d0**2 + d1**2)) + d2/(np.sqrt(d0**2 + d2**2)), d0/(np.sqrt(d0**2 + d1**2)), -d0/(np.sqrt(d0**2 + d2**2))]\n",
    "    else:\n",
    "        v = [-d1/(np.sqrt(d0**2 + d1**2)), d0/(np.sqrt(d0**2 + d1**2)) + d2/(np.sqrt(d1**2 + d2**2)), -d1/(np.sqrt(d1**2 + d2**2))]\n",
    "        w = [-d1/(np.sqrt(d0**2 + d1**2)), d0/(np.sqrt(d0**2 + d1**2)) - d2/(np.sqrt(d1**2 + d2**2)), d1/(np.sqrt(d1**2 + d2**2))]\n",
    "    v_original_order = [0, 0, 0]          # Permute the vector back to the original order\n",
    "    v_original_order[positive_index] = v[0]\n",
    "    v_original_order[negative_index] = v[1]\n",
    "    v_original_order[3 - positive_index - negative_index] = v[2]\n",
    "    w_original_order = [0, 0, 0]\n",
    "    w_original_order[positive_index] = w[0]\n",
    "    w_original_order[negative_index] = w[1]\n",
    "    w_original_order[3 - positive_index - negative_index] = w[2]\n",
    "    return v_original_order, w_original_order\n",
    "\n",
    "# Use convex optimization to find positive definite combination of certain 3*3 symmetric matrices\n",
    "def find_pos_def(mat_expr, variables):\n",
    "    t = cp.Variable()\n",
    "    l = len(variables)\n",
    "    x = cp.Variable(l)\n",
    "    M = sp_to_cp(mat_expr, variables)                     # The combination of certain matrices\n",
    "    constraints = [M - t*np.eye(3) >> 0, x >= -1, x <= 1] # Our question only concerns coefficients lying between -1 and 1\n",
    "    prob = cp.Problem(cp.Maximize(t), constraints)        # Find maximal t such that M-tI is positive definite\n",
    "    prob.solve(solver=cp.SCS,eps=tol,max_iters=50000)     # Add verbose=True if needed\n",
    "    if prob.value > 100*tol:\n",
    "        return M.value                                    # The positive definite linear combination with maximized least eigenvalue\n",
    "    else:\n",
    "        return None                                       # No positive definite linear combinations\n",
    "\n",
    "# Compute the Riemannian angle between two hyperplanes (represented by normal vectors) in X_3 at a certain base point\n",
    "# The formula is given in my paper\n",
    "def Riemannian_angle(equ_1, equ_2, mat):\n",
    "    comp_1 = mat @ equ_1\n",
    "    comp_2 = mat @ equ_2\n",
    "    angle_cos = - (np.trace(comp_1 @ comp_2))/(np.sqrt((np.trace(comp_1 @ comp_1)) * (np.trace(comp_2 @ comp_2))))\n",
    "    angle = np.arccos(angle_cos)\n",
    "    return angle\n",
    "\n",
    "# Find a positive definite matrix on the elongation of the line from the first matrix to the second one\n",
    "def elongate(matrix_1, matrix_2):\n",
    "    matrix_1 = np.array(matrix_1)\n",
    "    matrix_2 = np.array(matrix_2)\n",
    "    if not is_positive_definite(matrix_2):\n",
    "        raise ValueError(\"elongate: Input must be positive definite.\")\n",
    "    else:\n",
    "        matrix = 2*matrix_2 - matrix_1            # The elongation\n",
    "        while not is_positive_definite(matrix):   # Go back toward matrix_2 if matrix is indefinite\n",
    "            matrix = 0.5*matrix + 0.5*matrix_2\n",
    "        matrix = matrix/((det(matrix)) ** (1/3))  # Unitize the matrix with respect to the determinant\n",
    "        return np.array(matrix)\n",
    "\n",
    "# The input positive definite matrix lies on the plane defined by some equations as well as a new equation\n",
    "# Perturb it to the positive side of the hyperplane defined by the new equation while remaining positive definite and lying on the plane defined by the old equations\n",
    "def perturb_within_plane(matrix, equations, new_equation):\n",
    "    matrix = np.array(matrix)                                                           # make the matrices numpy for safety reason\n",
    "    equations = [np.array(equation) for equation in equations]\n",
    "    new_equation = np.array(new_equation)\n",
    "    if not is_positive_definite(matrix):\n",
    "        raise ValueError(\"perturb_within_plane: Input must be positive definite.\")\n",
    "    else:\n",
    "        matrix_sqrt = sqrtm(matrix)                                                     # Congruence so the input matrix is taken to the origin\n",
    "        equations_trans = [matrix_sqrt @ equ @ matrix_sqrt for equ in equations]\n",
    "        new_equation_trans = matrix_sqrt @ new_equation @ matrix_sqrt\n",
    "        orth_equations = orth_matrix(equations_trans)\n",
    "        orth_vectors = [word_to_vector_new(equation) for equation in orth_equations]    # Convert from matrices to vectors\n",
    "        new_vector = word_to_vector_new(new_equation_trans)\n",
    "        orth_vectors_matrix = np.array(orth_vectors).T                                  # Stack the current independent vectors into a matrix, each column is a vector\n",
    "        coeffs = list(np.linalg.pinv(orth_vectors_matrix) @ new_vector)                 # Project the new vector to the existing ones\n",
    "        projection_trans = sum(coeff*equ for coeff, equ in zip(coeffs, orth_equations)) # This linear combination lies on the desired plane while keeps away from the new hyperplane\n",
    "        projection = matrix_sqrt @ projection_trans @ matrix_sqrt                       # Take the matrix back\n",
    "        while not is_positive_definite(projection):\n",
    "            projection = 0.5*projection + 0.5*matrix                                    # Go back toward the original matrix if the new one is indefinite\n",
    "        projection = projection/((det(projection)) ** (1/3))                            # Unitize the matrix with respect to the determinant\n",
    "        return projection\n",
    "\n",
    "# Check if the word in SL(3,R) takes the old plane (defined by a set of normal matrices) to the new plane\n",
    "def equal_spaces(old_equations, new_equations, word):\n",
    "    mapped_equations = [inv(word) @ mat @ inv(word.T) for mat in old_equations] # The normal matrices for the mapped plane\n",
    "    mapped_vectors = [word_to_vector(mat) for mat in mapped_equations]          # Convert from matrices to vectors\n",
    "    new_vectors = [word_to_vector(mat) for mat in new_equations]\n",
    "    rank_A = len(linearly_independent_subset(mapped_vectors))                   # Check if they define the same plane by a rank argument\n",
    "    rank_B = len(linearly_independent_subset(new_vectors))\n",
    "    rank_AplusB = len(linearly_independent_subset(mapped_vectors + new_vectors))\n",
    "    spans_equal = (rank_A == rank_AplusB) and (rank_B == rank_AplusB)\n",
    "    return spans_equal\n",
    "\n",
    "# Randomly generate a SL(3,R) matrix. Not actually occurs in the main function but may be useful.\n",
    "def random_SL3_qr():\n",
    "    A = np.random.randn(3,3) # Random matrix\n",
    "    Q, R = np.linalg.qr(A)   # Random orthogonal matrix by taking QR decomposition\n",
    "    if np.linalg.det(Q) < 0: # ensure Q has det +1 (not a reflection)\n",
    "        Q[:,0] *= -1\n",
    "    x = np.random.randn(3)    # Random diagonal matrix\n",
    "    x -= np.mean(x)           # Zero trace\n",
    "    D = np.diag(np.exp(x))    # Exponential so the diagonal matrix has unit determinant\n",
    "    return Q @ D              # Assemble the orthogonal matrix with the diagonal one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute for all distinct words of a given maximal length from given generators in SL(3,R)\n",
    "def generator_to_words(generators, length):\n",
    "    A = [np.array(generator) for generator in generators]      # Make the generators numpy arrays\n",
    "    n = length\n",
    "    k = len(A)\n",
    "    A_inv = [inv(matrix) for matrix in A]\n",
    "    A = A + A_inv\n",
    "    word_A = [[matrix] for matrix in A]                                      # List of words ending with each generator\n",
    "    old_A = [[] for matrix in A]                                             # List of words already obtained\n",
    "    all_A = [[] for matrix in A]                                             # List of all words generated\n",
    "    for _ in range(n-1):                                                     # Each loop increase the maximal word length by 1\n",
    "        new_A = [[] for matrix in A]\n",
    "        for i in range(2*k):\n",
    "            for j in range(2*k):\n",
    "                if (j-i) % (2*k) != k:                                       # Avoid letter backtracking in a word\n",
    "                    new_A[i] = new_A[i] + [matrix @ A[i] for matrix in word_A[j]]\n",
    "        for i in range(2*k):\n",
    "            old_A[i] = remove_duplicates(old_A[i] + word_A[i])\n",
    "            word_A[i] = remove_duplicates(new_A[i])\n",
    "        for i in range(2*k):\n",
    "            word_A[i] = remove_preceding_elements(word_A[i], old_A + word_A[:i])\n",
    "    for i in range(2*k):\n",
    "        all_A[i] = old_A[i] + word_A[i]                                      # All words together\n",
    "    together_A = [matrix for matrix_list in all_A for matrix in matrix_list] # Flatten the list\n",
    "    together_A.sort(key=lambda M: np.trace(M.T @ M))                         # Sort the words by eigenvalue\n",
    "    return together_A\n",
    "\n",
    "# Compute bisectors Bis(X, g.X) (as in dataclass Word_Bis) from a list of generators, a maximal word length and a center X\n",
    "# Words that stabilize X will be excluded for well-defined bisectors\n",
    "def word_bisectors(generators, length, center):\n",
    "    words = generator_to_words(generators, length)\n",
    "    wbs = [Word_Bis(word, np.array(word) @ inv(np.array(center)) @ np.array(word).T - inv(np.array(center)))\\\n",
    "           for word in words]                                                # Definition of Selberg bisectors\n",
    "    wbs_filtered = [wb for wb in wbs if not np.all(np.abs(wb.bis)<tol)]      # Exclude bisectors with zero normal matrices\n",
    "    return wbs_filtered\n",
    "\n",
    "# Determine if the intersection of given hyperplanes is non-empty. Produce a sample point if so.\n",
    "def find_positive_definite_intersection(words):\n",
    "    ################## Part 1: Consider a linearly independent sublist\n",
    "    word_to_vector = [[word[0][0],word[1][1],word[2][2],word[0][1],word[0][2],word[1][2]] for word in words]\n",
    "    independent_vectors = []\n",
    "    for vec in word_to_vector:\n",
    "        if is_linearly_independent(independent_vectors, vec):# Check if the current vector is linearly independent based on previous ones\n",
    "            independent_vectors.append(vec)\n",
    "    indep_matrix = [[[vec[0],vec[3],vec[4]],\n",
    "                    [vec[3],vec[1],vec[5]],\n",
    "                    [vec[4],vec[5],vec[2]]] for vec in independent_vectors]\n",
    "    indep_matrix_np = [np.array(mat) for mat in indep_matrix]\n",
    "    indep_matrix_sp = [sp.Matrix(mat) for mat in indep_matrix]\n",
    "    ################### Part 2: The non-case\n",
    "    A = indep_matrix_np[0]\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(A)\n",
    "    ev_orth, ev_orth_neg = compute_vector(eigenvalues)\n",
    "    if ev_orth is None:\n",
    "        sample_point = np.zeros((3, 3)) \n",
    "        is_intersection = False\n",
    "    else:\n",
    "        n = len(indep_matrix)\n",
    "        Q = eigenvectors\n",
    "        D_orth = np.diag(ev_orth)\n",
    "    ################### Part 3: The case if n = 1\n",
    "        if n == 1:\n",
    "            sample_point = Q @ D_orth @ Q.T\n",
    "            is_intersection = True\n",
    "    ################### Part 4: The case if n > 1, we will begin canceling the variables\n",
    "        else:\n",
    "            linearized_matrix = [Q.T @ mat @ Q for mat in indep_matrix_np]\n",
    "            linearized_matrix_sp = [sp.Matrix(mat) for mat in linearized_matrix]\n",
    "            x_v = sp.symbols('x1:5')\n",
    "            x_v_new = x_v #The necessary variables\n",
    "            diag_max = [a + abs(b) for a, b in zip(ev_orth, ev_orth_neg)]\n",
    "            D_orth_neg = [np.diag(ev_orth_neg),\\\n",
    "                          np.array([[0, np.sqrt(diag_max[0]*diag_max[1]), 0],\n",
    "                                    [np.sqrt(diag_max[0]*diag_max[1]), 0, 0],\n",
    "                                    [0, 0, 0]]),\\\n",
    "                          np.array([[0, 0, np.sqrt(diag_max[0]*diag_max[2])],\n",
    "                                    [0, 0, 0],\n",
    "                                    [np.sqrt(diag_max[0]*diag_max[2]), 0, 0]]),\\\n",
    "                          np.array([[0, 0, 0],\n",
    "                                    [0, 0, np.sqrt(diag_max[1]*diag_max[2])],\n",
    "                                    [0, np.sqrt(diag_max[1]*diag_max[2]), 0]])]\n",
    "            D_orth_sp = sp.Matrix(D_orth)\n",
    "            D_orth_neg_sp = [sp.Matrix(mat) for mat in D_orth_neg]\n",
    "            matrix_comb = sum((var * mat for mat, var in zip(D_orth_neg_sp, x_v)), start=D_orth_sp)\n",
    "            # Remove extra variables\n",
    "            for i in range(1,n):\n",
    "                trace_matrix_prod = (matrix_comb * linearized_matrix_sp[i]).trace().expand()\n",
    "                trace_coeffs = {var: trace_matrix_prod.coeff(var) for var in x_v}\n",
    "                #If a nonzero constant appears, return to false since it is surely empty.\n",
    "                if all(abs(coeff) < tol for coeff in trace_coeffs.values()):\n",
    "                    sample_point = np.zeros((3, 3)) \n",
    "                    is_intersection = False\n",
    "                    return Find_Intersection(np.array(sample_point), is_intersection) \n",
    "                max_var = max(trace_coeffs, key=lambda v: abs(trace_coeffs[v]))\n",
    "                x_sol = sp.solve(trace_matrix_prod, max_var)[0]  # Solve f = 0 for max_var\n",
    "                x_v_new = tuple(var for var in x_v_new if var != max_var) # Drop max_var from x_v_new\n",
    "                matrix_comb = matrix_comb.subs(max_var,x_sol)\n",
    "            # If all variables are removed\n",
    "            if n == 5:\n",
    "                D = np.array(matrix_comb).astype(np.float64)\n",
    "                if is_positive_definite(D):\n",
    "                    sample_point = Q @ D @ Q.T\n",
    "                    is_intersection = True\n",
    "                else:\n",
    "                    sample_point = np.zeros((3, 3)) \n",
    "                    is_intersection = False\n",
    "            # Set the equations\n",
    "            else:\n",
    "                poly_comb = matrix_comb.det()\n",
    "                poly_comb_coeff = poly_comb.as_coefficients_dict()\n",
    "                all_zero = all(abs(coef) < tol for coef in poly_comb_coeff.values())\n",
    "                if all_zero:\n",
    "                    sample_point = np.zeros((3, 3)) \n",
    "                    is_intersection = False\n",
    "                else:\n",
    "                    D = find_pos_def(matrix_comb, x_v_new)\n",
    "                    if D is None:\n",
    "                        sample_point = np.zeros((3, 3)) \n",
    "                        is_intersection = False\n",
    "                    else:\n",
    "                        sample_point = Q @ D @ Q.T\n",
    "                        is_intersection = True\n",
    "    if is_intersection:\n",
    "        if not is_positive_definite(sample_point):\n",
    "            is_intersection = False\n",
    "            sample_point = np.zeros((3, 3))\n",
    "        else:\n",
    "            sample_point = sample_point/((det(sample_point)) ** (1/3))\n",
    "    return Find_Intersection(np.array(sample_point), is_intersection)\n",
    "\n",
    "# Add a new bisector new_wb to the existing polytope in X_3 and compute for the new polytope structure.\n",
    "# The existing bisectors are described by my_wbs and the polytope structure is described by my_face_list. \n",
    "def selberg_domain_add_facet(my_wbs, my_face_list, new_wb):\n",
    "    new_vec = word_to_vector(new_wb.bis)\n",
    "    # Assign to each face a case number\n",
    "    my_temp_list = [0]*len(my_face_list)\n",
    "    # After each round, I will always sort the elements so their codimensions are small to large.\n",
    "    for j in range(len(my_temp_list)):\n",
    "        # If the equations defining F_j span the new equation\n",
    "        face_equs = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "        face_vecs = [word_to_vector(equ) for equ in face_equs]\n",
    "        if not is_linearly_independent(linearly_independent_subset(face_vecs), new_vec):\n",
    "            my_temp_list[j] = 1\n",
    "        # If the face is a minimal face. Since excellent me always sorts the faces, I can always check j from small to large.\n",
    "        elif my_face_list[j].subfaces == []:\n",
    "            # if the new hyperplane intersects with the minimal face, it's type 6\n",
    "            if find_positive_definite_intersection(face_equs + [new_wb.bis]).is_intersection:\n",
    "                my_temp_list[j] = 6\n",
    "            # if the new hyperplane does not intersect with the minimal face, it's type 2 or 4\n",
    "            else:\n",
    "                face_sample_point = my_face_list[j].sample_point\n",
    "                if np.trace(face_sample_point @ new_wb.bis) > 0:\n",
    "                    my_temp_list[j] = 2\n",
    "                else:\n",
    "                    my_temp_list[j] = 4\n",
    "        # If the face has subfaces.\n",
    "        else:\n",
    "            face_subfaces = my_face_list[j].subfaces\n",
    "            face_subfaces_temp = [my_temp_list[ind] for ind in face_subfaces]\n",
    "            # If the type of either subface is 6.\n",
    "            if 6 in face_subfaces_temp:\n",
    "                my_temp_list[j] = 6\n",
    "            # If the type of a subface is 2 or 3, while which of the other subface is 4 or 5.\n",
    "            elif {2, 3} & set(face_subfaces_temp) and {4, 5} & set(face_subfaces_temp):\n",
    "                my_temp_list[j] = 6\n",
    "            # If the type of a subface is 1, 3, or 5.\n",
    "            elif {1, 3, 5} & set(face_subfaces_temp):\n",
    "                face_sample_point = my_face_list[j].sample_point\n",
    "                if np.trace(face_sample_point @ new_wb.bis) > 0:\n",
    "                    my_temp_list[j] = 3\n",
    "                else:\n",
    "                    my_temp_list[j] = 5\n",
    "            # Types of all subfaces are 2, or are 4.\n",
    "            else:\n",
    "                # If the new hyperplane intersects the span of the face\n",
    "                if find_positive_definite_intersection(face_equs + [new_wb.bis]).is_intersection:\n",
    "                    # Sample point of this intersection\n",
    "                    face_inters_sample_point = find_positive_definite_intersection(face_equs + [new_wb.bis]).sample_point\n",
    "                    # Find out the equations shape the sides of the face \n",
    "                    face_subfaces_equs = []\n",
    "                    for ind in face_subfaces:\n",
    "                        if my_face_list[ind].codim == my_face_list[j].codim + 1:\n",
    "                            face_subfaces_equs_temp = [elem for elem in my_face_list[ind].equs if elem not in my_face_list[j].equs]\n",
    "                            face_subfaces_equs[:] = list(set(face_subfaces_equs) | set(face_subfaces_equs_temp))\n",
    "                    # Assume the type is 6\n",
    "                    my_temp_list[j] = 6\n",
    "                    for ind in face_subfaces_equs:\n",
    "                        # However, if any side separates the sample point from the face, the type is either 2 or 4\n",
    "                        if np.trace(face_inters_sample_point @ my_wbs[ind].bis) < 0:\n",
    "                            my_temp_list[j] = face_subfaces_temp[0]\n",
    "                            break\n",
    "                # If the new hyperplane does not intersect the span of the face, the type is either 2 or 4\n",
    "                else:\n",
    "                    my_temp_list[j] = face_subfaces_temp[0]\n",
    "    # If the face is of type 4 or 5, it will be deleted.\n",
    "    ind_remove_list = [j for j in range(len(my_temp_list)) if my_temp_list[j] in [4, 5]]\n",
    "    for j in sorted(ind_remove_list, reverse=True):\n",
    "        del my_face_list[j]\n",
    "        del my_temp_list[j]\n",
    "    # The presence of these faces in subfaces is also erased.\n",
    "    for j in range(len(my_temp_list)):\n",
    "        my_face_list[j].subfaces = [ind for ind in my_face_list[j].subfaces if ind not in ind_remove_list]\n",
    "        List_subfaces_temp = []\n",
    "        for ind in my_face_list[j].subfaces:\n",
    "            decrease = sum(1 for val in ind_remove_list if val < ind)\n",
    "            List_subfaces_temp.append(ind - decrease)\n",
    "        my_face_list[j].subfaces = List_subfaces_temp.copy()\n",
    "    # Update the remaining elements\n",
    "    for j in range(len(my_temp_list)):\n",
    "        # If the face is of type 1, the new equation will be added.\n",
    "        if my_temp_list[j] == 1:\n",
    "            my_face_list[j].equs.append(len(my_wbs))\n",
    "        # If the face is of type 6:\n",
    "        elif my_temp_list[j] == 6:\n",
    "            # Equations for new face\n",
    "            new_face_equs = my_face_list[j].equs + [len(my_wbs)]\n",
    "            # Codimension of new face\n",
    "            new_face_codim = my_face_list[j].codim + 1\n",
    "            # Subfaces for both old and new faces\n",
    "            new_face_subfaces = [ind for ind in my_face_list[j].subfaces if my_temp_list[ind] == 1]\n",
    "            for ind in my_face_list[j].subfaces:\n",
    "                if ind < len(my_temp_list):\n",
    "                    if my_temp_list[ind] == 6:\n",
    "                        my_face_list[j].subfaces.append(my_face_list[ind].subfaces[-1])\n",
    "                        new_face_subfaces.append(my_face_list[ind].subfaces[-1])\n",
    "            my_face_list[j].subfaces.append(len(my_face_list))\n",
    "            # Sample point for the new face\n",
    "            if len(new_face_subfaces) == 0:\n",
    "                face_equs = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                new_face_sample_point = find_positive_definite_intersection(face_equs + [new_wb.bis]).sample_point\n",
    "            elif len(new_face_subfaces) >= 2:\n",
    "                new_face_sample_point = sum((my_face_list[ind].sample_point for ind in new_face_subfaces), np.zeros((3, 3)))\n",
    "                new_face_sample_point = new_face_sample_point/((det(new_face_sample_point)) ** (1/3))\n",
    "            # If only one subface\n",
    "            else:\n",
    "                face_equs = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                subface_equ_ind = first_unique_element(my_face_list[new_face_subfaces[0]].equs, new_face_equs)\n",
    "                subface_equ = my_wbs[subface_equ_ind].bis\n",
    "                subface_sample_point = my_face_list[new_face_subfaces[0]].sample_point\n",
    "                new_face_sample_point = perturb_within_plane(subface_sample_point, face_equs + [new_wb.bis], subface_equ)\n",
    "            # Sample point for the old face\n",
    "            if np.trace(my_face_list[j].sample_point @ new_wb.bis) < np.sqrt(tol):\n",
    "                face_equs = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                old_face_sample_point = perturb_within_plane(new_face_sample_point, face_equs, new_wb.bis)\n",
    "                # Check if this point is inside the polytope. \n",
    "                # The new face will be good. Moreover, if the old sample point is on the face, it will be fine.\n",
    "                # To make it safe, add that ind is not in my_face_list[j].equs\n",
    "                while any(ind not in my_face_list[j].equs and np.trace(wb.bis @ my_face_list[j].sample_point) > tol\\\n",
    "                          and np.trace(wb.bis @ old_face_sample_point) < tol for ind, wb in enumerate(my_wbs)):\n",
    "                    old_face_sample_point = 0.5*(old_face_sample_point + new_face_sample_point)\n",
    "                temporary_sample_point = 0.5*(old_face_sample_point + new_face_sample_point)\n",
    "                temporary_sample_point = temporary_sample_point/((det(temporary_sample_point)) ** (1/3))\n",
    "                my_face_list[j].sample_point = temporary_sample_point\n",
    "            # Save the new face to my_face_list\n",
    "            my_face_list.append(Poly_Face(new_face_equs, new_face_codim, new_face_subfaces, np.array(new_face_sample_point)))\n",
    "    # Save the new equation to bises_active\n",
    "    my_wbs.append(new_wb)\n",
    "    # Remove the unnecessary equations\n",
    "    equ_remove_list = list(range(len(my_wbs)))\n",
    "    for j in range(len(my_face_list)):\n",
    "        if my_face_list[j].codim == 1:\n",
    "            equ_remove_list = [ind for ind in equ_remove_list if ind != my_face_list[j].equs[0]]\n",
    "    for j in sorted(equ_remove_list, reverse=True):\n",
    "        del my_wbs[j]\n",
    "    for j in range(len(my_face_list)):\n",
    "        my_face_list[j].equs = [ind for ind in my_face_list[j].equs if ind not in equ_remove_list]\n",
    "        List_equs_temp = []\n",
    "        for ind in my_face_list[j].equs:\n",
    "            decrease = sum(1 for val in equ_remove_list if val < ind)\n",
    "            List_equs_temp.append(ind - decrease)\n",
    "        my_face_list[j].equs = List_equs_temp.copy()\n",
    "    # Sort the faces again, including the subfaces\n",
    "    my_face_list_indexed = [(i, face) for i, face in enumerate(my_face_list)]\n",
    "    my_face_list_indexed.sort(key=lambda obj: obj[1].codim, reverse=True)\n",
    "    index_mapping = {old_index: new_index for new_index, (old_index, _) in enumerate(my_face_list_indexed)}\n",
    "    for _, face in my_face_list_indexed:\n",
    "        face.subfaces = [index_mapping[ind] for ind in face.subfaces]\n",
    "    my_face_list = [face for _, face in my_face_list_indexed]\n",
    "    return my_wbs, my_face_list\n",
    "\n",
    "# Check if two given faces are paired by a given word.\n",
    "# The bisectors are described by my_wbs. The polytope structure is described by my_face_list.\n",
    "def face_is_paired(my_wbs, my_face_list, old_face_ind, new_face_ind, word):\n",
    "    if my_face_list[old_face_ind].codim != my_face_list[new_face_ind].codim:\n",
    "        return False\n",
    "    if len(my_face_list[old_face_ind].subfaces) != len(my_face_list[new_face_ind].subfaces):\n",
    "        return False\n",
    "    old_face_equations = [my_wbs[ind].bis for ind in my_face_list[old_face_ind].equs]\n",
    "    new_face_equations = [my_wbs[ind].bis for ind in my_face_list[new_face_ind].equs]\n",
    "    if not equal_spaces(old_face_equations, new_face_equations, word):\n",
    "        return False\n",
    "    if len(my_face_list[old_face_ind].subfaces) == 0:\n",
    "        return True\n",
    "    cod = my_face_list[old_face_ind].codim\n",
    "    old_facets = [j for j in my_face_list[old_face_ind].subfaces if my_face_list[j].codim == cod + 1]\n",
    "    new_facets = [k for k in my_face_list[new_face_ind].subfaces if my_face_list[k].codim == cod + 1]\n",
    "    if len(old_facets) != len(new_facets):\n",
    "        return False\n",
    "    for j in old_facets:\n",
    "        if not any(face_is_paired(my_wbs, my_face_list, j, k, word) for k in new_facets):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Find unpaired ridges in a non-exact (pre-)Dirichlet-Selberg domain\n",
    "def unpaired_ridge(my_wbs, my_face_list):\n",
    "    facet_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 1]\n",
    "    unpaired_ridges = []\n",
    "    for i in facet_indices:\n",
    "        i_ridges = [j for j in my_face_list[i].subfaces if my_face_list[j].codim == 2]\n",
    "        i_pair = next((i_0 for i_0 in facet_indices if np.all(np.abs(my_wbs[my_face_list[i].equs[0]].word @ my_wbs[my_face_list[i_0].equs[0]].word\\\n",
    "                                                                     - np.eye(3))<tol)), None)\n",
    "        if i_pair != None:\n",
    "            i_pair_ridges = [j_0 for j_0 in my_face_list[i_pair].subfaces if my_face_list[j_0].codim == 2]\n",
    "            for j in i_ridges:\n",
    "                j_equations = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                j_pair = next((j_0 for j_0 in i_pair_ridges if equal_spaces(j_equations,\\\n",
    "                                                                            [my_wbs[ind].bis for ind in my_face_list[j_0].equs],\\\n",
    "                                                                            my_wbs[my_face_list[i].equs[0]].word)), None)\n",
    "                if j_pair == None:\n",
    "                    mat = (my_wbs[my_face_list[i].equs[0]].word).T @ my_face_list[j].sample_point @ my_wbs[my_face_list[i].equs[0]].word\n",
    "                    if all(np.trace(mat @ my_wbs[ind].bis)> tol for ind in range(len(my_wbs)) if ind not in my_face_list[i_pair].equs):\n",
    "                        unpaired_ridges.append([i, j])\n",
    "    if len(unpaired_ridges) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return unpaired_ridges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core solver functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the polytope structure of the Dirichlet-Selberg domain from generators and center.\n",
    "# The algorithm will thoroughly try all words up to length_1. After this, it searches for unpaired ridges and try to add any words up to length_2 that can pair them.\n",
    "# The algorithm will stop trying after a given loop times eliminating the unpaired ridges.\n",
    "def compute_selberg_domain(generators, length_1, length_2, loop_times, center):\n",
    "    wbs = word_bisectors(generators, length_1, center)\n",
    "    more_wbs = word_bisectors(generators, length_2, center)\n",
    "    my_wbs = []                                           # Initialize the word-bisectors used in the polytope\n",
    "    my_face_list = [Poly_Face([], 0, [], np.array(center))]     # Initialize the polytope, which is just the entire space X_3\n",
    "    for i in tqdm(range(len(wbs)), desc =\"Adding words to the Dirichlet-Selberg domain\"):\n",
    "        my_wbs, my_face_list = selberg_domain_add_facet(my_wbs, my_face_list, wbs[i]) # Add the i-th word-bisector to the polytope\n",
    "    for _ in tqdm(range(loop_times), desc =\"Adding more words to eliminate unpaired ridges\"):\n",
    "        unpaired_ridges = unpaired_ridge(my_wbs, my_face_list)\n",
    "        if unpaired_ridges == None:                           # Stop searching if all ridges are paired\n",
    "            break\n",
    "        else:\n",
    "            facet_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 1]\n",
    "            # print(\"current number of facets:\", len(facet_indices))\n",
    "            # print(\"current number of unpaired ridges\", len(unpaired_ridges))\n",
    "            min_dist = np.inf\n",
    "            new_wb = None                                     # Searching for the candidate bisector closest to the origin\n",
    "            for i, j in unpaired_ridges:\n",
    "                i_pair = next((i_0 for i_0 in facet_indices if np.all(np.abs(my_wbs[my_face_list[i].equs[0]].word @ my_wbs[my_face_list[i_0].equs[0]].word\\\n",
    "                                                                     - np.eye(3))<tol)), None)\n",
    "                j_equations = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                i_pair_equation = my_wbs[my_face_list[i_pair].equs[0]].bis\n",
    "                for k in range(len(more_wbs)):\n",
    "                    if np.trace(more_wbs[k].bis @ np.array(center)) < min_dist:\n",
    "                        candidate_equations = [i_pair_equation, more_wbs[k].bis]\n",
    "                        if equal_spaces(j_equations, candidate_equations, my_wbs[my_face_list[i].equs[0]].word):\n",
    "                            min_dist = np.trace(more_wbs[k].bis @ np.array(center))\n",
    "                            new_wb = more_wbs[k]              # Update the desired bisector if a smaller distance is detected\n",
    "            if new_wb is not None:\n",
    "                my_wbs, my_face_list = selberg_domain_add_facet(my_wbs, my_face_list, new_wb)\n",
    "            # print(\"ridge fixed\")\n",
    "    return my_wbs, my_face_list\n",
    "\n",
    "# The short version of the Dirichlet-Selberg domain computing algorithm\n",
    "def compute_selberg_domain_short(generators, length, center):\n",
    "    my_wbs, my_face_list = compute_selberg_domain(generators, length, length, 0, center)\n",
    "    return my_wbs, my_face_list\n",
    "\n",
    "# Check if a polytope is exact with respect to the canonical facet pairings\n",
    "def polytope_is_exact(my_wbs, my_face_list):\n",
    "    facet_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 1] # Get a list of facets\n",
    "    paired_indices = []\n",
    "    for i in facet_indices:\n",
    "        i_pair = next((j for j in facet_indices if face_is_paired(my_wbs, my_face_list,\\\n",
    "                                                                  i, j, my_wbs[my_face_list[i].equs[0]].word)), None)\n",
    "        if i_pair == None:\n",
    "            return False, facet_indices, None                                           # False if facets are not paired\n",
    "        else:\n",
    "            paired_indices.append(i_pair)\n",
    "    return True, facet_indices, paired_indices                                          # Corresponding facets are canonically paired\n",
    "\n",
    "# Compute the ridge cycles for a given exact polytope in X_3\n",
    "def compute_ridge_cycle(my_wbs, my_face_list):\n",
    "    if not polytope_is_exact(my_wbs, my_face_list):                  # Ridges cycles are defined only for exact polytopes \n",
    "        return None\n",
    "    facet_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 1]\n",
    "    all_ridge_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 2]\n",
    "    ridge_cycle_list = []                                        # Initialize the list of ridge cycles\n",
    "    for i in facet_indices:\n",
    "        ridge_indices = [j for j in my_face_list[i].subfaces if j in all_ridge_indices]\n",
    "        for j in ridge_indices:                                  # Consider the index pair for a facet and a ridge of it\n",
    "            if any(j in ridge_cycle.ridge for ridge_cycle in ridge_cycle_list):\n",
    "                continue                                         # Case if it is already in a ridge cycle\n",
    "            else:\n",
    "                current_ridge = j\n",
    "                current_facet = i                                # Chasing the ridges along the cycle\n",
    "                current_pairing = my_face_list[current_facet].equs[0]\n",
    "                ridge_cycle = Ridge_Cycles([current_ridge], [current_pairing])\n",
    "                for _ in range(2*len(all_ridge_indices)):        # Ridge cycles will not be too long\n",
    "                    mapped_facet = next((mapped_i for mapped_i in facet_indices if \\\n",
    "                                        face_is_paired(my_wbs, my_face_list, current_facet, mapped_i, my_wbs[current_pairing].word)), None)\n",
    "                    new_ridge_indices = [new_j for new_j in my_face_list[mapped_facet].subfaces if new_j in all_ridge_indices]\n",
    "                    new_ridge = next((new_j for new_j in new_ridge_indices if \\\n",
    "                                        face_is_paired(my_wbs, my_face_list, current_ridge, new_j, my_wbs[current_pairing].word)), None)\n",
    "                    new_facet = next(new_i for new_i in facet_indices if new_ridge in my_face_list[new_i].subfaces and new_i != mapped_facet)\n",
    "                    new_pairing = my_face_list[new_facet].equs[0]\n",
    "                    if new_ridge == ridge_cycle.ridge[0] and new_pairing == ridge_cycle.pairing[0]:\n",
    "                        ridge_cycle_list.append(ridge_cycle)      # Add the ridge cycle to ridge_cycle_list if a full cycle is obtained\n",
    "                        break\n",
    "                    else:\n",
    "                        ridge_cycle.ridge.append(new_ridge)       # Shift to the next ridge and facet if the cycle is not completed\n",
    "                        ridge_cycle.pairing.append(new_pairing)\n",
    "                        current_ridge = new_ridge\n",
    "                        current_facet = new_facet\n",
    "                        current_pairing = new_pairing\n",
    "    return ridge_cycle_list\n",
    "\n",
    "# Compute the angle sum for a ridge cycle of a given polytope in X_3\n",
    "# Specifically, the result is a natural number k if the angle sum is 2pi/k, and is None if the ridge cycle does not satisfy this angle sum condition\n",
    "def angle_sum(my_wbs, my_face_list, ridge_cycle):\n",
    "    angle_sum = 0                                           # Initialize the angle sum\n",
    "    point = my_face_list[ridge_cycle.ridge[0]].sample_point # The base point of the first ridge is selected to be the given sample point\n",
    "    for i in range(len(ridge_cycle.ridge)):\n",
    "        first_bis = my_face_list[ridge_cycle.ridge[i]].equs[0]\n",
    "        second_bis = my_face_list[ridge_cycle.ridge[i]].equs[1]\n",
    "        angle = Riemannian_angle(my_wbs[first_bis].bis, my_wbs[second_bis].bis, point) # Compute the Riemannian angle between the bisectors\n",
    "        angle_sum = angle_sum + angle                       # Add this to the angle sum\n",
    "        word = my_wbs[ridge_cycle.pairing[i]].word          \n",
    "        point = word.T @ point @ word                       # Shift to the paired base point of the next ridge\n",
    "    quotient = 2*np.pi/angle_sum                            # Check if the quotient of the angle sum with 2pi is a natural number\n",
    "    quotient_round = round(quotient)\n",
    "    if abs(quotient - quotient_round)> 100*tol:\n",
    "        return None\n",
    "    else:\n",
    "        return quotient_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:17:45.110280Z",
     "iopub.status.busy": "2025-07-06T13:17:45.109357Z",
     "iopub.status.idle": "2025-07-06T13:18:28.214076Z",
     "shell.execute_reply": "2025-07-06T13:18:28.213058Z",
     "shell.execute_reply.started": "2025-07-06T13:17:45.110253Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     38\u001b[39m center = [[\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m],\n\u001b[32m     39\u001b[39m          [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m],\n\u001b[32m     40\u001b[39m          [\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m]]\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# my_wbs, my_face_list = compute_selberg_domain_short(generators, 2, center)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m my_wbs, my_face_list = \u001b[43mcompute_selberg_domain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# ############################# \u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Count the number of faces\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# All edges and four faces of codimension 3 are on the Satake boundary, not computed here\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumber of facets:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28msum\u001b[39m(\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m my_face_list \u001b[38;5;28;01mif\u001b[39;00m face.codim == \u001b[32m1\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcompute_selberg_domain\u001b[39m\u001b[34m(generators, length_1, length_2, loop_times, center)\u001b[39m\n\u001b[32m      7\u001b[39m my_wbs = []                                           \u001b[38;5;66;03m# Initialize the word-bisectors used in the polytope\u001b[39;00m\n\u001b[32m      8\u001b[39m my_face_list = [Poly_Face([], \u001b[32m0\u001b[39m, [], np.array(center))]     \u001b[38;5;66;03m# Initialize the polytope, which is just the entire space X_3\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAdding words to the Dirichlet-Selberg domain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m     10\u001b[39m     my_wbs, my_face_list = selberg_domain_add_facet(my_wbs, my_face_list, wbs[i]) \u001b[38;5;66;03m# Add the i-th word-bisector to the polytope\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(loop_times), desc =\u001b[33m\"\u001b[39m\u001b[33mAdding more words to eliminate unpaired ridges\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/notebook.py:234\u001b[39m, in \u001b[36mtqdm_notebook.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m unit_scale = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    233\u001b[39m total = \u001b[38;5;28mself\u001b[39m.total * unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.container.pbar = proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.displayed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/notebook.py:108\u001b[39m, in \u001b[36mtqdm_notebook.status_printer\u001b[39m\u001b[34m(_, total, desc, ncols)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[32m    110\u001b[39m     pbar = IProgress(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m=total)\n",
      "\u001b[31mImportError\u001b[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# generators = [[[0.5, 0.5, 0],\n",
    "#          [0.5, -0.5, 1],\n",
    "#          [0.5, -0.5, -1]],\n",
    "#               [[-0.5, 1, 0.5],\n",
    "#          [-0.5, -1, 0.5],\n",
    "#          [0.5, 0, 0.5]],\n",
    "#              [[-1, 0.5, -0.5],\n",
    "#          [0, 0.5, 0.5],\n",
    "#          [1, 0.5, -0.5]]]\n",
    "# # Test: Compute the polytope structure\n",
    "generators = [[[0.5, 0.5, 0],\n",
    "         [0.5, -0.5, 1],\n",
    "         [0.5, -0.5, -1]],\n",
    "              [[-0.5, 1, 0.5],\n",
    "         [-0.5, -1, 0.5],\n",
    "         [0.5, 0, 0.5]]]\n",
    "#################################\n",
    "# Test: Compute the polytope structure\n",
    "# generators = [[[1, 2, 0],\n",
    "#                [0, 1, 0],\n",
    "#                [0, 0, 1]],\n",
    "#               [[1, 0, 2],\n",
    "#                [0, 1, 0],\n",
    "#                [0, 0, 1]],\n",
    "#               [[1, 0, 0],\n",
    "#                [0, 1, 2],\n",
    "#                [0, 0, 1]],\n",
    "#               [[1, 0, 0],\n",
    "#                [2, 1, 0],\n",
    "#                [0, 0, 1]],\n",
    "#               [[1, 0, 0],\n",
    "#                [0, 1, 0],\n",
    "#                [2, 0, 1]],\n",
    "#               [[1, 0, 0],\n",
    "#                [0, 1, 0],\n",
    "#                [0, 2, 1]]]\n",
    "center = [[1, 0, 0],\n",
    "         [0, 1, 0],\n",
    "         [0, 0, 1]]\n",
    "# my_wbs, my_face_list = compute_selberg_domain_short(generators, 2, center)\n",
    "my_wbs, my_face_list = compute_selberg_domain(generators, 1, 2, 20, center)\n",
    "# ############################# \n",
    "# Count the number of faces\n",
    "# All edges and four faces of codimension 3 are on the Satake boundary, not computed here\n",
    "print(\"Number of facets:\", sum(1 for face in my_face_list if face.codim == 1))\n",
    "print(\"Number of ridges:\", sum(1 for face in my_face_list if face.codim == 2))\n",
    "print(\"Number of faces of codimension 3:\", sum(1 for face in my_face_list if face.codim == 3))\n",
    "############################# \n",
    "# Make sure every sample point lies on the corresponding plane. Expected to be something close to zero.\n",
    "max_trace = 0\n",
    "for face in my_face_list:\n",
    "    for ind in face.equs:\n",
    "        my_trace = np.trace(my_wbs[ind].bis @ face.sample_point)\n",
    "        max_trace = max(max_trace, abs(my_trace))\n",
    "print(\"The largest trace for sample points multiplying with corresponding facets:\", max_trace)\n",
    "############################# \n",
    "# Make sure every sample point is in the interior. Expected to be a positive number.\n",
    "min_trace = np.inf\n",
    "for face in my_face_list:\n",
    "    for ind in range(len(my_wbs)):\n",
    "        if ind not in face.equs:\n",
    "            my_trace = np.trace(my_wbs[ind].bis @ face.sample_point)\n",
    "            min_trace = min(min_trace, my_trace)\n",
    "print(\"The smallest trace of sample points multiplying with non-corresponding facets:\", min_trace)\n",
    "# print(my_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:20:10.386035Z",
     "iopub.status.busy": "2025-07-06T13:20:10.385642Z",
     "iopub.status.idle": "2025-07-06T13:20:11.427430Z",
     "shell.execute_reply": "2025-07-06T13:20:11.426359Z",
     "shell.execute_reply.started": "2025-07-06T13:20:10.385989Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[Ridge_Cycles(ridge=[16, 19, 29], pairing=[0, 0, 5]), Ridge_Cycles(ridge=[17, 20, 30], pairing=[0, 1, 4]), Ridge_Cycles(ridge=[22, 21, 24], pairing=[0, 2, 2]), Ridge_Cycles(ridge=[26, 25, 18], pairing=[0, 4, 1]), Ridge_Cycles(ridge=[23, 27, 28], pairing=[1, 1, 2])]\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "is_exact, original_facets, paired_facets = polytope_is_exact(my_wbs, my_face_list)\n",
    "print(is_exact)\n",
    "if is_exact:\n",
    "    ridge_cycles = compute_ridge_cycle(my_wbs, my_face_list)\n",
    "    print(ridge_cycles)\n",
    "    for ridge_cycle in ridge_cycles:\n",
    "        print(angle_sum(my_wbs, my_face_list, ridge_cycle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:20:17.470963Z",
     "iopub.status.busy": "2025-07-06T13:20:17.470644Z",
     "iopub.status.idle": "2025-07-06T13:20:17.476056Z",
     "shell.execute_reply": "2025-07-06T13:20:17.474871Z",
     "shell.execute_reply.started": "2025-07-06T13:20:17.470940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "codim_3_list = [my_face for my_face in my_face_list if my_face.codim == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:20:19.535273Z",
     "iopub.status.busy": "2025-07-06T13:20:19.534893Z",
     "iopub.status.idle": "2025-07-06T13:20:19.541142Z",
     "shell.execute_reply": "2025-07-06T13:20:19.540072Z",
     "shell.execute_reply.started": "2025-07-06T13:20:19.535248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5  0.   0. ]\n",
      " [ 0.   0.5 -0.5]\n",
      " [ 0.  -0.5  0.5]]\n",
      "[[ 0.5 -0.5  0. ]\n",
      " [-0.5  0.5  0. ]\n",
      " [ 0.   0.  -0.5]]\n",
      "[[-0.5  0.   0. ]\n",
      " [ 0.   0.5  0.5]\n",
      " [ 0.   0.5  0.5]]\n"
     ]
    }
   ],
   "source": [
    "codim_3 = codim_3_list[0]\n",
    "for equ in codim_3.equs:\n",
    "    print(my_wbs[equ].bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:20:46.025438Z",
     "iopub.status.busy": "2025-07-06T13:20:46.025121Z",
     "iopub.status.idle": "2025-07-06T13:20:46.031683Z",
     "shell.execute_reply": "2025-07-06T13:20:46.030511Z",
     "shell.execute_reply.started": "2025-07-06T13:20:46.025415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5  0. ]\n",
      " [ 0.5 -0.5  1. ]\n",
      " [ 0.5 -0.5 -1. ]]\n",
      "[[-0.5  1.   0.5]\n",
      " [-0.5 -1.   0.5]\n",
      " [ 0.5  0.   0.5]]\n",
      "[[-1.   0.5 -0.5]\n",
      " [ 0.   0.5  0.5]\n",
      " [ 1.   0.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "ridge_cycle = ridge_cycles[1]\n",
    "for wb in ridge_cycle.pairing:\n",
    "    print(my_wbs[wb].word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T13:48:33.636422Z",
     "iopub.status.busy": "2025-07-06T13:48:33.636058Z",
     "iopub.status.idle": "2025-07-06T13:48:33.668398Z",
     "shell.execute_reply": "2025-07-06T13:48:33.667532Z",
     "shell.execute_reply.started": "2025-07-06T13:48:33.636395Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 3, 4)\n",
      "[[ 0.          0.35355339 -0.35355339]\n",
      " [ 0.35355339  0.          0.        ]\n",
      " [-0.35355339  0.          0.        ]]\n",
      "0.0\n",
      "(0, 1, 2, 3, 5)\n",
      "[[ 0.         -0.35355339  0.        ]\n",
      " [-0.35355339  0.          0.35355339]\n",
      " [ 0.          0.35355339  0.        ]]\n",
      "0.0\n",
      "(0, 1, 2, 3, 6)\n",
      "[[ 0.          0.         -0.35355339]\n",
      " [ 0.          0.          0.35355339]\n",
      " [-0.35355339  0.35355339  0.        ]]\n",
      "0.0\n",
      "(0, 1, 2, 4, 5)\n",
      "[[0.         0.         0.35355339]\n",
      " [0.         0.         0.35355339]\n",
      " [0.35355339 0.35355339 0.        ]]\n",
      "0.0\n",
      "(0, 1, 2, 4, 6)\n",
      "[[0.         0.35355339 0.        ]\n",
      " [0.35355339 0.         0.35355339]\n",
      " [0.         0.35355339 0.        ]]\n",
      "0.0\n",
      "(0, 1, 2, 5, 6)\n",
      "[[ 0.         -0.35355339 -0.35355339]\n",
      " [-0.35355339  0.          0.        ]\n",
      " [-0.35355339  0.          0.        ]]\n",
      "0.0\n",
      "(0, 1, 3, 4, 5)\n",
      "[[ 0.00000000e+00 -2.50000000e-01  2.50000000e-01]\n",
      " [-2.50000000e-01 -2.98518123e-16  2.50000000e-01]\n",
      " [ 2.50000000e-01  2.50000000e-01 -5.00000000e-01]]\n",
      "-1.908195823574485e-17\n",
      "(0, 1, 3, 4, 6)\n",
      "[[ 0.00000000e+00  2.50000000e-01 -2.50000000e-01]\n",
      " [ 2.50000000e-01 -2.29629325e-16  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01 -5.00000000e-01]]\n",
      "1.7347234759768093e-17\n",
      "(0, 1, 3, 5, 6)\n",
      "[[ 0.00000000e+00 -2.50000000e-01 -2.50000000e-01]\n",
      " [-2.50000000e-01 -4.59258651e-17  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01  5.00000000e-01]]\n",
      "1.3877787807814488e-17\n",
      "(0, 1, 4, 5, 6)\n",
      "[[ 0.00000000e+00  2.50000000e-01  2.50000000e-01]\n",
      " [ 2.50000000e-01 -6.88887976e-17  2.50000000e-01]\n",
      " [ 2.50000000e-01  2.50000000e-01  5.00000000e-01]]\n",
      "-1.7347234759768093e-17\n",
      "(0, 2, 3, 4, 5)\n",
      "[[ 0.00000000e+00 -2.50000000e-01  2.50000000e-01]\n",
      " [-2.50000000e-01 -5.00000000e-01  2.50000000e-01]\n",
      " [ 2.50000000e-01  2.50000000e-01 -1.11022302e-16]]\n",
      "-1.3877787807814488e-17\n",
      "(0, 2, 3, 4, 6)\n",
      "[[ 0.00000000e+00  2.50000000e-01 -2.50000000e-01]\n",
      " [ 2.50000000e-01 -5.00000000e-01  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01 -8.32667268e-17]]\n",
      "-1.7347234759768136e-18\n",
      "(0, 2, 3, 5, 6)\n",
      "[[ 0.00000000e+00 -2.50000000e-01 -2.50000000e-01]\n",
      " [-2.50000000e-01  5.00000000e-01  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01  1.11022302e-16]]\n",
      "1.0408340855860803e-17\n",
      "(0, 2, 4, 5, 6)\n",
      "[[0.00000000e+00 2.50000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 5.00000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 2.50000000e-01 2.22044605e-16]]\n",
      "1.3877787807814488e-17\n",
      "(0, 3, 4, 5, 6)\n",
      "[[ 0.00000000e+00 -5.55111512e-17 -5.55111512e-17]\n",
      " [-5.55111512e-17  7.07106781e-01 -5.55111512e-17]\n",
      " [-5.55111512e-17 -5.55111512e-17 -7.07106781e-01]]\n",
      "-4.421740811494559e-50\n",
      "(1, 2, 3, 4, 5)\n",
      "[[-5.00000000e-01 -2.50000000e-01  2.50000000e-01]\n",
      " [-2.50000000e-01  0.00000000e+00  2.50000000e-01]\n",
      " [ 2.50000000e-01  2.50000000e-01  2.49800181e-16]]\n",
      "-1.0408340855860803e-17\n",
      "(1, 2, 3, 4, 6)\n",
      "[[-5.00000000e-01  2.50000000e-01 -2.50000000e-01]\n",
      " [ 2.50000000e-01  0.00000000e+00  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01  2.22044605e-16]]\n",
      "-1.3877787807814389e-17\n",
      "(1, 2, 3, 5, 6)\n",
      "[[ 5.00000000e-01 -2.50000000e-01 -2.50000000e-01]\n",
      " [-2.50000000e-01  0.00000000e+00  2.50000000e-01]\n",
      " [-2.50000000e-01  2.50000000e-01 -2.22044605e-16]]\n",
      "-1.3877787807814488e-17\n",
      "(1, 2, 4, 5, 6)\n",
      "[[ 5.00000000e-01  2.50000000e-01  2.50000000e-01]\n",
      " [ 2.50000000e-01  0.00000000e+00  2.50000000e-01]\n",
      " [ 2.50000000e-01  2.50000000e-01 -2.22044605e-16]]\n",
      "-2.0816681711721642e-17\n",
      "(1, 3, 4, 5, 6)\n",
      "[[ 7.07106781e-01 -5.55111512e-17 -5.55111512e-17]\n",
      " [-5.55111512e-17  0.00000000e+00 -5.55111512e-17]\n",
      " [-5.55111512e-17 -5.55111512e-17 -7.07106781e-01]]\n",
      "-4.421740811494559e-50\n",
      "(2, 3, 4, 5, 6)\n",
      "[[ 7.07106781e-01 -5.55111512e-17 -5.55111512e-17]\n",
      " [-5.55111512e-17 -7.07106781e-01 -5.55111512e-17]\n",
      " [-5.55111512e-17 -5.55111512e-17  0.00000000e+00]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "vertices = [[[1, 0, 0],\n",
    "                    [0, 0, 0],\n",
    "                    [0, 0, 0]],\n",
    "                   [[0, 0, 0],\n",
    "                    [0, 1, 0],\n",
    "                    [0, 0, 0]],\n",
    "                   [[0, 0, 0],\n",
    "                    [0, 0, 0],\n",
    "                    [0, 0, 1]],\n",
    "                   [[1, 1, 1],\n",
    "                    [1, 1, 1],\n",
    "                    [1, 1, 1]],\n",
    "                   [[1, -1, -1],\n",
    "                    [-1, 1, 1],\n",
    "                    [-1, 1, 1]],\n",
    "                   [[1, -1, 1],\n",
    "                    [-1, 1, -1],\n",
    "                    [1, -1, 1]],\n",
    "                   [[1, 1, -1],\n",
    "                    [1, 1, -1],\n",
    "                    [-1, -1, 1]]]\n",
    "for inds in itertools.combinations(range(7),5):\n",
    "    points = [vertices[i] for i in inds]\n",
    "    plane_equations = orth_matrix(points)\n",
    "    if len(plane_equations) == 1:\n",
    "        plane_equation = plane_equations[0]\n",
    "        if all(np.trace(plane_equation)*np.trace(plane_equation @ mat) > -1e-10 for mat in vertices):\n",
    "            print(inds)\n",
    "            print(plane_equation)\n",
    "            print(det(plane_equation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# Test: Find the sample point in bad case\n",
    "# Mat_A = [[1, 0, 0],\n",
    "#          [0, -1, 0],\n",
    "#          [0, 0, 0]]\n",
    "# Mat_B = [[[0, 0, 0],\n",
    "#           [0, -1, 0],\n",
    "#           [0, 0, 1]],\n",
    "#          [[0, 1, 0],\n",
    "#           [1, -1, 0],\n",
    "#           [0, 0, 1]],\n",
    "#          [[0, 0, 0],\n",
    "#           [0, 0, 1],\n",
    "#           [0, 1, 0]],\n",
    "#          [[0, 1, 1],\n",
    "#           [1, 0, 1],\n",
    "#           [1, 1, 0]],\n",
    "#          [[0, 0, 1],\n",
    "#           [0, 0, 1],\n",
    "#           [1, 1, 0]],\n",
    "#          [[0, 1, 0],\n",
    "#           [1, 0, 0],\n",
    "#           [0, 0, 0]]]\n",
    "# Q = np.array(random_SL3_qr())\n",
    "# M_1 = Q.T @ Mat_A @ Q\n",
    "# M_2 = Q.T @ Mat_B[0] @ Q\n",
    "M_1 = [[ 1., -1., -1.],\n",
    "       [-1.,  0.,  1.],\n",
    "       [-1.,  1.,  1.]]\n",
    "M_2 = [[0., -1., -1.],\n",
    "       [-1.,  1.,  1.],\n",
    "       [-1.,  1.,  1.]]\n",
    "M_3 = [[0.,  1., -1.],\n",
    "       [ 1.,  1., -1.],\n",
    "       [-1., -1.,  1.]]\n",
    "words = [M_1, M_2, M_3]\n",
    "%time X = find_positive_definite_intersection(words).sample_point\n",
    "print(X)\n",
    "# Y = Q @ X @ Q.T\n",
    "# print(Y)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
