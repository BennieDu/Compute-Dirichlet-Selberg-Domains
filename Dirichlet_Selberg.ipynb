{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "from scipy.linalg import null_space\n",
    "from scipy.linalg import sqrtm\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "from dataclasses import dataclass\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tolerance for numerical computation, set to 1e-10 by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tol = 1e-10 # The absolute tolerance\n",
    "r_tol = 1e-7  # The relative tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Word_Bis:               # The class of bisectors in the symmetric space $X_3$. A list of Word_Bis models describes the bisectors defining the Dirichlet-Selber domain.\n",
    "    word: np.ndarray          # A matrix $g$ in $SL(3,R)$, typically a word in given generators\n",
    "    bis: np.ndarray           # A normal vector (as a 3*3 matrix) of the Selberg bisector $Bis(X, g.X)$\n",
    "\n",
    "@dataclass\n",
    "class Poly_Face:              # The class of faces of polytopes in $X_3$. A list of Poly_Face models describes the polytope structure of the Dirichlet-Selber domain.\n",
    "    equs: list[int]           # A list of bisectors indices (in the list of the accompanying Word_Bis models) whose intersection is the minimal plane containing the face.\n",
    "    codim: int                # The codimension (5 - dim) of the face.\n",
    "    subfaces: list[int]       # A list of face indices that are proper subfaces of the current face.\n",
    "    sample_point: np.ndarray  # A point in $X_3$ (as a 3*3 matrix) lying in the interior of the current face.\n",
    "\n",
    "@dataclass\n",
    "class Find_Intersection:      # The class describing if the union of certain $X_3$ hyperplanes is empty.\n",
    "    sample_point: np.ndarray  # A sample point of the intersection if non-empty, or the zero matrix if empty.\n",
    "    is_intersection: bool     # Boolean variable describing if the intersection is empty.\n",
    "\n",
    "@dataclass\n",
    "class Ridge_Cycle:           # The class describing a ridge-cycle of a Dirichlet-Selberg domain.\n",
    "    ridge: list[int]          # A list of ridge indices (in the list of the accompanying Poly_Face models), for ridges $r_0, r_1, r_2,...$ in the same ridge cycle.\n",
    "    pairing: list[int]        # A list of word indices (in the list of the accompanying Word_Bis models), each word $g_i$ sends $r_i$ to $r_{i+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the new vector is in the span of a independent set of vectors (with tolerance)\n",
    "def in_span(vectors, new_vector):\n",
    "    if len(vectors) == 0:\n",
    "        return np.linalg.norm(new_vector) < a_tol               # The first vector (if nonzero) is independent on its own\n",
    "    matrix = np.array(vectors).T                              # Stack the current independent vectors into a matrix, so each column is a vector    \n",
    "    projection = matrix @ np.linalg.pinv(matrix) @ new_vector # Compute the projection of the new vector onto the space spanned by the existing vectors\n",
    "    residual = new_vector - projection                        # Compute the difference (residual) between the new vector and its projection\n",
    "    return np.linalg.norm(residual) < a_tol                     # The new vector is dependent to the existing ones if the residual is smaller than the threshold\n",
    "\n",
    "# Return a linearly independent subset of vectors (with tolerance)\n",
    "def extract_basis(vectors):\n",
    "    indep_vectors = []\n",
    "    for vector in vectors:\n",
    "        if not in_span(indep_vectors, vector):\n",
    "            indep_vectors.append(vector)\n",
    "    return indep_vectors\n",
    "\n",
    "# Check if the vector tuples span the same subspace\n",
    "def same_span(vectors_A, vectors_B):\n",
    "    rank_A = len(extract_basis(vectors_A))                   # Check if they define the same plane by a rank argument\n",
    "    rank_B = len(extract_basis(vectors_B))\n",
    "    rank_AplusB = len(extract_basis(vectors_A + vectors_B))\n",
    "    return (rank_A == rank_AplusB) and (rank_B == rank_AplusB)\n",
    "    \n",
    "# Check if a symmetric matrix (in np.array) is positive definite. Return true if it is, false if it may not be (concerning the tolerance).\n",
    "def is_positive_definite(matrix):\n",
    "    if not isinstance(matrix, np.ndarray):\n",
    "        raise ValueError(\"Input must be a numpy array.\")\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        return False                                  # The matrix is not square\n",
    "    try:\n",
    "        min_diag = np.min(np.linalg.eigvalsh(matrix)) # Find the smallest eigenvalue\n",
    "        return min_diag > a_tol                         # Positive definite if it is positive (concerning the tolerance).\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False                                  # Not positive definite\n",
    "\n",
    "# Converting between symmetric 3*3 matrices and 6-dimensional vectors\n",
    "def word_to_vector(word, param): #word_to_vector(word, 1)\n",
    "    vector = [word[0][0], word[1][1], word[2][2], param * word[0][1], param * word[0][2], param * word[1][2]]\n",
    "    return vector\n",
    "\n",
    "def vector_to_word(vector, param): #vector_to_word(vector, 1/2)\n",
    "    word = np.array([[vector[0], param * vector[3], param * vector[4]],\n",
    "                     [param * vector[3], vector[1], param * vector[5]],\n",
    "                     [param * vector[4], param * vector[5], vector[2]]])\n",
    "    return word\n",
    "\n",
    "# Find the orthogonal complement of 3*3 symmetric matrices, with respect to the product trace.\n",
    "def orth_matrix(matrices):\n",
    "    vectors = [word_to_vector(matrix, 1) for matrix in matrices]\n",
    "    vectors = extract_basis(vectors)\n",
    "    orth_vectors = null_space(np.array(vectors)).T.tolist()\n",
    "    orth_matrices = [np.array(vector_to_word(orth_vector, 1/2)) for orth_vector in orth_vectors]\n",
    "    return orth_matrices\n",
    "\n",
    "# Convert a matrix of linear expressions in sympy to cvxpy for convex optimization purposes.\n",
    "def sp_to_cp(M_sym, variables):\n",
    "    free_syms = variables\n",
    "    n_vars = len(free_syms)\n",
    "    rows, cols = M_sym.shape                                                                # Get the matrix shape\n",
    "    coeff_matrices = [np.zeros((rows, cols), dtype=np.float64) for _ in range(n_vars + 1)]  # Initialize the coefficient matrices\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):                 \n",
    "            expr = sp.expand(M_sym[i, j])                                                   # Decompose the matrix into entries\n",
    "            if expr.is_Add:                 \n",
    "                terms = expr.as_ordered_terms()                                             # Convert the entry into a list of summands\n",
    "            else:\n",
    "                terms = [expr]                                                              # Simply wrap the entry if it is a single term\n",
    "            for term in terms:\n",
    "                found = False\n",
    "                for idx, sym in enumerate(free_syms):\n",
    "                    if term.has(sym):\n",
    "                        coeff = term.coeff(sym)\n",
    "                        coeff_matrices[idx + 1][i, j] = float(coeff)                        # Add the coefficient of a certain variable to the corresponding matrix\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    coeff_matrices[0][i, j] = float(term)                                   # Add the constant term to the zeroth matrix\n",
    "    x_cvx = cp.Variable(n_vars)                                                             # Define the cvxpy variables\n",
    "    M_cvx = coeff_matrices[0] + sum(x_cvx[i]*coeff_matrices[i+1] for i in range(n_vars))    # Combine the coefficient matrices into a cvxpy matrix with variables\n",
    "    return M_cvx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question-specific helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a basis of vectors perpendicular to a given 3-dimensional vector.\n",
    "# Specifically, given an indefinite vector, the first output vector is positive definite, while the second output vector is indefinite.\n",
    "def compute_vector(d):\n",
    "    positive_indices = [i for i, x in enumerate(d) if x > a_tol]\n",
    "    negative_indices = [i for i, x in enumerate(d) if x < -a_tol]\n",
    "    if not positive_indices or not negative_indices:\n",
    "        return None, None                 # Our program does not focus on definite input vectors\n",
    "    positive_index = positive_indices[0]  # Find the first positive component index of the vector\n",
    "    negative_index = negative_indices[0]  # Find the first negative component index of the vector\n",
    "    d_sorted = [0, 0, 0]                  # Rearrange the components of the vector into (pos, neg, rest)\n",
    "    d_sorted[0] = d[positive_index]       # The positive one becomes d0\n",
    "    d_sorted[1] = d[negative_index]       # The negative one becomes d1\n",
    "    d_sorted[2] = d[3 - positive_index - negative_index] # The remaining becomes d2\n",
    "    d0, d1, d2 = d_sorted\n",
    "    if d2<0:                              # Compute the perpendicular vectors in the new order\n",
    "        v = [-d1/(np.sqrt(d0**2 + d1**2)) - d2/(np.sqrt(d0**2 + d2**2)), d0/(np.sqrt(d0**2 + d1**2)), d0/(np.sqrt(d0**2 + d2**2))]\n",
    "        w = [-d1/(np.sqrt(d0**2 + d1**2)) + d2/(np.sqrt(d0**2 + d2**2)), d0/(np.sqrt(d0**2 + d1**2)), -d0/(np.sqrt(d0**2 + d2**2))]\n",
    "    else:\n",
    "        v = [-d1/(np.sqrt(d0**2 + d1**2)), d0/(np.sqrt(d0**2 + d1**2)) + d2/(np.sqrt(d1**2 + d2**2)), -d1/(np.sqrt(d1**2 + d2**2))]\n",
    "        w = [-d1/(np.sqrt(d0**2 + d1**2)), d0/(np.sqrt(d0**2 + d1**2)) - d2/(np.sqrt(d1**2 + d2**2)), d1/(np.sqrt(d1**2 + d2**2))]\n",
    "    v_original_order = [0, 0, 0]          # Permute the vector back to the original order\n",
    "    v_original_order[positive_index] = v[0]\n",
    "    v_original_order[negative_index] = v[1]\n",
    "    v_original_order[3 - positive_index - negative_index] = v[2]\n",
    "    w_original_order = [0, 0, 0]\n",
    "    w_original_order[positive_index] = w[0]\n",
    "    w_original_order[negative_index] = w[1]\n",
    "    w_original_order[3 - positive_index - negative_index] = w[2]\n",
    "    return v_original_order, w_original_order\n",
    "\n",
    "# Use convex optimization to find positive definite combination of certain 3*3 symmetric matrices\n",
    "def find_pos_def(mat_expr, variables):\n",
    "    t = cp.Variable()\n",
    "    l = len(variables)\n",
    "    x = cp.Variable(l)\n",
    "    M = sp_to_cp(mat_expr, variables)                     # The combination of certain matrices\n",
    "    constraints = [M - t*np.eye(3) >> 0, x >= -1, x <= 1] # Our question only concerns coefficients lying between -1 and 1\n",
    "    prob = cp.Problem(cp.Maximize(t), constraints)        # Find maximal t such that M-tI is positive definite\n",
    "    prob.solve(solver=cp.SCS,eps=a_tol,max_iters=50000)     # Add verbose=True if needed\n",
    "    if prob.value > 100*a_tol:\n",
    "        return M.value                                    # The positive definite linear combination with maximized least eigenvalue\n",
    "    else:\n",
    "        return None                                       # No positive definite linear combinations\n",
    "\n",
    "# Compute the Riemannian angle between two hyperplanes (represented by normal vectors) in X_3 at a certain base point\n",
    "# The formula is given in my paper\n",
    "def Riemannian_angle(equ_1, equ_2, mat):\n",
    "    comp_1 = mat @ equ_1\n",
    "    comp_2 = mat @ equ_2\n",
    "    angle_cos = - (np.trace(comp_1 @ comp_2))/(np.sqrt((np.trace(comp_1 @ comp_1)) * (np.trace(comp_2 @ comp_2))))\n",
    "    angle = np.arccos(angle_cos)\n",
    "    return angle\n",
    "\n",
    "# Find a positive definite matrix on the elongation of the line from the first matrix to the second one\n",
    "def elongate(matrix_1, matrix_2):\n",
    "    matrix_1 = np.array(matrix_1)\n",
    "    matrix_2 = np.array(matrix_2)\n",
    "    if not is_positive_definite(matrix_2):\n",
    "        raise ValueError(\"elongate: Input must be positive definite.\")\n",
    "    else:\n",
    "        matrix = 2*matrix_2 - matrix_1            # The elongation\n",
    "        while not is_positive_definite(matrix):   # Go back toward matrix_2 if matrix is indefinite\n",
    "            matrix = 0.5*matrix + 0.5*matrix_2\n",
    "        matrix = matrix/((det(matrix)) ** (1/3))  # Unitize the matrix with respect to the determinant\n",
    "        return np.array(matrix)\n",
    "\n",
    "# The input positive definite matrix lies on the plane defined by some equations as well as a new equation\n",
    "# Perturb it to the positive side of the hyperplane defined by the new equation while remaining positive definite and lying on the plane defined by the old equations\n",
    "def perturb_within_plane(matrix, equations, new_equation):\n",
    "    matrix = np.array(matrix)                                                           # make the matrices numpy for safety reason\n",
    "    equations = [np.array(equation) for equation in equations]\n",
    "    new_equation = np.array(new_equation)\n",
    "    if not is_positive_definite(matrix):\n",
    "        raise ValueError(\"perturb_within_plane: Input must be positive definite.\")\n",
    "    else:\n",
    "        matrix_sqrt = sqrtm(matrix)                                                     # Congruence so the input matrix is taken to the origin\n",
    "        equations_trans = [matrix_sqrt @ equ @ matrix_sqrt for equ in equations]\n",
    "        new_equation_trans = matrix_sqrt @ new_equation @ matrix_sqrt\n",
    "        orth_equations = orth_matrix(equations_trans)\n",
    "        orth_vectors = [word_to_vector(equation, np.sqrt(2)) for equation in orth_equations]    # Convert from matrices to vectors\n",
    "        new_vector = word_to_vector(new_equation_trans, np.sqrt(2))\n",
    "        orth_vectors_matrix = np.array(orth_vectors).T                                  # Stack the current independent vectors into a matrix, each column is a vector\n",
    "        coeffs = list(np.linalg.pinv(orth_vectors_matrix) @ new_vector)                 # Project the new vector to the existing ones\n",
    "        projection_trans = sum(coeff*equ for coeff, equ in zip(coeffs, orth_equations)) # This linear combination lies on the desired plane while keeps away from the new hyperplane\n",
    "        projection = matrix_sqrt @ projection_trans @ matrix_sqrt                       # Take the matrix back\n",
    "        while not is_positive_definite(projection):\n",
    "            projection = 0.5*projection + 0.5*matrix                                    # Go back toward the original matrix if the new one is indefinite\n",
    "        projection = projection/((det(projection)) ** (1/3))                            # Unitize the matrix with respect to the determinant\n",
    "        return projection\n",
    "\n",
    "# Check if the word in SL(3,R) takes the old plane (defined by a set of normal matrices) to the new plane\n",
    "def equal_spaces(old_equations, new_equations, word):\n",
    "    mapped_equations = [inv(word) @ mat @ inv(word.T) for mat in old_equations] # The normal matrices for the mapped plane\n",
    "    mapped_vectors = [word_to_vector(mat, 1) for mat in mapped_equations]          # Convert from matrices to vectors\n",
    "    new_vectors = [word_to_vector(mat, 1) for mat in new_equations]\n",
    "    return same_span(mapped_vectors, new_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute for all distinct words of a given maximal length from given generators in SL(3,R)\n",
    "def distinct_matrix_products(generators, max_length):\n",
    "    generators = [np.array(mat) for mat in generators] # Make sure they are numpy arrays\n",
    "    k = len(generators)\n",
    "    G = generators + [inv(mat) for mat in generators]\n",
    "    inv_idx = lambda j: (j + k) % (2*k)\n",
    "    seen = [np.eye(generators[0].shape[0])]  # The list of matrices and last-index-list, List[np.ndarray]\n",
    "    frontier = {0: set()} # Dict[int, Set[int]]\n",
    "    for _ in range(max_length):\n",
    "        next_frontier = {}  # Dict[int, Set[int]] \n",
    "        for ind in frontier:            # A tuple of word and a possible last-index\n",
    "            for j, mat in enumerate(G):        # A tuple of generator and its index to be added\n",
    "                if inv_idx(j) in frontier[ind]:\n",
    "                    continue                   # Avoid backtracking\n",
    "                N = seen[ind] @ mat                    # If not, add the generator to the end of the word\n",
    "                matched = False\n",
    "                for S_ind in range(len(seen)):\n",
    "                    if np.allclose(N, seen[S_ind], atol = a_tol, rtol = r_tol): # The word is already there; if it is in next_frontier, add a last-index\n",
    "                        matched = True\n",
    "                        if S_ind in next_frontier:\n",
    "                            next_frontier[S_ind].add(j)\n",
    "                        break\n",
    "                if not matched:\n",
    "                    seen.append(N)\n",
    "                    N_ind = len(seen) - 1\n",
    "                    next_frontier[N_ind] = set()\n",
    "                    next_frontier[N_ind].add(j)\n",
    "        frontier = next_frontier\n",
    "        if not frontier:\n",
    "            break\n",
    "    seen.sort(key=lambda M: np.trace(M.T @ M)) # sort by Frobenius norm\n",
    "    return seen\n",
    "\n",
    "# Compute bisectors Bis(X, g.X) (as in dataclass Word_Bis) from a list of generators, a maximal word length and a center X\n",
    "# Words that stabilize X will be excluded for well-defined bisectors\n",
    "def word_bisectors(generators, length, center):\n",
    "    words = distinct_matrix_products(generators, length)\n",
    "    wbs = [Word_Bis(word, np.array(word) @ inv(np.array(center)) @ np.array(word).T - inv(np.array(center)))\\\n",
    "           for word in words]                                                # Definition of Selberg bisectors\n",
    "    wbs_filtered = [wb for wb in wbs if not np.all(np.abs(wb.bis)<a_tol)]      # Exclude bisectors with zero normal matrices\n",
    "    return wbs_filtered\n",
    "\n",
    "# Determine if the intersection of given hyperplanes is non-empty. Produce a sample point if so.\n",
    "def find_positive_definite_intersection(words):\n",
    "    ################## Part 1: Consider a linearly independent sublist\n",
    "    vectors = [word_to_vector(word, 1) for word in words]\n",
    "    independent_vectors = extract_basis(vectors)\n",
    "    indep_matrix = [vector_to_word(vec, 1) for vec in independent_vectors]\n",
    "    indep_matrix_sp = [sp.Matrix(mat) for mat in indep_matrix]\n",
    "    ################### Part 2: The non-case\n",
    "    A = indep_matrix[0]\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(A)\n",
    "    ev_orth, ev_orth_neg = compute_vector(eigenvalues)\n",
    "    if ev_orth is None:\n",
    "        sample_point = np.zeros((3, 3)) \n",
    "        is_intersection = False\n",
    "    else:\n",
    "        n = len(indep_matrix)\n",
    "        Q = eigenvectors\n",
    "        D_orth = np.diag(ev_orth)\n",
    "    ################### Part 3: The case if n = 1\n",
    "        if n == 1:\n",
    "            sample_point = Q @ D_orth @ Q.T\n",
    "            is_intersection = True\n",
    "    ################### Part 4: The case if n > 1, we will begin canceling the variables\n",
    "        else:\n",
    "            linearized_matrix = [Q.T @ mat @ Q for mat in indep_matrix]\n",
    "            linearized_matrix_sp = [sp.Matrix(mat) for mat in linearized_matrix]\n",
    "            x_v = sp.symbols('x1:5')\n",
    "            x_v_new = x_v #The necessary variables\n",
    "            diag_max = [a + abs(b) for a, b in zip(ev_orth, ev_orth_neg)]\n",
    "            D_orth_neg = [np.diag(ev_orth_neg),\\\n",
    "                        vector_to_word(np.sqrt(diag_max[0]*diag_max[1]) * np.eye(6)[:, 3], 1),\\\n",
    "                        vector_to_word(np.sqrt(diag_max[0]*diag_max[2]) * np.eye(6)[:, 4], 1),\\\n",
    "                        vector_to_word(np.sqrt(diag_max[1]*diag_max[2]) * np.eye(6)[:, 5], 1)]\n",
    "            D_orth_sp = sp.Matrix(D_orth)\n",
    "            D_orth_neg_sp = [sp.Matrix(mat) for mat in D_orth_neg]\n",
    "            matrix_comb = sum((var * mat for mat, var in zip(D_orth_neg_sp, x_v)), start=D_orth_sp)\n",
    "            # Remove extra variables\n",
    "            for i in range(1,n):\n",
    "                trace_matrix_prod = (matrix_comb * linearized_matrix_sp[i]).trace().expand()\n",
    "                trace_coeffs = {var: trace_matrix_prod.coeff(var) for var in x_v}\n",
    "                #If a nonzero constant appears, return to false since it is surely empty.\n",
    "                if all(abs(coeff) < a_tol for coeff in trace_coeffs.values()):\n",
    "                    sample_point = np.zeros((3, 3)) \n",
    "                    is_intersection = False\n",
    "                    return Find_Intersection(np.array(sample_point), is_intersection) \n",
    "                max_var = max(trace_coeffs, key=lambda v: abs(trace_coeffs[v]))\n",
    "                x_sol = sp.solve(trace_matrix_prod, max_var)[0]  # Solve f = 0 for max_var\n",
    "                x_v_new = tuple(var for var in x_v_new if var != max_var) # Drop max_var from x_v_new\n",
    "                matrix_comb = matrix_comb.subs(max_var,x_sol)\n",
    "            # If all variables are removed\n",
    "            if n == 5:\n",
    "                D = np.array(matrix_comb).astype(np.float64)\n",
    "                if is_positive_definite(D):\n",
    "                    sample_point = Q @ D @ Q.T\n",
    "                    is_intersection = True\n",
    "                else:\n",
    "                    sample_point = np.zeros((3, 3)) \n",
    "                    is_intersection = False\n",
    "            # Set the equations\n",
    "            else:\n",
    "                poly_comb = matrix_comb.det()\n",
    "                poly_comb_coeff = poly_comb.as_coefficients_dict()\n",
    "                all_zero = all(abs(coef) < a_tol for coef in poly_comb_coeff.values())\n",
    "                if all_zero:\n",
    "                    sample_point = np.zeros((3, 3)) \n",
    "                    is_intersection = False\n",
    "                else:\n",
    "                    D = find_pos_def(matrix_comb, x_v_new)\n",
    "                    if D is None:\n",
    "                        sample_point = np.zeros((3, 3)) \n",
    "                        is_intersection = False\n",
    "                    else:\n",
    "                        sample_point = Q @ D @ Q.T\n",
    "                        is_intersection = True\n",
    "    if is_intersection:\n",
    "        if not is_positive_definite(sample_point):\n",
    "            is_intersection = False\n",
    "            sample_point = np.zeros((3, 3))\n",
    "        else:\n",
    "            sample_point = sample_point/((det(sample_point)) ** (1/3))\n",
    "    return Find_Intersection(np.array(sample_point), is_intersection)\n",
    "\n",
    "# Add a new bisector new_wb to the existing polytope in X_3 and compute for the new polytope structure.\n",
    "# The existing bisectors are described by my_wbs and the polytope structure is described by my_face_list. \n",
    "def selberg_domain_add_facet(my_wbs, my_face_list, new_wb):\n",
    "    new_vec = word_to_vector(new_wb.bis, 1)\n",
    "    # Assign to each face a case number\n",
    "    my_temp_list = [0]*len(my_face_list)\n",
    "    # After each round, I will always sort the elements so their codimensions are small to large.\n",
    "    for j in range(len(my_temp_list)):\n",
    "        # If the equations defining F_j span the new equation\n",
    "        face_equs = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "        face_vecs = [word_to_vector(equ, 1) for equ in face_equs]\n",
    "        if in_span(extract_basis(face_vecs), new_vec):\n",
    "            my_temp_list[j] = 1\n",
    "        # If the face is a minimal face. Since excellent me always sorts the faces, I can always check j from small to large.\n",
    "        elif my_face_list[j].subfaces == []:\n",
    "            # if the new hyperplane intersects with the minimal face, it's type 6\n",
    "            if find_positive_definite_intersection(face_equs + [new_wb.bis]).is_intersection:\n",
    "                my_temp_list[j] = 6\n",
    "            # if the new hyperplane does not intersect with the minimal face, it's type 2 or 4\n",
    "            else:\n",
    "                face_sample_point = my_face_list[j].sample_point\n",
    "                if np.trace(face_sample_point @ new_wb.bis) > 0:\n",
    "                    my_temp_list[j] = 2\n",
    "                else:\n",
    "                    my_temp_list[j] = 4\n",
    "        # If the face has subfaces.\n",
    "        else:\n",
    "            face_subfaces = my_face_list[j].subfaces\n",
    "            face_subfaces_temp = [my_temp_list[ind] for ind in face_subfaces]\n",
    "            # If the type of either subface is 6.\n",
    "            if 6 in face_subfaces_temp:\n",
    "                my_temp_list[j] = 6\n",
    "            # If the type of a subface is 2 or 3, while which of the other subface is 4 or 5.\n",
    "            elif {2, 3} & set(face_subfaces_temp) and {4, 5} & set(face_subfaces_temp):\n",
    "                my_temp_list[j] = 6\n",
    "            # If the type of a subface is 1, 3, or 5.\n",
    "            elif {1, 3, 5} & set(face_subfaces_temp):\n",
    "                face_sample_point = my_face_list[j].sample_point\n",
    "                if np.trace(face_sample_point @ new_wb.bis) > 0:\n",
    "                    my_temp_list[j] = 3\n",
    "                else:\n",
    "                    my_temp_list[j] = 5\n",
    "            # Types of all subfaces are 2, or are 4.\n",
    "            else:\n",
    "                # If the new hyperplane intersects the span of the face\n",
    "                if find_positive_definite_intersection(face_equs + [new_wb.bis]).is_intersection:\n",
    "                    # Sample point of this intersection\n",
    "                    face_inters_sample_point = find_positive_definite_intersection(face_equs + [new_wb.bis]).sample_point\n",
    "                    # Find out the equations shape the sides of the face \n",
    "                    face_subfaces_equs = []\n",
    "                    for ind in face_subfaces:\n",
    "                        if my_face_list[ind].codim == my_face_list[j].codim + 1:\n",
    "                            face_subfaces_equs_temp = [elem for elem in my_face_list[ind].equs if elem not in my_face_list[j].equs]\n",
    "                            face_subfaces_equs[:] = list(set(face_subfaces_equs) | set(face_subfaces_equs_temp))\n",
    "                    # Assume the type is 6\n",
    "                    my_temp_list[j] = 6\n",
    "                    for ind in face_subfaces_equs:\n",
    "                        # However, if any side separates the sample point from the face, the type is either 2 or 4\n",
    "                        if np.trace(face_inters_sample_point @ my_wbs[ind].bis) < 0:\n",
    "                            my_temp_list[j] = face_subfaces_temp[0]\n",
    "                            break\n",
    "                # If the new hyperplane does not intersect the span of the face, the type is either 2 or 4\n",
    "                else:\n",
    "                    my_temp_list[j] = face_subfaces_temp[0]\n",
    "    # If the face is of type 4 or 5, it will be deleted.\n",
    "    ind_remove_list = [j for j in range(len(my_temp_list)) if my_temp_list[j] in [4, 5]]\n",
    "    for j in sorted(ind_remove_list, reverse=True):\n",
    "        del my_face_list[j]\n",
    "        del my_temp_list[j]\n",
    "    # The presence of these faces in subfaces is also erased.\n",
    "    for j in range(len(my_temp_list)):\n",
    "        my_face_list[j].subfaces = [ind for ind in my_face_list[j].subfaces if ind not in ind_remove_list]\n",
    "        List_subfaces_temp = []\n",
    "        for ind in my_face_list[j].subfaces:\n",
    "            decrease = sum(1 for val in ind_remove_list if val < ind)\n",
    "            List_subfaces_temp.append(ind - decrease)\n",
    "        my_face_list[j].subfaces = List_subfaces_temp.copy()\n",
    "    # Update the remaining elements\n",
    "    for j in range(len(my_temp_list)):\n",
    "        # If the face is of type 1, the new equation will be added.\n",
    "        if my_temp_list[j] == 1:\n",
    "            my_face_list[j].equs.append(len(my_wbs))\n",
    "        # If the face is of type 6:\n",
    "        elif my_temp_list[j] == 6:\n",
    "            # Equations for new face\n",
    "            new_face_equs = my_face_list[j].equs + [len(my_wbs)]\n",
    "            # Codimension of new face\n",
    "            new_face_codim = my_face_list[j].codim + 1\n",
    "            # Subfaces for both old and new faces\n",
    "            new_face_subfaces = [ind for ind in my_face_list[j].subfaces if my_temp_list[ind] == 1]\n",
    "            for ind in my_face_list[j].subfaces:\n",
    "                if ind < len(my_temp_list):\n",
    "                    if my_temp_list[ind] == 6:\n",
    "                        my_face_list[j].subfaces.append(my_face_list[ind].subfaces[-1])\n",
    "                        new_face_subfaces.append(my_face_list[ind].subfaces[-1])\n",
    "            my_face_list[j].subfaces.append(len(my_face_list))\n",
    "            # Sample point for the new face\n",
    "            if len(new_face_subfaces) == 0:\n",
    "                face_equs = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                new_face_sample_point = find_positive_definite_intersection(face_equs + [new_wb.bis]).sample_point\n",
    "            elif len(new_face_subfaces) >= 2:\n",
    "                new_face_sample_point = sum((my_face_list[ind].sample_point for ind in new_face_subfaces), np.zeros((3, 3)))\n",
    "                new_face_sample_point = new_face_sample_point/((det(new_face_sample_point)) ** (1/3))\n",
    "            # If only one subface\n",
    "            else:\n",
    "                face_equs = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                # subface_equ_ind = first_unique_element(my_face_list[new_face_subfaces[0]].equs, new_face_equs)\n",
    "                subface_equ_ind = next((ind for ind in my_face_list[new_face_subfaces[0]].equs if ind not in set(new_face_equs)), None)\n",
    "                subface_equ = my_wbs[subface_equ_ind].bis\n",
    "                subface_sample_point = my_face_list[new_face_subfaces[0]].sample_point\n",
    "                new_face_sample_point = perturb_within_plane(subface_sample_point, face_equs + [new_wb.bis], subface_equ)\n",
    "            # Sample point for the old face\n",
    "            if np.trace(my_face_list[j].sample_point @ new_wb.bis) < np.sqrt(a_tol):\n",
    "                face_equs = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                old_face_sample_point = perturb_within_plane(new_face_sample_point, face_equs, new_wb.bis)\n",
    "                # Check if this point is inside the polytope. \n",
    "                # The new face will be good. Moreover, if the old sample point is on the face, it will be fine.\n",
    "                # To make it safe, add that ind is not in my_face_list[j].equs\n",
    "                while any(ind not in my_face_list[j].equs and np.trace(wb.bis @ my_face_list[j].sample_point) > a_tol\\\n",
    "                          and np.trace(wb.bis @ old_face_sample_point) < a_tol for ind, wb in enumerate(my_wbs)):\n",
    "                    old_face_sample_point = 0.5*(old_face_sample_point + new_face_sample_point)\n",
    "                temporary_sample_point = 0.5*(old_face_sample_point + new_face_sample_point)\n",
    "                temporary_sample_point = temporary_sample_point/((det(temporary_sample_point)) ** (1/3))\n",
    "                my_face_list[j].sample_point = temporary_sample_point\n",
    "            # Save the new face to my_face_list\n",
    "            my_face_list.append(Poly_Face(new_face_equs, new_face_codim, new_face_subfaces, np.array(new_face_sample_point)))\n",
    "    # Save the new equation to bises_active\n",
    "    my_wbs.append(new_wb)\n",
    "    # Remove the unnecessary equations\n",
    "    equ_remove_list = list(range(len(my_wbs)))\n",
    "    for j in range(len(my_face_list)):\n",
    "        if my_face_list[j].codim == 1:\n",
    "            equ_remove_list = [ind for ind in equ_remove_list if ind != my_face_list[j].equs[0]]\n",
    "    for j in sorted(equ_remove_list, reverse=True):\n",
    "        del my_wbs[j]\n",
    "    for j in range(len(my_face_list)):\n",
    "        my_face_list[j].equs = [ind for ind in my_face_list[j].equs if ind not in equ_remove_list]\n",
    "        List_equs_temp = []\n",
    "        for ind in my_face_list[j].equs:\n",
    "            decrease = sum(1 for val in equ_remove_list if val < ind)\n",
    "            List_equs_temp.append(ind - decrease)\n",
    "        my_face_list[j].equs = List_equs_temp.copy()\n",
    "    # Sort the faces again, including the subfaces\n",
    "    my_face_list_indexed = [(i, face) for i, face in enumerate(my_face_list)]\n",
    "    my_face_list_indexed.sort(key=lambda obj: obj[1].codim, reverse=True)\n",
    "    index_mapping = {old_index: new_index for new_index, (old_index, _) in enumerate(my_face_list_indexed)}\n",
    "    for _, face in my_face_list_indexed:\n",
    "        face.subfaces = [index_mapping[ind] for ind in face.subfaces]\n",
    "    my_face_list = [face for _, face in my_face_list_indexed]\n",
    "    return my_wbs, my_face_list\n",
    "\n",
    "# Check if two given faces are paired by a given word.\n",
    "# The bisectors are described by my_wbs. The polytope structure is described by my_face_list.\n",
    "def face_is_paired(my_wbs, my_face_list, old_face_ind, new_face_ind, word):\n",
    "    if my_face_list[old_face_ind].codim != my_face_list[new_face_ind].codim:\n",
    "        return False\n",
    "    if len(my_face_list[old_face_ind].subfaces) != len(my_face_list[new_face_ind].subfaces):\n",
    "        return False\n",
    "    old_face_equations = [my_wbs[ind].bis for ind in my_face_list[old_face_ind].equs]\n",
    "    new_face_equations = [my_wbs[ind].bis for ind in my_face_list[new_face_ind].equs]\n",
    "    if not equal_spaces(old_face_equations, new_face_equations, word):\n",
    "        return False\n",
    "    if len(my_face_list[old_face_ind].subfaces) == 0:\n",
    "        return True\n",
    "    cod = my_face_list[old_face_ind].codim\n",
    "    old_facets = [j for j in my_face_list[old_face_ind].subfaces if my_face_list[j].codim == cod + 1]\n",
    "    new_facets = [k for k in my_face_list[new_face_ind].subfaces if my_face_list[k].codim == cod + 1]\n",
    "    if len(old_facets) != len(new_facets):\n",
    "        return False\n",
    "    for j in old_facets:\n",
    "        if not any(face_is_paired(my_wbs, my_face_list, j, k, word) for k in new_facets):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Find unpaired ridges in a non-exact (pre-)Dirichlet-Selberg domain\n",
    "def unpaired_ridge(my_wbs, my_face_list):\n",
    "    facet_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 1]\n",
    "    unpaired_ridges = []\n",
    "    for i in facet_indices:\n",
    "        i_ridges = [j for j in my_face_list[i].subfaces if my_face_list[j].codim == 2]\n",
    "        i_pair = next((i_0 for i_0 in facet_indices if np.all(np.abs(my_wbs[my_face_list[i].equs[0]].word @ my_wbs[my_face_list[i_0].equs[0]].word\\\n",
    "                                                                     - np.eye(3))<a_tol)), None)\n",
    "        if i_pair != None:\n",
    "            i_pair_ridges = [j_0 for j_0 in my_face_list[i_pair].subfaces if my_face_list[j_0].codim == 2]\n",
    "            for j in i_ridges:\n",
    "                j_equations = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                j_pair = next((j_0 for j_0 in i_pair_ridges if equal_spaces(j_equations,\\\n",
    "                                        [my_wbs[ind].bis for ind in my_face_list[j_0].equs],my_wbs[my_face_list[i].equs[0]].word)), None)\n",
    "                if j_pair == None:\n",
    "                    mat = (my_wbs[my_face_list[i].equs[0]].word).T @ my_face_list[j].sample_point @ my_wbs[my_face_list[i].equs[0]].word\n",
    "                    if all(np.trace(mat @ my_wbs[ind].bis)> a_tol for ind in range(len(my_wbs)) if ind not in my_face_list[i_pair].equs):\n",
    "                        unpaired_ridges.append([i, j])\n",
    "    return unpaired_ridges\n",
    "\n",
    "# Find the word that takes the destination point into the Dirichlet-Selberg domain\n",
    "def path_word(my_wbs, my_face_list, dest_point):\n",
    "    if not is_positive_definite(dest_point):\n",
    "        raise ValueError(\"path_word: destination point must be positive definite.\")\n",
    "    dest_point = dest_point/(det(dest_point) ** (1/3))                            # Normalize the destination point\n",
    "    center = next(face.sample_point for face in my_face_list if face.codim == 0)  # The center is the sample point of the polytope itself\n",
    "    if all(np.trace(dest_point @ wb.bis)>-a_tol for wb in my_wbs):                  # If the destination is already in the Dirichlet-Selberg domain\n",
    "        return []\n",
    "    meet_ind = max(range(len(my_wbs)), key = lambda i: -(np.trace(dest_point @ my_wbs[i].bis))/(np.trace(center @ my_wbs[i].bis)))\n",
    "    meet_word = my_wbs[meet_ind].word                                             # The word corresponding to the first bisector meeting the ray from the center towards the destination\n",
    "    new_dest = meet_word.T @ dest_point @ meet_word                               # Take the destination closer to the center\n",
    "    new_path = path_word(my_wbs, my_face_list, new_dest)\n",
    "    new_path.insert(0, meet_ind)\n",
    "    return new_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core solver functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the polytope structure of the Dirichlet-Selberg domain from generators and center.\n",
    "# The algorithm will thoroughly try all words up to length_1. After this, it searches for unpaired ridges and try to add any words up to length_2 that can pair them.\n",
    "# The algorithm will stop trying after a given loop times eliminating the unpaired ridges.\n",
    "def compute_selberg_domain(generators, length_1, length_2, loop_times, center):\n",
    "    wbs = word_bisectors(generators, length_1, center)\n",
    "    more_wbs = word_bisectors(generators, length_2, center)\n",
    "    my_wbs = []                                           # Initialize the word-bisectors used in the polytope\n",
    "    my_face_list = [Poly_Face([], 0, [], np.array(center))]     # Initialize the polytope, which is just the entire space X_3\n",
    "    for i in tqdm(range(len(wbs)), desc =\"Adding words to the Dirichlet-Selberg domain\"):\n",
    "        my_wbs, my_face_list = selberg_domain_add_facet(my_wbs, my_face_list, wbs[i]) # Add the i-th word-bisector to the polytope\n",
    "    for _ in tqdm(range(loop_times), desc =\"Adding more words to eliminate unpaired ridges\"):\n",
    "        unpaired_ridges = unpaired_ridge(my_wbs, my_face_list)\n",
    "        if not unpaired_ridges:                           # Stop searching if all ridges are paired\n",
    "            break\n",
    "        else:\n",
    "            facet_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 1]\n",
    "            # print(\"current number of facets:\", len(facet_indices))\n",
    "            # print(\"current number of unpaired ridges\", len(unpaired_ridges))\n",
    "            min_dist = np.inf\n",
    "            new_wb = None                                     # Searching for the candidate bisector closest to the origin\n",
    "            for i, j in unpaired_ridges:\n",
    "                i_pair = next((i_0 for i_0 in facet_indices if np.all(np.abs(my_wbs[my_face_list[i].equs[0]].word @ my_wbs[my_face_list[i_0].equs[0]].word\\\n",
    "                                                                     - np.eye(3))<a_tol)), None)\n",
    "                j_equations = [my_wbs[ind].bis for ind in my_face_list[j].equs]\n",
    "                i_pair_equation = my_wbs[my_face_list[i_pair].equs[0]].bis\n",
    "                for k in range(len(more_wbs)):\n",
    "                    if np.trace(more_wbs[k].bis @ np.array(center)) < min_dist:\n",
    "                        candidate_equations = [i_pair_equation, more_wbs[k].bis]\n",
    "                        if equal_spaces(j_equations, candidate_equations, my_wbs[my_face_list[i].equs[0]].word):\n",
    "                            min_dist = np.trace(more_wbs[k].bis @ np.array(center))\n",
    "                            new_wb = more_wbs[k]              # Update the desired bisector if a smaller distance is detected\n",
    "            if new_wb is not None:\n",
    "                my_wbs, my_face_list = selberg_domain_add_facet(my_wbs, my_face_list, new_wb)\n",
    "            # print(\"ridge fixed\")\n",
    "    return my_wbs, my_face_list\n",
    "\n",
    "# The short version of the Dirichlet-Selberg domain computing algorithm\n",
    "def compute_selberg_domain_short(generators, length, center):\n",
    "    my_wbs, my_face_list = compute_selberg_domain(generators, length, length, 0, center)\n",
    "    return my_wbs, my_face_list\n",
    "\n",
    "# Check if a polytope is exact with respect to the canonical facet pairings\n",
    "def polytope_is_exact(my_wbs, my_face_list):\n",
    "    facet_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 1] # Get a list of facets\n",
    "    paired_indices = []\n",
    "    for i in facet_indices:\n",
    "        i_pair = next((j for j in facet_indices if face_is_paired(my_wbs, my_face_list,\\\n",
    "                                                                  i, j, my_wbs[my_face_list[i].equs[0]].word)), None)\n",
    "        if i_pair == None:\n",
    "            return False, facet_indices, None                                           # False if facets are not paired\n",
    "        else:\n",
    "            paired_indices.append(i_pair)\n",
    "    return True, facet_indices, paired_indices                                          # Corresponding facets are canonically paired\n",
    "\n",
    "# Compute the ridge cycles for a given exact polytope in X_3. Will rewrite to utilize polytope_is_exact() more\n",
    "def compute_ridge_cycle(my_wbs, my_face_list):\n",
    "    is_exact, facet_indices, paired_indices = polytope_is_exact(my_wbs, my_face_list)\n",
    "    if not is_exact:                  # Ridges cycles are defined only for exact polytopes \n",
    "        return None\n",
    "    all_ridge_indices = [i for i in range(len(my_face_list)) if my_face_list[i].codim == 2]\n",
    "    ridge_cycle_list = []                                        # Initialize the list of ridge cycles\n",
    "    for i in facet_indices:\n",
    "        ridge_indices = [j for j in my_face_list[i].subfaces if j in all_ridge_indices]\n",
    "        for j in ridge_indices:                                  # Consider the index pair for a facet and a ridge of it\n",
    "            if any(j in ridge_cycle.ridge for ridge_cycle in ridge_cycle_list):\n",
    "                continue                                         # Case if it is already in a ridge cycle\n",
    "            current_ridge = j\n",
    "            current_facet = i                                # Chasing the ridges along the cycle\n",
    "            current_pairing = my_face_list[current_facet].equs[0]\n",
    "            ridge_cycle = Ridge_Cycle([current_ridge], [current_pairing])\n",
    "            for _ in range(2*len(all_ridge_indices)):        # Ridge cycles will not be too long\n",
    "                mapped_facet = next((mapped_i for mapped_i in facet_indices if \\\n",
    "                                    face_is_paired(my_wbs, my_face_list, current_facet, mapped_i, my_wbs[current_pairing].word)), None)\n",
    "                new_ridge_indices = [new_j for new_j in my_face_list[mapped_facet].subfaces if new_j in all_ridge_indices]\n",
    "                new_ridge = next((new_j for new_j in new_ridge_indices if \\\n",
    "                                    face_is_paired(my_wbs, my_face_list, current_ridge, new_j, my_wbs[current_pairing].word)), None)\n",
    "                new_facet = next(new_i for new_i in facet_indices if new_ridge in my_face_list[new_i].subfaces and new_i != mapped_facet)\n",
    "                new_pairing = my_face_list[new_facet].equs[0]\n",
    "                if new_ridge == ridge_cycle.ridge[0] and new_pairing == ridge_cycle.pairing[0]:\n",
    "                    ridge_cycle_list.append(ridge_cycle)      # Add the ridge cycle to ridge_cycle_list if a full cycle is obtained\n",
    "                    break\n",
    "                ridge_cycle.ridge.append(new_ridge)       # Shift to the next ridge and facet if the cycle is not completed\n",
    "                ridge_cycle.pairing.append(new_pairing)\n",
    "                current_ridge = new_ridge\n",
    "                current_facet = new_facet\n",
    "                current_pairing = new_pairing\n",
    "    return ridge_cycle_list\n",
    "\n",
    "# Compute the angle sum for a ridge cycle of a given polytope in X_3\n",
    "# Specifically, the result is a natural number k if the angle sum is 2pi/k, and is None if the ridge cycle does not satisfy this angle sum condition\n",
    "def angle_sum(my_wbs, my_face_list, ridge_cycle):\n",
    "    angle_sum = 0                                           # Initialize the angle sum\n",
    "    point = my_face_list[ridge_cycle.ridge[0]].sample_point # The base point of the first ridge is selected to be the given sample point\n",
    "    for i in range(len(ridge_cycle.ridge)):\n",
    "        first_bis = my_face_list[ridge_cycle.ridge[i]].equs[0]\n",
    "        second_bis = my_face_list[ridge_cycle.ridge[i]].equs[1]\n",
    "        angle = Riemannian_angle(my_wbs[first_bis].bis, my_wbs[second_bis].bis, point) # Compute the Riemannian angle between the bisectors\n",
    "        angle_sum = angle_sum + angle                       # Add this to the angle sum\n",
    "        word = my_wbs[ridge_cycle.pairing[i]].word          \n",
    "        point = word.T @ point @ word                       # Shift to the paired base point of the next ridge\n",
    "    quotient = 2*np.pi/angle_sum                            # Check if the quotient of the angle sum with 2pi is a natural number\n",
    "    quotient_round = round(quotient)\n",
    "    if abs(quotient - quotient_round)> 100*a_tol:\n",
    "        return None\n",
    "    else:\n",
    "        return quotient_round\n",
    "\n",
    "# Test if a given matrix in SL(3,R) is recovered by the facet pairings of the domain\n",
    "def word_is_recovered(my_wbs, my_face_list, matrix):\n",
    "    matrix = matrix/(det(matrix)**(1/3))\n",
    "    center = next(face.sample_point for face in my_face_list if face.codim == 0)  # The center is the sample point of the polytope itself\n",
    "    dest_point = matrix.T @ center @ matrix\n",
    "    word = path_word(my_wbs, my_face_list, dest_point)\n",
    "    for ind in word:\n",
    "        matrix = matrix @ my_wbs[ind].word\n",
    "    if np.all(np.abs(matrix - np.eye(3))<a_tol):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo Program: A congruence subgroup of level-two in SL(3,Z) (may take several minutes to finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ef034954074672a1838eebc69bbc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding words to the Dirichlet-Selberg domain:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/cvxpy/problems/problem.py:1510: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606d09b591c64aecb0a23f152e8951b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding more words to eliminate unpaired ridges:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of facets: 24\n",
      "Number of ridges: 84\n",
      "Number of peaks: 96\n",
      "Number of edges: 0\n",
      "Number of vertices: 0\n"
     ]
    }
   ],
   "source": [
    "generators = []\n",
    "for i, j in itertools.permutations(range(3), 2):\n",
    "    generator = np.eye(3)\n",
    "    generator[i, j] = 2\n",
    "    generators.append(generator)\n",
    "center = np.eye(3)\n",
    "my_wbs, my_face_list = compute_selberg_domain(generators, 1, 2, 20, center)\n",
    "# Count the number of faces\n",
    "print(\"Number of facets:\", sum(1 for face in my_face_list if face.codim == 1))\n",
    "print(\"Number of ridges:\", sum(1 for face in my_face_list if face.codim == 2))\n",
    "print(\"Number of peaks:\", sum(1 for face in my_face_list if face.codim == 3))\n",
    "print(\"Number of edges:\", sum(1 for face in my_face_list if face.codim == 4))\n",
    "print(\"Number of vertices:\", sum(1 for face in my_face_list if face.codim == 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo Program: A lattice group in SL(3,Z[1/2]) with 5-simplex fundamental domain (quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8e5782a69a4ea8856bf48a01a45e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding words to the Dirichlet-Selberg domain:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb361486af94940ad73340434789137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding more words to eliminate unpaired ridges:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of facets: 6\n",
      "Number of ridges: 15\n",
      "Number of peaks: 16\n",
      "Number of edges: 0\n",
      "Number of vertices: 0\n"
     ]
    }
   ],
   "source": [
    "generator = np.array([[1/2, 1/2, 0],\n",
    "        [1/2, -1/2, 1],\n",
    "        [1/2, -1/2, -1]])\n",
    "generators = [generator, generator[[1, 2, 0]][:, [1, 2, 0]]]\n",
    "center = np.eye(3)\n",
    "my_wbs, my_face_list = compute_selberg_domain(generators, 1, 3, 20, center)\n",
    "# Count the number of faces\n",
    "print(\"Number of facets:\", sum(1 for face in my_face_list if face.codim == 1))\n",
    "print(\"Number of ridges:\", sum(1 for face in my_face_list if face.codim == 2))\n",
    "print(\"Number of peaks:\", sum(1 for face in my_face_list if face.codim == 3))\n",
    "print(\"Number of edges:\", sum(1 for face in my_face_list if face.codim == 4))\n",
    "print(\"Number of vertices:\", sum(1 for face in my_face_list if face.codim == 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the sample points are taken correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest trace for sample points multiplying with corresponding facets: 2.7755575615628914e-15\n",
      "The smallest trace of sample points multiplying with non-corresponding facets: 0.0875728471814019\n"
     ]
    }
   ],
   "source": [
    "# Make sure every sample point lies on the corresponding plane. Expected to be something close to zero.\n",
    "max_trace = 0\n",
    "for face in my_face_list:\n",
    "    for ind in face.equs:\n",
    "        my_trace = np.trace(my_wbs[ind].bis @ face.sample_point)\n",
    "        max_trace = max(max_trace, abs(my_trace))\n",
    "print(\"The largest trace for sample points multiplying with corresponding facets:\", max_trace)\n",
    "# Make sure every sample point is in the interior. Expected to be a positive number.\n",
    "min_trace = np.inf\n",
    "for face in my_face_list:\n",
    "    for ind in range(len(my_wbs)):\n",
    "        if ind not in face.equs:\n",
    "            my_trace = np.trace(my_wbs[ind].bis @ face.sample_point)\n",
    "            min_trace = min(min_trace, my_trace)\n",
    "print(\"The smallest trace of sample points multiplying with non-corresponding facets:\", min_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute for the ridge cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices of ridges in the 0 th cycle: [16, 17, 21]\n",
      "The angle sum divisor for the 0 th ridge cycle equals 2\n",
      "The indices of ridges in the 1 th cycle: [19, 24, 27]\n",
      "The angle sum divisor for the 1 th ridge cycle equals 2\n",
      "The indices of ridges in the 2 th cycle: [22, 28, 30]\n",
      "The angle sum divisor for the 2 th ridge cycle equals 2\n",
      "The indices of ridges in the 3 th cycle: [26, 18, 25]\n",
      "The angle sum divisor for the 3 th ridge cycle equals 1\n",
      "The indices of ridges in the 4 th cycle: [20, 29, 23]\n",
      "The angle sum divisor for the 4 th ridge cycle equals 2\n"
     ]
    }
   ],
   "source": [
    "is_exact, original_facets, paired_facets = polytope_is_exact(my_wbs, my_face_list)\n",
    "if not is_exact:\n",
    "    print(\"The Dirichlet-Selberg domain is not exact.\")\n",
    "else:\n",
    "    ridge_cycles = compute_ridge_cycle(my_wbs, my_face_list)\n",
    "    for i in range(len(ridge_cycles)):\n",
    "        ridge_cycle = ridge_cycles[i]\n",
    "        print(\"The indices of ridges in the\", i, \"th cycle:\", ridge_cycle.ridge)\n",
    "        pairings = [my_wbs[wb].word for wb in ridge_cycle.pairing]\n",
    "        # word = np.eye(3)\n",
    "        # for pairing in pairings:\n",
    "        #     word = word @ pairing\n",
    "        # print(\"The word generated from the\", i, \"th ridge cycle:\")\n",
    "        # print(word)\n",
    "        my_angle_sum = angle_sum(my_wbs, my_face_list, ridge_cycle)\n",
    "        if my_angle_sum == None:\n",
    "            print(\"The\", i, \"th ridge cycle does not satisfy the angle sum condition.\")\n",
    "        else:\n",
    "            print(\"The angle sum divisor for the\", i, \"th ridge cycle equals\", my_angle_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if each generator is recovered as a product of the facet pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0 th generator is recovered by the product of facet pairings with indices: [2]\n",
      "the 1 th generator is recovered by the product of facet pairings with indices: [3]\n"
     ]
    }
   ],
   "source": [
    "for ind, matrix in enumerate(generators):\n",
    "    if word_is_recovered(my_wbs, my_face_list, matrix):\n",
    "        print(\"the\", ind, \"th generator is recovered by the product of facet pairings with indices:\", path_word(my_wbs, my_face_list, matrix.T @ center @ matrix))\n",
    "    else:\n",
    "        print(\"the\", ind, \"th generator is not recovered by the facet pairings.\" )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
